# 贯穿项目：数据探索者报告

## 项目概述

学生选择一个真实数据集，在 14 周内完成从探索到建模的完整数据分析项目。

**项目目标**：
- 体验完整的数据分析流程
- 培养"假设驱动"的分析思维
- 学会用 AI 加速但不盲从
- 练习数据沟通和故事叙述

---

## 项目阶段

### 阶段 1：选题与数据获取（Week 01-02）

**任务**：
- 选择感兴趣的数据集
- 初步数据探索
- 明确研究问题（不能只是"看看数据里有什么"）

**可选数据集来源**：

| 类型 | 示例 | 适合的分析 |
|------|------|-----------|
| 公开竞赛 | Kaggle Titanic、House Prices | 预测建模 |
| 政府开放数据 | 国家统计局、WHO | 趋势分析 |
| UCI ML | Iris、Wine Quality | 分类、聚类 |
| 自建数据 | 问卷、实验、爬虫 | 自定义分析 |

**检查点**：
- [ ] 数据集已获取并可加载
- [ ] 有明确的研究问题（如"什么因素影响了..."）
- [ ] 初步 EDA 报告（数据规模、变量类型、缺失情况）

---

### 阶段 2：数据清洗与 EDA（Week 03-04）

**任务**：
- 处理缺失值、异常值
- 数据类型转换
- 生成描述性统计
- 创建探索性可视化

**交付物**：
- `data_cleaning.ipynb`：清洗过程和决策记录
- `eda_report.ipynb`：探索性分析，包含：
  - 变量分布
  - 相关性分析
  - 有趣的初步发现（3-5 个）

**AI 使用重点**：
- 用 AI 生成清洗代码
- 但必须人工检查每一步是否合理
- 记录为什么这样处理缺失值/异常值

---

### 阶段 3：统计推断（Week 05-08）

**任务**：
- 根据研究问题设计假设检验
- 选择合适检验方法
- 计算 p-value、置信区间、效应量
- 解释结果的业务意义

**交付物**：
- `statistical_analysis.ipynb`：
  - 研究假设
  - 检验方法选择理由
  - 检验前提验证
  - 结果和解释

**AI 使用重点**：
- AI 协助选择检验方法
- AI 执行计算
- 学生负责：
  - 验证前提条件
  - 解释业务含义
  - 判断是否多重比较问题

---

### 阶段 4：预测建模（Week 09-11）

**任务**：
- 建立预测模型（回归或分类）
- 特征工程
- 模型评估和选择
- 模型解释

**交付物**：
- `predictive_model.ipynb`：
  - 模型选择理由
  - 特征工程过程
  - 训练/测试分割策略
  - 性能评估（多指标）
  - 特征重要性分析

**AI 使用重点**：
- AI 快速尝试多种模型
- 学生负责：
  - 定义评估指标
  - 防止过拟合
  - 解释模型结果
  - 判断模型是否可用

---

### 阶段 5：整合与展示（Week 12-14）

**任务**：
- 整合分析为连贯的故事
- 创建最终可视化
- 准备展示材料

**最终交付物**：

1. **分析报告** (`final_report.ipynb` 或 HTML)
   - 执行摘要（1页）
   - 研究背景和问题
   - 数据介绍
   - 分析方法
   - 主要发现
   - 局限性和未来方向

2. **数据集和代码**
   - 原始数据（或获取脚本）
   - 清洗后的数据
   - 完整代码（可复现）

3. **展示材料**
   - 10-15 分钟展示 PPT
   - 面向非技术观众
   - 突出关键发现和洞察

4. **AI 使用日志**
   - AI_LOG.md
   - 记录使用场景、审查过程、改进措施

---

## 评估标准

### 数据分析质量（40%）

| 维度 | 优秀 | 良好 | 合格 | 不合格 |
|------|------|------|------|--------|
| 问题定义 | 清晰、可验证、有意义 | 较清晰 | 模糊但可执行 | 不明确 |
| 方法选择 | 恰当、前提验证 | 基本恰当 | 有小问题 | 明显错误 |
| 结果解释 | 深入、联系业务 | 较合理 | 表面化 | 错误或过度 |
| 可复现性 | 代码清晰、可运行 | 基本可复现 | 有小问题 | 无法复现 |

### AI 协作能力（20%）

- AI 使用是否透明（有日志）
- 是否能发现 AI 建议中的问题
- 是否能在 AI 基础上改进

### 数据沟通（20%）

- 可视化是否清晰、不误导
- 故事叙述是否有吸引力
- 非技术观众能否理解

### 创新与洞察（20%）

- 是否有意外的发现
- 分析是否深入而非表面
- 是否提出了有价值的建议

---

## 示例项目

### 示例 1：员工流失预测
- **数据**：公司 HR 数据（工资、满意度、工时等）
- **问题**：什么因素导致员工离职？能否预测谁可能离职？
- **分析**：
  - EDA：流失率分布、相关因素
  - 推断：工资与流失的关系（t 检验）
  - 建模：分类模型预测流失风险

### 示例 2：房价影响因素
- **数据**：Kaggle House Prices
- **问题**：什么因素最影响房价？能准确预测房价吗？
- **分析**：
  - EDA：房价分布、区域差异
  - 推断：不同区域房价差异（ANOVA）
  - 建模：回归模型预测房价

### 示例 3：教育公平分析
- **数据**：公开教育数据（成绩、家庭背景、学校资源）
- **问题**：家庭背景对成绩的影响有多大？学校资源能弥补吗？
- **分析**：
  - EDA：成绩分布、群体差异
  - 推断：回归分析控制混杂变量
  - 可视化：展示教育不平等

---

## 常见问题

**Q：可以一个人做还是可以组队？**  
A：推荐 2-3 人组队，但每人必须有明确的分工和贡献。

**Q：数据集要多大？**  
A：至少几百行，包含多个变量。太小无法体现统计方法，太大处理麻烦。

**Q：可以用 AI 生成数据吗？**  
A：不可以。必须使用真实数据，但可以用 AI 辅助数据清洗和分析。

**Q：如果数据没有有趣的发现怎么办？**  
A："没有显著发现"本身就是一个有价值的结论。重要的是分析过程严谨，而不是一定要找到什么。

**Q：展示时要讲代码吗？**  
A：不需要。展示面向非技术观众，重点讲问题、发现和洞察。代码在报告里。
