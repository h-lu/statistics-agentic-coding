# 写作范例库（供 Agent 参照）

本文件给出"教材写作"的具体 before / after 范例。
所有写章节的 agent 在动笔前必须读此文件，理解"好"与"坏"的区别。

---

## 原则速览

1. **叙事优先，结论收尾**：先带读者经历一个场景/困惑，再给出概念名称。不要上来就"本节介绍 X"。
2. **贯穿案例**：每章围绕一个渐进式小项目展开，每学一个概念就往项目上加一层。读者在章末能拿到一个"有用的小东西"。
3. **变化的节奏**：长句解释、短句点睛；段落叙述与代码块穿插；偶尔反问、偶尔设悬念。不要每节结构都一模一样。
4. **真实的温度**：像一个有经验的统计/数据分析老师坐在学生旁边讲，不是一个委员会写的规范文档。

---

## 范例 1：引入新概念

### ❌ 坏（模板填空式）

> ## 置信区间
>
> 置信区间（confidence interval）是统计推断中的重要概念，用于估计总体参数的不确定性。
>
> ```python
> import numpy as np
>
> mean = np.mean(x)
> # ... 计算置信区间 ...
> ```
>
> ### 小结
> - 置信区间用于估计不确定性
> - 置信水平常用 95%

**问题在哪？**
- 上来就定义，读者不知道"为什么要关心这个"。
- 代码像装饰品，没有把概念和现实问题连起来。
- 小结是"正确的废话"：读完也不知道何时、为何要用。

### ✅ 好（场景驱动式）

> ## 你到底有多确定？
>
> 你算出某个指标的平均值是 3.2，然后在报告里写："平均值是 3.2"。老潘看完只回了四个字：**"有多确定？"**
>
> 这不是抬杠。因为同样是 3.2：
> - 如果来自 20 个样本，它可能随便换一批人就变成 2.8 或 3.7；
> - 如果来自 2 万个样本，它才更像一个"稳定的事实"。
>
> 所以我们需要的不只是一个点，而是一个范围：在合理的假设下，这个平均值大概落在哪儿？这就是**置信区间**（confidence interval）要回答的问题。
>
> ```python
> import numpy as np
> from scipy import stats
>
> x = np.asarray(x, dtype=float)
> mean = x.mean()
> se = stats.sem(x, nan_policy="omit")
> ci_low, ci_high = stats.t.interval(0.95, df=len(x) - 1, loc=mean, scale=se)
> ```
>
> 你不需要背公式。先记住一个直觉：**区间越宽，你越不确定；区间越窄，你越有底气。**
>
> 下一步的问题也就自然出现了：这个区间为什么会变宽/变窄？它和样本量、方差之间是什么关系？

**为什么好？**
- 从"写报告被追问"的真实场景切入，读者立刻知道"我需要它"。
- 概念是在解决问题过程中出现的，不是先定义再举例。
- 结尾把读者带到下一节（区间的决定因素），过渡自然。

---

## 范例 2：讲解常见错误

### ❌ 坏（清单罗列式）

> ### 常见错误
>
> - p 值小于 0.05 说明结论成立
> - p 值大于 0.05 说明没有差异
> - p 值越小越好

**问题在哪？**
- 像贴在墙上的标语，没有上下文，读者记不住也用不上。
- 没说明读者会在什么场景下掉进这些坑。
- 没给出"怎么自救"的可操作动作。

### ✅ 好（情境还原式）

> 你把数据丢给 AI，让它"顺手做一下显著性检验"。AI 很勤奋，刷刷刷给你列了 20 个指标的 p 值，其中 3 个小于 0.05。
>
> 小北激动了："我们找到规律了！"
>
> 先别急。你现在遇到的不是统计技巧问题，而是一个**决策问题**：当你一次性检验很多指标时，总会有一部分"看起来显著"只是运气。
>
> 这个坑的名字叫**多重比较**（multiple comparisons）。解决它的方法不止一种，但第一步永远是：**把你做了多少次比较写清楚**，并在报告里说明是否做了校正。
>
> 阿码追问："那我是不是永远不能看 p<0.05？"
>
> 也不是。你要学会的是：p 值只是证据的一部分。至少再问两句：
> - 效应量有多大？（差异是不是"有意义"）
> - 前提假设满足吗？（数据分布、独立性、方差齐性等）

**为什么好？**
- 错误出现在"真实工作流"里：AI 一键产出结果，读者很容易照单全收。
- 不只是说"别这样"，还告诉读者第一步怎么做（写清比较次数/校正）。
- 通过角色对话把边界问题自然引出（阿码的追问）。

---

## 范例 3：章节开头（引入动机）

### ❌ 坏

> ## 描述性统计
>
> 描述性统计用于对数据进行汇总与描述，包括均值、中位数、方差等。

**问题在哪？**
- 没有场景。读者看完只会觉得"嗯，是的"，然后跳过。
- 这句话对读者的下一步行为没有任何指导。

### ✅ 好

> ## 你手里拿到一份表，第一眼该看哪里？
>
> 你打开一份新数据：1000 行、30 列。AI 在旁边催你："我可以直接训练模型。"小北也很想快进："我们能不能先跑个回归？"
>
> 但你真正需要的是一个更慢、更可靠的起步：先回答三个问题：
> 1) 这张表在讲谁？（样本是什么）
> 2) 这些列分别是什么意思？（字段是什么）
> 3) 哪些数字一眼就不靠谱？（缺失、异常、尺度）
>
> 描述性统计不是"背公式"，而是让你在 5 分钟内对一份陌生数据建立直觉：大概的范围、分布形状、典型值与离群点。先把地基打好，后面的推断和建模才有意义。

**为什么好？**
- 从读者最常见的起点切入："打开一份陌生数据，不知道先做什么"。
- 把描述性统计变成行动指南（3 个问题），而不是术语介绍。
- 自然对齐本章目标：建立数据直觉，为后续推断/建模铺路。

---

## 范例 4：小结的写法

### ❌ 坏（项目符号堆砌）

> ### 小结
>
> - 均值用于衡量集中趋势
> - 标准差用于衡量离散程度
> - 箱线图用于观察异常值

### ✅ 好（回顾 + 展望）

> 这一节你做的不是"把指标算出来"，而是学会了**先看数据长什么样**：均值和中位数回答的是两类问题；标准差描述波动；箱线图把异常值直接摆到你面前。
>
> 现在你有了直觉，但也更容易产生一个追问：我看到的差异，是真差异，还是抽样带来的幻觉？下节我们开始谈不确定性。

**为什么好？**
- 不是罗列术语，而是把术语收束成一条"你获得了什么能力"的叙述。
- 最后一句把读者引向下一节（从描述到推断），过渡自然。

---

## 范例 5：贯穿案例的用法

一章围绕一个渐进式小项目展开。比如 Week 02 的贯穿案例可以是**"一次用户留存分析的误会"**：

- 第 1 节（数据卡）：先写清样本是谁、时间范围是什么、字段怎么来的
- 第 2 节（集中趋势）：留存率看均值还是中位数？为什么
- 第 3 节（分布与分组）：不同渠道/不同城市分布有没有长尾
- 第 4 节（可视化）：用一张图把误会讲清楚（并解释图的边界）
- 第 5 节（错误与反例）：故意做一次"截断 Y 轴"的误导图，再把它修正

每节末尾都能拿到一个可复用的分析片段，章末汇总成一页小报告，读者会有成就感。

---

## 范例 6：循环角色的使用

### ❌ 坏（为出场而出场）

> 小北说："p 值越小越好。"
>
> 阿码说："对，我也是这么理解的。"

**问题在哪？**
- 角色在复述或背诵，没有推动叙事。
- 小北不应该给出结论，他更适合先误解、再被纠正。
- 阿码只是附和，没展示他爱追问边界的性格。

### ✅ 好（角色推动叙事）

> 小北把 AI 生成的结果复制进报告：`p = 0.03`，然后写下结论："差异显著。"
>
> 老潘问："你检验了几个指标？"
>
> 小北愣住了："就……AI 给我的这些？"
>
> 你这才顺势补上一句：当你一次看很多指标时，总会出现"看起来显著"的幸运儿。你需要在报告里写清比较次数，并决定是否做校正。
>
> 阿码不服："那我是不是以后都不用 p 值了？"
>
> 好问题。你告诉他：p 值不是不能用，而是不能单独用。至少再补两块拼图：效应量和前提假设检查。

**为什么好？**
- 小北通过"复制 AI 结果就下结论"犯错，极贴近 AI 时代的真实学习场景。
- 老潘一句话把工程视角带进来（流程审计：你到底做了多少次比较？）。
- 阿码的追问把边界讲清楚（不是否定工具，而是建立使用条件）。

---

## 范例 7：回顾桥的写法

### ❌ 坏（生硬复习）

> ## 回顾
>
> 上周我们学习了箱线图。箱线图由中位数、四分位数和须组成。
>
> 本周我们将学习异常值处理。

**问题在哪？**
- 在重复上周内容，没有把上周和本周连接起来。
- "本周我们将学习"是禁忌句式，模板感很强。

### ✅ 好（在新场景中让旧概念再次出场）

> 上周你用箱线图第一次看到一个事实：数据不是一团乖巧的点，它有长尾，有离群点。
>
> 这周我们要做的不是"把离群点删掉"这么粗暴。我们要回答的是：这些点到底是什么？是录入错误？是极端但真实的用户？还是某个分组特有的现象？
>
> 你会发现，上周那张箱线图其实已经给了你线索：离群点集中在哪些分组？如果按城市拆开看，长尾还在吗？
>
> 同样的图，同样的中位数和四分位数，只是这次我们用它来做决策：**该修数据，还是该修解释。**

**为什么好？**
- 旧概念（箱线图）在新场景（异常值决策）里再次出现，起到"桥"的作用。
- 读者能感受到上周学的东西变得更有用，而不是被丢弃。

---

## 范例 8：StatLab 超级线进度写法

### ❌ 坏（与正文脱节）

> ## StatLab 进度
>
> 本周给 StatLab 加了缺失值处理。代码如下：
>
> ```python
> import pandas as pd
>
> def drop_missing(df: pd.DataFrame) -> pd.DataFrame:
>     return df.dropna()
> ```

**问题在哪？**
- 代码直接出现，没有叙事上下文。
- 没有说明"为什么 StatLab 需要这个改进"。
- 没有与本周正文内容建立连接。

### ✅ 好（自然融入本周主题）

> ## StatLab 进度
>
> 到目前为止，StatLab 有一个“看不见的坑”：我们在报告里直接计算均值、画分布图，但如果某一列缺失值很多，结论可能会悄悄偏掉，甚至你自己都没意识到。
>
> 这正好是本周“缺失值机制与处理策略”派上用场的地方。与其一上来就 `dropna()`，不如先把缺失情况写进报告，让读者知道“我们正在和什么样的数据打交道”：
>
> ```python
> import pandas as pd
>
> def missing_summary(df: pd.DataFrame) -> pd.DataFrame:
>     \"\"\"Return missing-rate table for report.md.\"\"\"
>     rate = df.isna().mean().sort_values(ascending=False)
>     return (rate * 100).round(1).rename(\"missing_%\").to_frame()
> ```
>
> 现在 `report.md` 的开头会多一张“缺失概览表”。缺失率最高的字段会被优先点名，我们也能更有底气地解释：后面的分析结论到底“站在什么数据地基上”。
>
> 老潘看到这段改动会说什么？“别急着修数据，先把问题暴露出来。你写的是报告，不是魔术。”

**为什么好？**
- 从 StatLab 的真实“痛点”出发，让本周知识有了用武之地。
- 改进有前后对比（之前缺失被忽略，现在缺失被量化并进入报告）。
- 用老潘的点评收束，增加工程视角。

---

## 禁忌清单

| 编号 | 禁忌 | 替代 |
|------|------|------|
| 1 | 每节用相同的子标题模式（"最小正例""常见错误""小结"） | 让内容决定结构，每节可以不同 |
| 2 | 用"在本节中，我们将…"开头 | 用场景/问题/悬念开头 |
| 3 | 列表超过 5 条连续出现 | 拆散到段落叙述中 |
| 4 | "数据分析/统计本质上是…"类的空泛定义 | 用具体场景替代 |
| 5 | 一节内只有代码块 + 一句话解释 | 代码前后都要有足够的叙述上下文 |
| 6 | 用"重要心态""注意"等说教标签 | 把态度建议织进叙述里 |
| 7 | 每节末尾都用项目符号列表做小结 | 可以用叙述段落、可以用表格、可以用回顾问句 |

