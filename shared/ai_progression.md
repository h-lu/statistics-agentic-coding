# AI 辅助统计分析的渐进融合路径

## 设计理念

LLM（ChatGPT、Claude 等）已经可以帮你写代码、画图、跑检验，甚至替你写一段“看起来很像结论”的文字。但对学习者来说，最危险的不是“不会用 AI”，而是**过早把判断权交给 AI**：你可能得到一份格式完美、逻辑却不成立的分析报告。

本书的策略：**先建立统计直觉与审查能力，再逐步引入 AI 作为协作伙伴。** AI 是加速器，但不替你承担结论责任。

## 四阶段路径（与 16 周课程对齐）

### 阶段一：观察期（Week 01-04）

**原则**：AI 可以出现，但不成为“答案来源”。先把 EDA 的基本功打牢。

**在正文中**：
- 不教授“提示词技巧”，只强调“你必须能解释每个图和每个指标”
- 示例代码以学生可理解为标准（不追求炫技）

**在作业中**：
- **禁止**设置“必须使用 AI 才能完成”的题
- 允许在“挑战”层加入反思题：让 AI 生成一段 EDA 结论，你指出其中的漏洞（不交 AI 输出，交你的审查）

### 阶段二：识别期（Week 05-08）

**原则**：学会审查 AI 的统计推断结论。不是“让 AI 跑检验”，而是“看 AI 跑的检验是否站得住”。

**在正文中**：
- 可以展示一段 AI 生成的检验/结论，让读者指出：前提假设、样本量、多重比较、效应量解释是否缺失
- 用“阿码说：‘这不就是让 AI 跑一下 t 检验吗？’”引出讨论

**在作业中**：
- ASSIGNMENT.md 可以包含 `### AI 协作练习（可选）`：
  - 给一段 AI 生成的“检验结论”，让学生写审查报告
  - 要求至少指出 2 个风险点，并给出改进建议

**审查清单模板**（供 exercise-factory 使用）：
```markdown
### AI 协作练习（可选）

下面这段结论是某个 AI 工具基于你的数据生成的。请审查它（你提交的是审查与修订，不是原文）：

> （AI 结论粘贴在这里）

审查清单：
- [ ] 它回答的问题和你真正想问的问题一致吗？
- [ ] 它说明了检验的前提假设吗？（独立性/正态性/方差齐性等）
- [ ] 它有把效应量/区间估计写出来吗？还是只谈 p-value？
- [ ] 有没有多重比较风险？是否需要校正？
- [ ] 它有没有把“相关”写成“因果”？

你的修订版（用你自己的话重写）：
...
```

### 阶段三：协作期（Week 09-12）

**原则**：AI 辅助建模与评估，但关键决策（特征、评估指标、避免数据泄漏）必须由人主导。

**在正文中**：
- 可以展示 human-in-the-loop 工作流：人定问题与指标 → AI 产出候选模型与图 → 人审查（泄漏/过拟合/解释性）→ 迭代
- 强调“用 Pipeline 做交叉验证避免数据泄漏”这类工程底线

**在作业中**：
- `### AI 协作练习（可选）` 可以更主动：
  - 让 AI 生成 5 个可疑的边界用例，你来筛选并补充
  - 让 AI 生成一段模型评估总结，你来指出它遗漏的前提/限制

### 阶段四：主导期（Week 13-16）

**原则**：AI 作为结对分析伙伴。学生主导研究问题、假设与解释边界，AI 辅助实现对照实验与报告润色。

**在正文中**：
- 强调“能复现”比“写得漂亮”更重要：结论必须能用脚本跑出来
- 鼓励用 agent team 做分工（一个人盯统计假设，一个人盯代码复现，一个人盯叙事表达）

**在作业/项目中**：
- 允许 AI 深度参与，但必须提交：
  - 审查清单
  - 改动记录（你采纳了什么、拒绝了什么、为什么）

## 关键约束

1. **任何周的核心作业都不能要求使用 AI 工具**：AI 练习永远是“可选”。
2. **AI 输出不能直接当结论**：必须经过审查与可复现验证。
3. **每个 AI 协作练习必须包含审查清单**：避免“复制粘贴式作业”。
4. **任何侧栏中的统计数据/外部事件必须有真实来源**：禁止编造。

