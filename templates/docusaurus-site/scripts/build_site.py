#!/usr/bin/env python3
"""
build_site.py - Docusaurus ç«™ç‚¹å†…å®¹ç”Ÿæˆè„šæœ¬

ä» chapters/ ç›®å½•è‡ªåŠ¨ç”Ÿæˆ Docusaurus ç«™ç‚¹å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š
- è§£æ TOC.md ç”Ÿæˆ sidebars.ts
- ä¸ºæ¯ä¸ª week_XX ç”Ÿæˆå®Œæ•´çš„é¡µé¢ç»“æ„
- å¤„ç† YAML æ–‡ä»¶ï¼ˆANCHORS.yml, TERMS.ymlï¼‰çš„æ¸²æŸ“
- å¤„ç†ä»£ç æ–‡ä»¶çš„èšåˆå’Œå±•ç¤º

ç”¨æ³•:
    python scripts/build_site.py [options]

é€‰é¡¹:
    --site-dir SITE_DIR    ç«™ç‚¹ç›®å½• (é»˜è®¤: site)
    --chapters-dir DIR     chapters ç›®å½• (é»˜è®¤: chapters)
    --shared-dir DIR       shared ç›®å½• (é»˜è®¤: shared)
    --verbose              è¯¦ç»†è¾“å‡º
"""

import argparse
import logging
import os
import re
import shutil
import sys
from dataclasses import dataclass, field
from pathlib import Path
from typing import Any, Optional

import yaml


# =============================================================================
# æ•°æ®ç±»å®šä¹‰
# =============================================================================

@dataclass
class WeekInfo:
    """æ¯å‘¨ä¿¡æ¯"""
    number: int
    title: str
    phase: str
    phase_label: str
    has_chapter: bool = False
    has_assignment: bool = False
    has_rubric: bool = False
    has_anchors: bool = False
    has_terms: bool = False
    has_examples: bool = False
    has_starter_code: bool = False
    has_tests: bool = False


@dataclass
class PhaseInfo:
    """é˜¶æ®µä¿¡æ¯"""
    name: str
    label: str
    weeks: list[WeekInfo] = field(default_factory=list)


@dataclass
class AnchorEntry:
    """é”šç‚¹æ¡ç›®"""
    id: str
    claim: str
    evidence: str
    verification: str
    status: str = "pending"


@dataclass
class TermEntry:
    """æœ¯è¯­æ¡ç›®"""
    chinese: str
    english: str
    definition: str


# =============================================================================
# æ—¥å¿—é…ç½®
# =============================================================================

def setup_logging(verbose: bool = False) -> logging.Logger:
    """é…ç½®æ—¥å¿—è¾“å‡º"""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format='%(asctime)s [%(levelname)s] %(message)s',
        datefmt='%H:%M:%S'
    )
    return logging.getLogger(__name__)


# =============================================================================
# TOC è§£æå™¨
# =============================================================================

class TOCParser:
    """TOC.md è§£æå™¨"""
    
    # é˜¶æ®µæ˜ å°„
    PHASE_MAP = {
        'é˜¶æ®µä¸€': ('phase-1', 'æ€ç»´å¥ åŸº'),
        'é˜¶æ®µäºŒ': ('phase-2', 'ç³»ç»ŸåŒ–å·¥ç¨‹'),
        'é˜¶æ®µä¸‰': ('phase-3', 'AI æ—¶ä»£çš„å·¥ç¨‹'),
        'é˜¶æ®µå››': ('phase-4', 'ç»¼åˆå®æˆ˜'),
    }
    
    def __init__(self, chapters_dir: Path, logger: logging.Logger):
        self.chapters_dir = chapters_dir
        self.logger = logger
        self.phases: list[PhaseInfo] = []
        
    def parse(self) -> list[PhaseInfo]:
        """è§£æ TOC.md æ–‡ä»¶"""
        toc_path = self.chapters_dir / 'TOC.md'
        
        if not toc_path.exists():
            self.logger.warning(f"TOC.md ä¸å­˜åœ¨: {toc_path}")
            return self._create_default_phases()
        
        self.logger.info(f"è§£æ TOC.md: {toc_path}")
        content = toc_path.read_text(encoding='utf-8')
        
        current_phase: Optional[PhaseInfo] = None
        
        for line in content.split('\n'):
            line = line.strip()
            
            # è§£æé˜¶æ®µæ ‡é¢˜
            if line.startswith('## '):
                phase_name = line[3:].strip()
                current_phase = self._create_phase(phase_name)
                if current_phase:
                    self.phases.append(current_phase)
                    self.logger.debug(f"å‘ç°é˜¶æ®µ: {current_phase.label}")
            
            # è§£æå‘¨æ¡ç›® - æ”¯æŒåˆ—è¡¨æ ¼å¼ (- **Week**) å’Œè¡¨æ ¼æ ¼å¼ (| 01 | ...)
            elif current_phase and (line.startswith('- **Week') or (line.startswith('|') and re.match(r'^\|\s*\d+\s*\|', line))):
                week_info = self._parse_week_line(line, current_phase)
                if week_info:
                    current_phase.weeks.append(week_info)
                    self.logger.debug(f"  å‘ç°å‘¨: Week {week_info.number:02d} - {week_info.title}")
        
        return self.phases
    
    def _create_phase(self, phase_name: str) -> Optional[PhaseInfo]:
        """åˆ›å»ºé˜¶æ®µä¿¡æ¯"""
        for phase_key, (phase_id, phase_label) in self.PHASE_MAP.items():
            if phase_key in phase_name:
                return PhaseInfo(
                    name=phase_name,
                    label=f"{phase_key}ï¼š{phase_label}"
                )
        return None
    
    def _parse_week_line(self, line: str, phase: PhaseInfo) -> Optional[WeekInfo]:
        """è§£æå‘¨æ¡ç›®è¡Œ - æ”¯æŒåˆ—è¡¨æ ¼å¼å’Œè¡¨æ ¼æ ¼å¼"""
        # å°è¯•åŒ¹é…åˆ—è¡¨æ ¼å¼: - **Week 01**: æ ‡é¢˜
        list_pattern = r'- \*\*Week\s*(\d+)\*\*:\s*(.+)'
        # å°è¯•åŒ¹é…è¡¨æ ¼æ ¼å¼: | 01 | [æ ‡é¢˜](week_01/CHAPTER.md) | ...
        table_pattern = r'^\|\s*(\d+)\s*\|\s*\[([^\]]+)\]\([^)]+\)'
        
        match = re.match(list_pattern, line)
        if match:
            week_num = int(match.group(1))
            week_title = match.group(2).strip()
        else:
            match = re.match(table_pattern, line)
            if not match:
                return None
            week_num = int(match.group(1))
            week_title = match.group(2).strip()
        
        # æ£€æŸ¥å‘¨ç›®å½•ä¸­çš„æ–‡ä»¶
        week_dir = self.chapters_dir / f'week_{week_num:02d}'
        
        week_info = WeekInfo(
            number=week_num,
            title=week_title,
            phase=phase.name,
            phase_label=phase.label,
            has_chapter=(week_dir / 'CHAPTER.md').exists(),
            has_assignment=(week_dir / 'ASSIGNMENT.md').exists(),
            has_rubric=(week_dir / 'RUBRIC.md').exists(),
            has_anchors=(week_dir / 'ANCHORS.yml').exists(),
            has_terms=(week_dir / 'TERMS.yml').exists(),
            has_examples=(week_dir / 'examples').exists() and any((week_dir / 'examples').iterdir()),
            has_starter_code=(week_dir / 'starter_code').exists() and any((week_dir / 'starter_code').iterdir()),
            has_tests=(week_dir / 'tests').exists() and any((week_dir / 'tests').iterdir()),
        )
        
        return week_info
    
    def _create_default_phases(self) -> list[PhaseInfo]:
        """åˆ›å»ºé»˜è®¤é˜¶æ®µï¼ˆå½“ TOC.md ä¸å­˜åœ¨æ—¶ï¼‰"""
        self.logger.warning("ä½¿ç”¨é»˜è®¤é˜¶æ®µé…ç½®")
        phases = []
        
        for phase_key, (phase_id, phase_label) in self.PHASE_MAP.items():
            phase = PhaseInfo(
                name=f"{phase_key}ï¼š{phase_label}",
                label=f"{phase_key}ï¼š{phase_label}"
            )
            
            # ä¸ºæ¯ä¸ªé˜¶æ®µæ·»åŠ å‘¨
            week_ranges = {
                'é˜¶æ®µä¸€': range(1, 5),
                'é˜¶æ®µäºŒ': range(5, 9),
                'é˜¶æ®µä¸‰': range(9, 13),
                'é˜¶æ®µå››': range(13, 17),
            }
            
            for week_num in week_ranges.get(phase_key, range(1, 5)):
                week_dir = self.chapters_dir / f'week_{week_num:02d}'
                if week_dir.exists():
                    week_info = WeekInfo(
                        number=week_num,
                        title=f"Week {week_num:02d}",
                        phase=phase.name,
                        phase_label=phase.label,
                        has_chapter=(week_dir / 'CHAPTER.md').exists(),
                        has_assignment=(week_dir / 'ASSIGNMENT.md').exists(),
                        has_rubric=(week_dir / 'RUBRIC.md').exists(),
                        has_anchors=(week_dir / 'ANCHORS.yml').exists(),
                        has_terms=(week_dir / 'TERMS.yml').exists(),
                        has_examples=(week_dir / 'examples').exists() and any((week_dir / 'examples').iterdir()),
                        has_starter_code=(week_dir / 'starter_code').exists() and any((week_dir / 'starter_code').iterdir()),
                        has_tests=(week_dir / 'tests').exists() and any((week_dir / 'tests').iterdir()),
                    )
                    phase.weeks.append(week_info)
            
            phases.append(phase)
        
        return phases


# =============================================================================
# YAML è§£æå™¨
# =============================================================================

class YAMLParser:
    """YAML æ–‡ä»¶è§£æå™¨"""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
    
    def parse_anchors(self, file_path: Path) -> list[AnchorEntry]:
        """è§£æ ANCHORS.yml æ–‡ä»¶"""
        if not file_path.exists():
            return []
        
        try:
            content = yaml.safe_load(file_path.read_text(encoding='utf-8'))
            anchors = []
            
            if isinstance(content, list):
                for item in content:
                    if isinstance(item, dict):
                        anchors.append(AnchorEntry(
                            id=str(item.get('id', '')),
                            claim=str(item.get('claim', '')),
                            evidence=str(item.get('evidence', '')),
                            verification=str(item.get('verification', '')),
                            status=str(item.get('status', 'pending'))
                        ))
            
            return anchors
        except Exception as e:
            self.logger.warning(f"è§£æ ANCHORS.yml å¤±è´¥: {file_path} - {e}")
            return []
    
    def parse_terms(self, file_path: Path) -> list[TermEntry]:
        """è§£æ TERMS.yml æˆ– glossary.yml æ–‡ä»¶"""
        if not file_path.exists():
            return []
        
        try:
            content = yaml.safe_load(file_path.read_text(encoding='utf-8'))
            terms = []
            
            if isinstance(content, list):
                for item in content:
                    if isinstance(item, dict):
                        # æ”¯æŒå¤šç§é”®åæ ¼å¼
                        chinese = item.get('chinese') or item.get('cn') or item.get('term_zh') or ''
                        english = item.get('english') or item.get('en') or item.get('term_en') or ''
                        definition = item.get('definition') or item.get('desc') or item.get('definition_zh') or ''
                        terms.append(TermEntry(
                            chinese=str(chinese),
                            english=str(english),
                            definition=str(definition)
                        ))
            elif isinstance(content, dict):
                # å¤„ç† glossary.yml æ ¼å¼
                for key, value in content.items():
                    if isinstance(value, dict):
                        chinese = value.get('chinese') or value.get('cn') or value.get('term_zh') or key
                        english = value.get('english') or value.get('en') or value.get('term_en') or ''
                        definition = value.get('definition') or value.get('desc') or value.get('definition_zh') or ''
                        terms.append(TermEntry(
                            chinese=str(chinese),
                            english=str(english),
                            definition=str(definition)
                        ))
            
            return terms
        except Exception as e:
            self.logger.warning(f"è§£æ TERMS.yml å¤±è´¥: {file_path} - {e}")
            return []


# =============================================================================
# ä»£ç æ–‡ä»¶æ”¶é›†å™¨
# =============================================================================

class CodeCollector:
    """ä»£ç æ–‡ä»¶æ”¶é›†å™¨"""
    
    CODE_EXTENSIONS = {'.java', '.py', '.js', '.ts', '.jsx', '.tsx', '.md', '.txt', '.yml', '.yaml', '.json', '.xml'}
    # æ’é™¤çš„æ–‡ä»¶æ‰©å±•åï¼ˆç¼–è¯‘äº§ç‰©ã€äºŒè¿›åˆ¶æ–‡ä»¶ç­‰ï¼‰
    EXCLUDED_EXTENSIONS = {'.class', '.jar', '.war', '.nar', '.ear', '.zip', '.tar.gz', '.rar'}
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
    
    def collect_files(self, directory: Path) -> dict[str, list[dict]]:
        """æ”¶é›†ç›®å½•ä¸­çš„ä»£ç æ–‡ä»¶"""
        result = {
            'examples': [],
            'starter_code': [],
            'tests': []
        }
        
        if not directory.exists():
            return result
        
        for subdir_name in ['examples', 'starter_code']:
            subdir = directory / subdir_name
            if subdir.exists():
                result[subdir_name] = self._collect_directory_files(subdir)

        # Tests ç›®å½•ï¼šä¼˜å…ˆæ£€æŸ¥é¡¶å±‚ tests/ï¼Œå¦åˆ™æ£€æŸ¥ starter_code/src/test/
        tests_dir = directory / 'tests'
        if not tests_dir.exists():
            tests_dir = directory / 'starter_code' / 'src' / 'test'
        if tests_dir.exists():
            result['tests'] = self._collect_directory_files(tests_dir)

        return result
    
    def _collect_directory_files(self, directory: Path) -> list[dict]:
        """é€’å½’æ”¶é›†ç›®å½•ä¸­çš„æ–‡ä»¶"""
        files = []

        try:
            for item in sorted(directory.rglob('*')):
                if item.is_file():
                    # è·³è¿‡éšè—æ–‡ä»¶
                    if item.name.startswith('.'):
                        continue
                    # è·³è¿‡æ’é™¤çš„æ‰©å±•åï¼ˆç¼–è¯‘äº§ç‰©ã€äºŒè¿›åˆ¶æ–‡ä»¶ç­‰ï¼‰
                    if item.suffix.lower() in self.EXCLUDED_EXTENSIONS:
                        continue

                    rel_path = item.relative_to(directory)
                    content = self._read_file_content(item)

                    files.append({
                        'path': str(rel_path),
                        'name': item.name,
                        'content': content,
                        'language': self._detect_language(item)
                    })
        except Exception as e:
            self.logger.warning(f"æ”¶é›†æ–‡ä»¶å¤±è´¥: {directory} - {e}")

        return files
    
    def _read_file_content(self, file_path: Path) -> str:
        """è¯»å–æ–‡ä»¶å†…å®¹"""
        try:
            # å°è¯•ä»¥æ–‡æœ¬æ–¹å¼è¯»å–
            return file_path.read_text(encoding='utf-8')
        except UnicodeDecodeError:
            # äºŒè¿›åˆ¶æ–‡ä»¶
            return "[Binary file - content not displayed]"
        except Exception as e:
            return f"[Error reading file: {e}]"
    
    def _detect_language(self, file_path: Path) -> str:
        """æ£€æµ‹æ–‡ä»¶è¯­è¨€"""
        ext = file_path.suffix.lower()
        language_map = {
            '.java': 'java',
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.jsx': 'jsx',
            '.tsx': 'tsx',
            '.md': 'markdown',
            '.yml': 'yaml',
            '.yaml': 'yaml',
            '.json': 'json',
            '.xml': 'xml',
            '.html': 'html',
            '.css': 'css',
            '.sh': 'bash',
            '.sql': 'sql',
        }
        return language_map.get(ext, 'text')


# =============================================================================
# å†…å®¹ç”Ÿæˆå™¨
# =============================================================================

class ContentGenerator:
    """MDX å†…å®¹ç”Ÿæˆå™¨"""
    
    def __init__(self, chapters_dir: Path, shared_dir: Path, logger: logging.Logger):
        self.chapters_dir = chapters_dir
        self.shared_dir = shared_dir
        self.logger = logger
        self.yaml_parser = YAMLParser(logger)
        self.code_collector = CodeCollector(logger)
    
    # -------------------------------------------------------------------------
    # æ¯å‘¨é¡µé¢ç”Ÿæˆ
    # -------------------------------------------------------------------------
    
    def generate_week_index(self, week: WeekInfo) -> str:
        """ç”Ÿæˆå‘¨ä¸»é¡µ index.mdx"""
        lines = [
            '---',
            f'title: "Week {week.number:02d}: {week.title}"',
            f'sidebar_position: {week.number}',
            f'slug: /weeks/{week.number:02d}',
            f'tags: ["week-{week.number:02d}", "{self._get_phase_tag(week.phase_label)}"]',
            '---',
            '',
            f'# Week {week.number:02d}: {week.title}',
            '',
            f'**é˜¶æ®µ**ï¼š{week.phase_label}',
            '',
            '## æœ¬å‘¨å†…å®¹',
            '',
        ]
        
        # æ·»åŠ é“¾æ¥åˆ—è¡¨
        links = [
            ('è®²ä¹‰', './chapter.mdx', week.has_chapter),
            ('ä½œä¸š', './assignment.mdx', week.has_assignment),
            ('è¯„åˆ†æ ‡å‡†', './rubric.mdx', week.has_rubric),
            ('ä»£ç ', './code.mdx', week.has_examples or week.has_starter_code or week.has_tests),
            ('é”šç‚¹', './anchors.mdx', week.has_anchors),
            ('æœ¯è¯­', './terms.mdx', week.has_terms),
        ]

        for label, link, exists in links:
            if exists:
                lines.append(f'- [{label}]({link})')
            else:
                lines.append(f'- ~~{label}~~ *(æœªæä¾›)*')
        
        lines.append('')
        return '\n'.join(lines)
    
    def generate_chapter(self, week: WeekInfo) -> str:
        """ç”Ÿæˆè®²ä¹‰é¡µé¢ chapter.mdx"""
        chapter_path = self.chapters_dir / f'week_{week.number:02d}' / 'CHAPTER.md'
        
        lines = [
            '---',
            f'title: "Week {week.number:02d}: {week.title} - è®²ä¹‰"',
            f'sidebar_position: 1',
            f'tags: ["week-{week.number:02d}", "chapter"]',
            '---',
            '',
        ]
        
        if chapter_path.exists():
            content = chapter_path.read_text(encoding='utf-8')
            # ç§»é™¤åŸæœ‰çš„ frontmatter
            content = self._escape_mdx_content(self._remove_frontmatter(content))
            lines.append(content)
        else:
            lines.extend([
                f'# Week {week.number:02d}: {week.title}',
                '',
                '> âš ï¸ æœ¬å‘¨è®²ä¹‰å†…å®¹æ­£åœ¨å‡†å¤‡ä¸­...',
                '',
            ])
        
        return '\n'.join(lines)
    
    def generate_assignment(self, week: WeekInfo) -> str:
        """ç”Ÿæˆä½œä¸šé¡µé¢ assignment.mdx"""
        assignment_path = self.chapters_dir / f'week_{week.number:02d}' / 'ASSIGNMENT.md'
        
        lines = [
            '---',
            f'title: "Week {week.number:02d}: {week.title} - ä½œä¸š"',
            f'sidebar_position: 2',
            f'tags: ["week-{week.number:02d}", "assignment"]',
            '---',
            '',
        ]
        
        if assignment_path.exists():
            content = assignment_path.read_text(encoding='utf-8')
            content = self._escape_mdx_content(self._remove_frontmatter(content))
            lines.append(content)
        else:
            lines.extend([
                f'# Week {week.number:02d}: {week.title} - ä½œä¸š',
                '',
                '> âš ï¸ æœ¬å‘¨ä½œä¸šå†…å®¹æ­£åœ¨å‡†å¤‡ä¸­...',
                '',
                'è¯·ç¨åæŸ¥çœ‹æ›´æ–°ã€‚',
                '',
            ])
        
        return '\n'.join(lines)
    
    def generate_rubric(self, week: WeekInfo) -> str:
        """ç”Ÿæˆè¯„åˆ†æ ‡å‡†é¡µé¢ rubric.mdx"""
        rubric_path = self.chapters_dir / f'week_{week.number:02d}' / 'RUBRIC.md'
        
        lines = [
            '---',
            f'title: "Week {week.number:02d}: {week.title} - è¯„åˆ†æ ‡å‡†"',
            f'sidebar_position: 3',
            f'tags: ["week-{week.number:02d}", "rubric"]',
            '---',
            '',
        ]
        
        if rubric_path.exists():
            content = rubric_path.read_text(encoding='utf-8')
            content = self._escape_mdx_content(self._remove_frontmatter(content))
            lines.append(content)
        else:
            lines.extend([
                f'# Week {week.number:02d}: {week.title} - è¯„åˆ†æ ‡å‡†',
                '',
                '> âš ï¸ æœ¬å‘¨è¯„åˆ†æ ‡å‡†æ­£åœ¨å‡†å¤‡ä¸­...',
                '',
                'è¯·ç¨åæŸ¥çœ‹æ›´æ–°ã€‚',
                '',
            ])
        
        return '\n'.join(lines)
    
    def generate_code(self, week: WeekInfo) -> str:
        """ç”Ÿæˆä»£ç é¡µé¢ code.mdx"""
        week_dir = self.chapters_dir / f'week_{week.number:02d}'
        code_files = self.code_collector.collect_files(week_dir)
        
        lines = [
            '---',
            f'title: "Week {week.number:02d}: {week.title} - ä»£ç "',
            f'sidebar_position: 4',
            f'tags: ["week-{week.number:02d}", "code"]',
            '---',
            '',
            f'# Week {week.number:02d}: {week.title} - ä»£ç ',
            '',
            'import Tabs from "@theme/Tabs";',
            'import TabItem from "@theme/TabItem";',
            '',
        ]
        
        has_any_code = any(code_files.values())
        
        if not has_any_code:
            lines.extend([
                '> âš ï¸ æœ¬å‘¨æš‚æ— ä»£ç ç¤ºä¾‹',
                '',
            ])
            return '\n'.join(lines)
        
        lines.extend([
            '<Tabs>',
            '',
        ])
        
        # Examples Tab
        lines.extend(self._generate_code_tab('Examples', code_files['examples'], 'examples'))
        
        # Starter Code Tab
        lines.extend(self._generate_code_tab('Starter Code', code_files['starter_code'], 'starter_code'))
        
        # Tests Tab
        lines.extend(self._generate_code_tab('Tests', code_files['tests'], 'tests'))
        
        lines.extend([
            '</Tabs>',
            '',
        ])
        
        return '\n'.join(lines)
    
    def _generate_code_tab(self, label: str, files: list[dict], tab_value: str) -> list[str]:
        """ç”Ÿæˆä»£ç  Tab å†…å®¹"""
        lines = [
            f'<TabItem value="{tab_value}" label="{label}">',
            '',
        ]
        
        if not files:
            lines.extend([
                f'_{label} æš‚æ— å†…å®¹_',
                '',
            ])
        else:
            # æ–‡ä»¶æ ‘
            lines.extend([
                '## æ–‡ä»¶åˆ—è¡¨',
                '',
            ])
            
            for file_info in files:
                lines.append(f'- `{file_info["path"]}`')
            
            lines.append('')
            
            # ä»£ç å†…å®¹
            lines.append('## ä»£ç å†…å®¹')
            lines.append('')
            
            for file_info in files:
                # å¯¹ä»£ç å—å†…å®¹ä¸­çš„ MDX æ•æ„Ÿå­—ç¬¦è¿›è¡Œè½¬ä¹‰
                content = self._escape_mdx_content(file_info['content'])
                
                # å¦‚æœå†…å®¹åŒ…å« ```ï¼Œä½¿ç”¨æ›´é•¿çš„å›´æ é¿å…åµŒå¥—é—®é¢˜
                if '```' in content:
                    fence = '````'
                else:
                    fence = '```'
                
                lines.extend([
                    f'### {file_info["path"]}',
                    '',
                    f'{fence}{file_info["language"]}',
                    content,
                    fence,
                    '',
                ])
        
        lines.extend([
            '</TabItem>',
            '',
        ])
        
        return lines
    
    def generate_anchors(self, week: WeekInfo) -> str:
        """ç”Ÿæˆé”šç‚¹é¡µé¢ anchors.mdx"""
        anchors_path = self.chapters_dir / f'week_{week.number:02d}' / 'ANCHORS.yml'
        anchors = self.yaml_parser.parse_anchors(anchors_path)
        
        lines = [
            '---',
            f'title: "Week {week.number:02d}: {week.title} - é”šç‚¹"',
            f'sidebar_position: 5',
            f'tags: ["week-{week.number:02d}", "anchors"]',
            '---',
            '',
            f'# Week {week.number:02d}: {week.title} - é”šç‚¹',
            '',
        ]
        
        if not anchors:
            lines.extend([
                '> âš ï¸ æœ¬å‘¨æš‚æ— é”šç‚¹è®°å½•',
                '',
            ])
            return '\n'.join(lines)
        
        lines.extend([
            '| ID | ä¸»å¼  | è¯æ® | éªŒè¯æ–¹å¼ | çŠ¶æ€ |',
            '|------|------|------|----------|------|',
        ])
        
        for anchor in anchors:
            # æˆªæ–­é•¿æ–‡æœ¬å¹¶è½¬ä¹‰ MDX
            claim = self._escape_inline_text(self._truncate_text(anchor.claim, 50))
            evidence = self._escape_inline_text(self._truncate_text(anchor.evidence, 50))
            verification = self._escape_inline_text(self._truncate_text(anchor.verification, 30))
            
            # çŠ¶æ€å¾½ç« 
            status_badge = self._get_status_badge(anchor.status)
            
            lines.append(f'| `{anchor.id}` | {claim} | {evidence} | {verification} | {status_badge} |')
        
        lines.append('')
        
        # æ·»åŠ è¯¦ç»†åˆ—è¡¨
        lines.extend([
            '## è¯¦ç»†å†…å®¹',
            '',
        ])
        
        for anchor in anchors:
            claim = self._escape_inline_text(anchor.claim)
            evidence = self._escape_inline_text(anchor.evidence)
            verification = self._escape_inline_text(anchor.verification)
            
            lines.extend([
                f'### {anchor.id}',
                '',
                f'**ä¸»å¼ **: {claim}',
                '',
                f'**è¯æ®**: {evidence}',
                '',
                f'**éªŒè¯æ–¹å¼**: {verification}',
                '',
                f'**çŠ¶æ€**: {anchor.status}',
                '',
            ])
        
        return '\n'.join(lines)
    
    def generate_terms(self, week: WeekInfo) -> str:
        """ç”Ÿæˆæœ¯è¯­é¡µé¢ terms.mdx"""
        terms_path = self.chapters_dir / f'week_{week.number:02d}' / 'TERMS.yml'
        terms = self.yaml_parser.parse_terms(terms_path)
        
        lines = [
            '---',
            f'title: "Week {week.number:02d}: {week.title} - æœ¯è¯­"',
            f'sidebar_position: 6',
            f'tags: ["week-{week.number:02d}", "terms"]',
            '---',
            '',
            f'# Week {week.number:02d}: {week.title} - æœ¯è¯­',
            '',
        ]
        
        if not terms:
            lines.extend([
                '> âš ï¸ æœ¬å‘¨æš‚æ— æœ¯è¯­å®šä¹‰',
                '',
            ])
            return '\n'.join(lines)
        
        lines.extend([
            '| ä¸­æ–‡ | è‹±æ–‡ | å®šä¹‰ |',
            '|------|------|------|',
        ])
        
        for term in terms:
            definition = self._escape_inline_text(self._truncate_text(term.definition, 80))
            lines.append(f'| {term.chinese} | {term.english} | {definition} |')
        
        lines.append('')

        return '\n'.join(lines)
    
    # -------------------------------------------------------------------------
    # å…¨å±€é¡µé¢ç”Ÿæˆ
    # -------------------------------------------------------------------------
    
    def generate_index(self, repo_root: Path) -> str:
        """ç”Ÿæˆé¦–é¡µ index.mdx"""
        readme_path = repo_root / 'README.md'
        
        lines = [
            '---',
            'title: "é¦–é¡µ"',
            'sidebar_position: 0',
            'slug: /',
            '---',
            '',
        ]
        
        if readme_path.exists():
            content = readme_path.read_text(encoding='utf-8')
            content = self._escape_mdx_content(self._remove_frontmatter(content))
            lines.append(content)
        else:
            lines.extend([
                '# Java è½¯ä»¶å·¥ç¨‹',
                '',
                'æ¬¢è¿æ¥åˆ° Java è½¯ä»¶å·¥ç¨‹è¯¾ç¨‹æ–‡æ¡£ç«™ç‚¹ï¼',
                '',
                '## è¯¾ç¨‹ç»“æ„',
                '',
                '- **é˜¶æ®µä¸€ï¼šæ€ç»´å¥ åŸº**ï¼ˆWeek 01-04ï¼‰',
                '- **é˜¶æ®µäºŒï¼šç³»ç»ŸåŒ–å·¥ç¨‹**ï¼ˆWeek 05-08ï¼‰',
                '- **é˜¶æ®µä¸‰ï¼šAI æ—¶ä»£çš„å·¥ç¨‹**ï¼ˆWeek 09-12ï¼‰',
                '- **é˜¶æ®µå››ï¼šç»¼åˆå®æˆ˜**ï¼ˆWeek 13-16ï¼‰',
                '',
            ])
        
        return '\n'.join(lines)
    
    def generate_syllabus(self) -> str:
        """ç”Ÿæˆæ•™å­¦å¤§çº²é¡µé¢ syllabus.mdx"""
        syllabus_path = self.chapters_dir / 'SYLLABUS.md'
        
        lines = [
            '---',
            'title: "æ•™å­¦å¤§çº²"',
            'sidebar_position: 100',
            '---',
            '',
        ]
        
        if syllabus_path.exists():
            content = syllabus_path.read_text(encoding='utf-8')
            content = self._escape_mdx_content(self._remove_frontmatter(content))
            lines.append(content)
        else:
            lines.extend([
                '# æ•™å­¦å¤§çº²',
                '',
                '> âš ï¸ æ•™å­¦å¤§çº²æ­£åœ¨å‡†å¤‡ä¸­...',
                '',
            ])
        
        return '\n'.join(lines)
    
    def generate_campusflow(self) -> str:
        """ç”Ÿæˆ CampusFlow é¡¹ç›®é¡µé¢ campusflow.mdx"""
        project_path = self.shared_dir / 'book_project.md'
        
        lines = [
            '---',
            'title: "CampusFlow é¡¹ç›®"',
            'sidebar_position: 101',
            '---',
            '',
        ]
        
        if project_path.exists():
            content = project_path.read_text(encoding='utf-8')
            content = self._escape_mdx_content(self._remove_frontmatter(content))
            lines.append(content)
        else:
            lines.extend([
                '# CampusFlow é¡¹ç›®',
                '',
                '> âš ï¸ é¡¹ç›®æ–‡æ¡£æ­£åœ¨å‡†å¤‡ä¸­...',
                '',
            ])
        
        return '\n'.join(lines)
    
    def generate_glossary(self) -> str:
        """ç”Ÿæˆæœ¯è¯­è¡¨é¡µé¢ glossary.mdx"""
        glossary_path = self.shared_dir / 'glossary.yml'
        terms = self.yaml_parser.parse_terms(glossary_path)
        
        lines = [
            '---',
            'title: "æœ¯è¯­è¡¨"',
            'sidebar_position: 102',
            '---',
            '',
            '# æœ¯è¯­è¡¨',
            '',
        ]
        
        if not terms:
            lines.extend([
                '> âš ï¸ æœ¯è¯­è¡¨æ­£åœ¨å‡†å¤‡ä¸­...',
                '',
            ])
            return '\n'.join(lines)
        
        # æŒ‰é¦–å­—æ¯åˆ†ç»„
        from collections import defaultdict
        grouped = defaultdict(list)
        
        for term in terms:
            first_char = term.chinese[0].upper() if term.chinese else '#'
            grouped[first_char].append(term)
        
        # å­—æ¯å¯¼èˆªï¼ˆçº¯æ–‡æœ¬ï¼Œä¸ä½¿ç”¨é”šç‚¹é“¾æ¥é¿å… MDX é—®é¢˜ï¼‰
        lines.append('## å¿«é€Ÿå¯¼èˆª')
        lines.append('')

        sorted_chars = sorted(grouped.keys())
        nav_items = []
        for char in sorted_chars:
            nav_items.append(f'**{char}**')
        lines.append(' Â· '.join(nav_items))
        lines.append('')
        
        # å„ç»„å†…å®¹
        for char in sorted(grouped.keys()):
            lines.extend([
                f'## {char}',
                '',
                '| ä¸­æ–‡ | è‹±æ–‡ | å®šä¹‰ |',
                '|------|------|------|',
            ])
            
            for term in sorted(grouped[char], key=lambda x: x.chinese):
                definition = self._truncate_text(term.definition, 100)
                # Wrap content with MDX special chars (<, >, {, }) in backticks to avoid JSX parsing errors
                import re
                # Pattern to match content like ArrayList<String>, /users/{id}, <>
                definition = re.sub(r'([\w/]+\{[^}]+\})', r'`\1`', definition)  # /users/{id}
                definition = re.sub(r'([\w]+<[^>]+>)', r'`\1`', definition)      # ArrayList<String>
                definition = re.sub(r'(<>)', r'`\1`', definition)                # <>
                lines.append(f'| {term.chinese} | {term.english} | {definition} |')
            
            lines.append('')
        
        return '\n'.join(lines)
    
    def generate_style_guide(self) -> str:
        """ç”Ÿæˆé£æ ¼æŒ‡å—é¡µé¢ style-guide.mdx"""
        style_path = self.shared_dir / 'style_guide.md'
        
        lines = [
            '---',
            'title: "é£æ ¼æŒ‡å—"',
            'sidebar_position: 103',
            '---',
            '',
        ]
        
        if style_path.exists():
            content = style_path.read_text(encoding='utf-8')
            content = self._escape_mdx_content(self._remove_frontmatter(content))
            lines.append(content)
        else:
            lines.extend([
                '# é£æ ¼æŒ‡å—',
                '',
                '> âš ï¸ é£æ ¼æŒ‡å—æ­£åœ¨å‡†å¤‡ä¸­...',
                '',
            ])
        
        return '\n'.join(lines)
    
    # -------------------------------------------------------------------------
    # è¾…åŠ©æ–¹æ³•
    # -------------------------------------------------------------------------
    
    def _remove_frontmatter(self, content: str) -> str:
        """ç§»é™¤ Markdown æ–‡ä»¶çš„ frontmatter"""
        if content.startswith('---'):
            parts = content.split('---', 2)
            if len(parts) >= 3:
                return parts[2].strip()
        return content
    
    def _escape_mdx_content(self, content: str) -> str:
        """è½¬ä¹‰ MDX å†…å®¹ä¸­å¯èƒ½è¢«è¯¯è®¤ä¸º JSX æ ‡ç­¾çš„è¯­æ³•"""
        import re
        import uuid

        # ä½¿ç”¨å”¯ä¸€çš„å ä½ç¬¦å‰ç¼€é¿å…å†²çª
        placeholder_prefix = f"__MDX_PROTECTED_{uuid.uuid4().hex[:8]}__"
        placeholders = {}
        placeholder_id = 0

        def make_placeholder():
            nonlocal placeholder_id
            ph = f"{placeholder_prefix}_{placeholder_id}_"
            placeholder_id += 1
            return ph

        # æ­¥éª¤0: é¦–å…ˆä¿æŠ¤ä»£ç å—ï¼ˆ```...```ï¼‰ï¼Œé¿å…ä»£ç å—å†…çš„å†…å®¹è¢«è½¬ä¹‰
        # åŒæ—¶å¯¹ä»£ç å—å†…çš„ URL è¿›è¡Œç‰¹æ®Šå¤„ç†ä»¥é¿å… MDX è§£æé—®é¢˜
        def protect_code_blocks(text):
            result = []
            i = 0
            while i < len(text):
                # æŸ¥æ‰¾ä»£ç å—å¼€å§‹
                if text[i:i+3] == '```':
                    # æ‰¾åˆ°ä»£ç å—ç»“æŸ
                    end_idx = text.find('\n```', i + 3)
                    if end_idx == -1:
                        # æ²¡æœ‰æ‰¾åˆ°ç»“æŸï¼Œä¿æŒåŸæ ·
                        result.append(text[i:])
                        break
                    # åŒ…å«ç»“æŸçš„ ```
                    end_idx = end_idx + 4
                    code_block = text[i:end_idx]
                    placeholder = make_placeholder()
                    # å­˜å‚¨åŸå§‹ä»£ç å—ç”¨äºæ¢å¤
                    placeholders[placeholder] = code_block
                    result.append(placeholder)
                    i = end_idx
                else:
                    result.append(text[i])
                    i += 1
            return ''.join(result)

        content = protect_code_blocks(content)
        self.logger.debug(f"After code block protection: {len(placeholders)} placeholders")

        # ä¿æŠ¤åˆæ³•çš„ MDX ç»„ä»¶å’Œ HTML æ ‡ç­¾ï¼ˆè¿™äº›ä¸åº”è¯¥è¢«è½¬ä¹‰ï¼‰
        protected_tags = ['Tabs', 'TabItem', 'details', 'summary', 'br', 'code', 'pre', 'kbd', 'sub', 'sup']

        # æ­¥éª¤0.5: ä¿æŠ¤å†…è”ä»£ç ï¼ˆ`...`ï¼‰ï¼Œé¿å…å†…è”ä»£ç å†…çš„å†…å®¹è¢«è½¬ä¹‰
        # åŒ¹é…å•ä¸ªåå¼•å·åŒ…å›´çš„å†…å®¹ï¼ˆä¸æ˜¯ä»£ç å—ï¼‰
        inline_code_pattern = r'(?<!`)`(?!`)([^`\n]+)(?<!`)`(?!`)'
        matches = list(re.finditer(inline_code_pattern, content))
        for match in reversed(matches):
            placeholder = make_placeholder()
            placeholders[placeholder] = match.group(0)
            content = content[:match.start()] + placeholder + content[match.end():]

        # æ­¥éª¤1: ä¿æŠ¤åˆæ³•çš„ MDX ç»„ä»¶ï¼Œç”¨å ä½ç¬¦æ›¿æ¢
        # ä½¿ç”¨åˆ—è¡¨å­˜å‚¨æ›¿æ¢ä¿¡æ¯ï¼Œé¿å…åœ¨è¿­ä»£æ—¶ä¿®æ”¹å­—ç¬¦ä¸²
        for tag in protected_tags:
            # åŒ¹é… <Tag ...>...</Tag>ï¼ˆåŒ…æ‹¬è·¨è¡Œçš„ï¼‰
            pattern = rf'<{tag}\b[^>]*>.*?</{tag}>'
            matches = list(re.finditer(pattern, content, re.DOTALL))
            for match in reversed(matches):  # ä»åå¾€å‰æ›¿æ¢ï¼Œé¿å…ä½ç½®åç§»
                placeholder = make_placeholder()
                placeholders[placeholder] = match.group(0)
                content = content[:match.start()] + placeholder + content[match.end():]
            
            # åŒ¹é…è‡ªé—­åˆ <Tag ... /> æˆ– <Tag>
            pattern = rf'<{tag}\b[^>]*/>'
            matches = list(re.finditer(pattern, content))
            for match in reversed(matches):
                placeholder = make_placeholder()
                placeholders[placeholder] = match.group(0)
                content = content[:match.start()] + placeholder + content[match.end():]
            
            # åŒ¹é… <Tag>ï¼ˆè‡ªé—­åˆä½†æ²¡æœ‰æ–œæ ï¼Œå¦‚ <br>, <hr>ï¼‰
            pattern = rf'<{tag}\b[^<>]*>'
            matches = list(re.finditer(pattern, content))
            for match in reversed(matches):
                placeholder = make_placeholder()
                placeholders[placeholder] = match.group(0)
                content = content[:match.start()] + placeholder + content[match.end():]
        
        # æ­¥éª¤2: ä¿æŠ¤å·²çŸ¥çš„åˆæ³• HTML æ ‡ç­¾ï¼ˆè¿™äº›ä¸åº”è¯¥è¢«è½¬ä¹‰ï¼‰
        html_tags = {'div', 'span', 'p', 'a', 'img', 'table', 'tr', 'td', 'th', 'thead', 'tbody',
                     'ul', 'ol', 'li', 'h1', 'h2', 'h3', 'h4', 'h5', 'h6', 'strong', 'em',
                     'b', 'i', 'u', 's', 'del', 'ins', 'iframe', 'video', 'audio', 'source',
                     'input', 'form', 'button', 'label', 'select', 'option', 'hr', 'small'}
        
        for tag in html_tags:
            # åŒ¹é… <tag ...>...</tag>
            pattern = rf'<{tag}\b[^>]*>.*?</{tag}>'
            matches = list(re.finditer(pattern, content, re.DOTALL))
            for match in reversed(matches):
                placeholder = make_placeholder()
                placeholders[placeholder] = match.group(0)
                content = content[:match.start()] + placeholder + content[match.end():]
            
            # åŒ¹é… <tag ... />
            pattern = rf'<{tag}\b[^>]*/>'
            matches = list(re.finditer(pattern, content))
            for match in reversed(matches):
                placeholder = make_placeholder()
                placeholders[placeholder] = match.group(0)
                content = content[:match.start()] + placeholder + content[match.end():]
            
            # åŒ¹é… <tag>ï¼ˆè‡ªé—­åˆä½†æ²¡æœ‰æ–œæ ï¼‰
            pattern = rf'<{tag}\b[^<>]*>'
            matches = list(re.finditer(pattern, content))
            for match in reversed(matches):
                placeholder = make_placeholder()
                placeholders[placeholder] = match.group(0)
                content = content[:match.start()] + placeholder + content[match.end():]
        
        # æ­¥éª¤3: è½¬ä¹‰çœ‹èµ·æ¥åƒ JSX/æ³›å‹çš„æ ‡ç­¾
        # æ³¨æ„ï¼šæ­¤æ—¶æ‰€æœ‰åˆæ³•æ ‡ç­¾å·²ç»è¢«å ä½ç¬¦ä¿æŠ¤
        
        # 3.1 è½¬ä¹‰ç©ºå°–æ‹¬å· <>ï¼ˆè±å½¢æ“ä½œç¬¦ï¼‰
        content = re.sub(r'(?<!&)<>', '&lt;&gt;', content)
        
        # 3.2 è½¬ä¹‰æ³›å‹ç±»å‹å‚æ•° <T, K>ã€<String, Integer> ç­‰
        # åŒ¹é… <å­—æ¯,å­—æ¯> æˆ– <å­—æ¯, å­—æ¯> ç­‰å½¢å¼
        def escape_generic(match):
            inner = match.group(1)
            # å¦‚æœå†…éƒ¨åŒ…å«é€—å·ï¼Œä¸”çœ‹èµ·æ¥åƒç±»å‹å‚æ•°ï¼Œåˆ™è½¬ä¹‰
            return f'&lt;{inner}&gt;'
        
        # åŒ¹é… <Type1, Type2> æˆ– <T, K extends Something> ç­‰å½¢å¼
        content = re.sub(r'<([A-Za-z][A-Za-z0-9_]*\s*,\s*[A-Za-z][^>]*)>', escape_generic, content)
        
        # 3.3 è½¬ä¹‰å•ä¸ªæ³›å‹å‚æ•° <String>ã€<Integer>ã€<6> ç­‰
        def escape_single_tag(match):
            tag = match.group(1)
            # ä»»ä½•çœ‹èµ·æ¥åƒæ ‡ç­¾çš„å†…å®¹éƒ½è½¬ä¹‰
            return f'&lt;{tag}&gt;'
        
        # åŒ¹é… <Word> å½¢å¼çš„æ ‡ç­¾ï¼ˆåŒ…æ‹¬ <6> è¿™ç§æ•°å­—å½¢å¼ï¼‰
        content = re.sub(r'<([A-Za-z0-9_]+)>', escape_single_tag, content)
        
        # 3.4 è½¬ä¹‰æ¯”è¾ƒè¡¨è¾¾å¼ä¸­çš„ <æ•°å­—ï¼ˆå¦‚ <60 åˆ†ï¼‰
        # åŒ¹é… <æ•°å­— åè·Ÿéå­—æ¯æ•°å­—å­—ç¬¦çš„æƒ…å†µ
        def escape_comparison(match):
            return f'&lt;{match.group(1)}'
        
        content = re.sub(r'<(\d+)(?=[^\d>])', escape_comparison, content)
        
        # 3.4b è½¬ä¹‰æ¯”è¾ƒè¿ç®—ç¬¦ <= å’Œ >=
        content = re.sub(r'<=', '&lt;=', content)
        content = re.sub(r'>=', '&gt;=', content)
        
        # 3.5 è½¬ä¹‰é—­åˆæ ‡ç­¾ </Word>
        content = re.sub(r'</([A-Za-z0-9_]+)>', lambda m: f'&lt;/{m.group(1)}&gt;', content)
        
        # 3.6 è½¬ä¹‰ ${...} æ ¼å¼çš„ shell å˜é‡/å ä½ç¬¦ï¼Œé¿å…è¢«å½“ä½œ JSX è¡¨è¾¾å¼
        # æ‰€æœ‰ ${...} æ ¼å¼éƒ½è½¬ä¹‰ï¼ˆå®ƒä»¬é€šå¸¸æ˜¯ shell å˜é‡ï¼Œä¸æ˜¯ JS è¡¨è¾¾å¼ï¼‰
        # ä½¿ç”¨ HTML å®ä½“è½¬ä¹‰ { å’Œ }
        def escape_shell_var(match):
            var_content = match.group(1)
            # è½¬ä¹‰ $ { } ä¸º HTML å®ä½“
            return f'&#36;&#123;{var_content}&#125;'
        
        content = re.sub(r'\$\{([^}]+)\}', escape_shell_var, content)
        
        # 3.7 è½¬ä¹‰ REST API è·¯å¾„å‚æ•° {id}, {taskId} ç­‰
        # è¿™äº›ä¼šè¢«è¯¯è®¤ä¸º JSX è¡¨è¾¾å¼
        # åŒ¹é… {word} æ ¼å¼ï¼Œä½†æ’é™¤çº¯æ•°å­—ï¼ˆå¦‚ {1} å¯èƒ½æ˜¯åˆæ³•å¯¹è±¡å­—é¢é‡ï¼‰
        def escape_path_param(match):
            inner = match.group(1)
            # å¦‚æœæ˜¯çº¯æ•°å­—ï¼Œä¸è½¬ä¹‰ï¼ˆå¯èƒ½æ˜¯å¯¹è±¡å­—é¢é‡ï¼‰
            if inner.isdigit():
                return match.group(0)
            # å…¶ä»–æƒ…å†µè½¬ä¹‰
            return f'\\{{{inner}}}'
        
        # åŒ¹é…ç®€å•çš„ {identifier} æ ¼å¼ï¼ˆä¸åŒ…æ‹¬å†’å·ï¼Œé¿å…åŒ¹é… {PORT:8080} è¿™ç§ shell å˜é‡é»˜è®¤å€¼è¯­æ³•ï¼‰
        content = re.sub(r'\{([a-zA-Z_][a-zA-Z0-9_]*)\}', escape_path_param, content)
        
        # æ­¥éª¤4: æ¢å¤ä¿æŠ¤çš„æ ‡ç­¾
        # ä»åå¾€å‰æ¢å¤ï¼Œé¿å…åµŒå¥—é—®é¢˜
        for placeholder in sorted(placeholders.keys(), reverse=True):
            original = placeholders[placeholder]
            content = content.replace(placeholder, original)

        # æ­¥éª¤4.5: å¯¹ä»£ç å—å†…çš„ URL è¿›è¡Œè½¬ä¹‰ï¼Œé¿å… MDX çš„ URL è§£æé—®é¢˜
        # Docusaurus/MDX åœ¨æŸäº›æƒ…å†µä¸‹ä¼šå°è¯•è§£æä»£ç å—å†…çš„ URLï¼Œå¯¼è‡´é”™è¯¯
        # ä½¿ç”¨é›¶å®½æ–­è¨€æ¥åŒ¹é…ä»£ç å—å†…çš„ http:// å’Œ https://
        def escape_urls_in_code_blocks(text):
            result = []
            i = 0
            while i < len(text):
                if text[i:i+3] == '```':
                    # æ‰¾åˆ°ä»£ç å—ç»“æŸ
                    end_idx = text.find('\n```', i + 3)
                    if end_idx == -1:
                        result.append(text[i:])
                        break
                    end_idx = end_idx + 4
                    code_block = text[i:end_idx]
                    # è½¬ä¹‰ URL ä¸­çš„å†’å·
                    code_block = code_block.replace('http://', 'http&#58;//')
                    code_block = code_block.replace('https://', 'https&#58;//')
                    result.append(code_block)
                    i = end_idx
                else:
                    result.append(text[i])
                    i += 1
            return ''.join(result)

        content = escape_urls_in_code_blocks(content)

        # æ­¥éª¤5: ç¡®ä¿è‡ªé—­åˆæ ‡ç­¾ä½¿ç”¨æ­£ç¡®çš„æ ¼å¼ï¼ˆ<br /> è€Œä¸æ˜¯ <br>ï¼‰
        # è¿™åœ¨ MDX è¡¨æ ¼ä¸­ç‰¹åˆ«é‡è¦
        self_closing_tags = ['br', 'hr', 'img', 'input', 'meta', 'link', 'area', 'base', 'col', 
                            'embed', 'param', 'source', 'track', 'wbr']
        for tag in self_closing_tags:
            # å°† <tag> è½¬æ¢ä¸º <tag />ï¼Œä½†é¿å…é‡å¤è½¬æ¢ <tag />
            content = re.sub(rf'<{tag}\b([^<>]*[^/])?>', rf'<{tag}\1 />', content)
            content = re.sub(rf'<{tag}\b\s*/\s*>', rf'<{tag} />', content)  # æ ‡å‡†åŒ–å·²æœ‰æ–œæ çš„æ ¼å¼
        
        return content
    
    def _get_phase_tag(self, phase_label: str) -> str:
        """è·å–é˜¶æ®µæ ‡ç­¾"""
        if 'é˜¶æ®µä¸€' in phase_label:
            return 'phase-1'
        elif 'é˜¶æ®µäºŒ' in phase_label:
            return 'phase-2'
        elif 'é˜¶æ®µä¸‰' in phase_label:
            return 'phase-3'
        elif 'é˜¶æ®µå››' in phase_label:
            return 'phase-4'
        return 'phase-unknown'
    
    def _truncate_text(self, text: str, max_length: int) -> str:
        """æˆªæ–­é•¿æ–‡æœ¬"""
        if len(text) <= max_length:
            return text
        return text[:max_length - 3] + '...'
    
    def _get_status_badge(self, status: str) -> str:
        """è·å–çŠ¶æ€å¾½ç« """
        status_map = {
            'verified': 'âœ… å·²éªŒè¯',
            'pending': 'â³ å¾…éªŒè¯',
            'failed': 'âŒ å¤±è´¥',
            'draft': 'ğŸ“ è‰ç¨¿',
        }
        return status_map.get(status.lower(), status)
    
    def _escape_inline_text(self, text: str) -> str:
        """è½¬ä¹‰å†…è”æ–‡æœ¬ä¸­çš„ MDX æ•æ„Ÿå­—ç¬¦ï¼ˆç”¨äºè¡¨æ ¼ç­‰å†…è”ç¯å¢ƒï¼‰"""
        import re
        import uuid
        
        # åˆæ³•çš„ HTML æ ‡ç­¾ï¼ˆè¿™äº›ä¸åº”è¯¥è¢«è½¬ä¹‰ï¼‰
        html_tags = {'br', 'hr', 'img', 'input', 'meta', 'link', 'area', 'base', 'col', 
                     'embed', 'param', 'source', 'track', 'wbr'}
        
        # ä½¿ç”¨å ä½ç¬¦ä¿æŠ¤åˆæ³•æ ‡ç­¾
        placeholder_prefix = f"__HTML_{uuid.uuid4().hex[:6]}__"
        placeholders = {}
        placeholder_id = 0
        
        def make_placeholder():
            nonlocal placeholder_id
            ph = f"{placeholder_prefix}_{placeholder_id}_"
            placeholder_id += 1
            return ph
        
        # ä¿æŠ¤åˆæ³•çš„è‡ªé—­åˆ HTML æ ‡ç­¾ <tag> æˆ– <tag />
        for tag in html_tags:
            # åŒ¹é… <tag> æˆ– <tag />
            pattern = rf'<{tag}\s*/?>'
            matches = list(re.finditer(pattern, text, re.IGNORECASE))
            for match in reversed(matches):
                placeholder = make_placeholder()
                placeholders[placeholder] = match.group(0)
                text = text[:match.start()] + placeholder + text[match.end():]
        
        # è½¬ä¹‰ç©ºå°–æ‹¬å· <>
        text = re.sub(r'<>', '&lt;&gt;', text)
        
        # è½¬ä¹‰æ³›å‹ç±»å‹ <String>, <Integer> ç­‰
        def escape_tag(match):
            tag = match.group(1)
            return f'&lt;{tag}&gt;'
        
        text = re.sub(r'<([A-Za-z0-9_]+)>', escape_tag, text)
        
        # è½¬ä¹‰æ¯”è¾ƒè¡¨è¾¾å¼ <60 ç­‰
        text = re.sub(r'<(\d+)(?=[^\d>])', lambda m: f'&lt;{m.group(1)}', text)
        
        # è½¬ä¹‰ REST API è·¯å¾„å‚æ•° {id}, {taskId} ç­‰
        def escape_path_param(match):
            inner = match.group(1)
            if inner.isdigit():
                return match.group(0)
            return f'\\{{{inner}}}'
        
        text = re.sub(r'\{([a-zA-Z_][a-zA-Z0-9_]*)\}', escape_path_param, text)
        
        # æ¢å¤ä¿æŠ¤çš„ HTML æ ‡ç­¾
        for placeholder in sorted(placeholders.keys(), reverse=True):
            text = text.replace(placeholder, placeholders[placeholder])
        
        return text


# =============================================================================
# Sidebars ç”Ÿæˆå™¨
# =============================================================================

class SidebarsGenerator:
    """sidebars.ts ç”Ÿæˆå™¨"""
    
    def __init__(self, logger: logging.Logger):
        self.logger = logger
    
    def generate(self, phases: list[PhaseInfo]) -> str:
        """ç”Ÿæˆ sidebars.ts å†…å®¹"""
        lines = [
            '/**',
            ' * Copyright (c) CampusFlow Authors.',
            ' *',
            ' * This source code is licensed under the MIT license.',
            ' */',
            '',
            'import type {SidebarsConfig} from \'@docusaurus/plugin-content-docs\';',
            '',
            'const sidebars: SidebarsConfig = {',
            '  tutorialSidebar: [',
        ]
        
        # æ·»åŠ å„é˜¶æ®µ
        for phase in phases:
            lines.extend(self._generate_phase_section(phase))
        
        # æ·»åŠ å…¨å±€é¡µé¢
        lines.extend([
            '    // å…¨å±€é¡µé¢',
            '    { type: \'doc\', id: \'syllabus\', label: \'æ•™å­¦å¤§çº²\' },',
            '    { type: \'doc\', id: \'campusflow\', label: \'CampusFlow\' },',
            '    { type: \'doc\', id: \'glossary\', label: \'æœ¯è¯­è¡¨\' },',
            '    { type: \'doc\', id: \'style-guide\', label: \'é£æ ¼æŒ‡å—\' },',
            '  ],',
            '};',
            '',
            'export default sidebars;',
            '',
        ])
        
        return '\n'.join(lines)
    
    def _generate_phase_section(self, phase: PhaseInfo) -> list[str]:
        """ç”Ÿæˆé˜¶æ®µéƒ¨åˆ†"""
        lines = [
            f'    // {phase.label}',
            '    {',
            '      type: \'category\',',
            f'      label: \'{phase.label}\',',
            '      collapsed: false,',
            '      items: [',
        ]
        
        for week in phase.weeks:
            lines.extend(self._generate_week_section(week))
        
        lines.extend([
            '      ],',
            '    },',
            '',
        ])
        
        return lines
    
    def _generate_week_section(self, week: WeekInfo) -> list[str]:
        """ç”Ÿæˆå‘¨éƒ¨åˆ†"""
        week_id = f'{week.number:02d}'
        
        lines = [
            '        {',
            '          type: \'category\',',
            f'          label: \'Week {week_id}: {week.title}\',',
            '          collapsed: true,',
            '          items: [',
            f'            {{ type: \'doc\', id: \'weeks/{week_id}/index\', label: \'å‘¨ä¸»é¡µ\' }},',
        ]
        
        # æ ¹æ®å­˜åœ¨çš„æ–‡ä»¶æ·»åŠ é“¾æ¥
        if week.has_chapter:
            lines.append(f'            {{ type: \'doc\', id: \'weeks/{week_id}/chapter\', label: \'è®²ä¹‰\' }},')
        
        if week.has_assignment:
            lines.append(f'            {{ type: \'doc\', id: \'weeks/{week_id}/assignment\', label: \'ä½œä¸š\' }},')
        
        if week.has_rubric:
            lines.append(f'            {{ type: \'doc\', id: \'weeks/{week_id}/rubric\', label: \'è¯„åˆ†æ ‡å‡†\' }},')
        
        # ä»£ç é¡µé¢ï¼ˆåªè¦æœ‰ä»£ç ç›®å½•å°±æ·»åŠ ï¼‰
        if week.has_examples or week.has_starter_code or week.has_tests:
            lines.append(f'            {{ type: \'doc\', id: \'weeks/{week_id}/code\', label: \'ä»£ç \' }},')
        
        if week.has_anchors:
            lines.append(f'            {{ type: \'doc\', id: \'weeks/{week_id}/anchors\', label: \'é”šç‚¹\' }},')
        
        if week.has_terms:
            lines.append(f'            {{ type: \'doc\', id: \'weeks/{week_id}/terms\', label: \'æœ¯è¯­\' }},')

        lines.extend([
            '          ],',
            '        },',
        ])
        
        return lines


# =============================================================================
# ç«™ç‚¹æ„å»ºå™¨
# =============================================================================

class SiteBuilder:
    """Docusaurus ç«™ç‚¹æ„å»ºå™¨"""
    
    def __init__(
        self,
        site_dir: Path,
        chapters_dir: Path,
        shared_dir: Path,
        repo_root: Path,
        logger: logging.Logger
    ):
        self.site_dir = site_dir
        self.chapters_dir = chapters_dir
        self.shared_dir = shared_dir
        self.repo_root = repo_root
        self.logger = logger
        
        self.docs_dir = site_dir / 'docs'
        self.toc_parser = TOCParser(chapters_dir, logger)
        self.content_generator = ContentGenerator(chapters_dir, shared_dir, logger)
        self.sidebars_generator = SidebarsGenerator(logger)
    
    def build(self) -> bool:
        """æ„å»ºç«™ç‚¹"""
        self.logger.info("=" * 60)
        self.logger.info("å¼€å§‹æ„å»º Docusaurus ç«™ç‚¹")
        self.logger.info("=" * 60)
        
        try:
            # 1. è§£æ TOC
            self.logger.info("\n[1/4] è§£æ TOC.md...")
            phases = self.toc_parser.parse()
            self.logger.info(f"  å‘ç° {len(phases)} ä¸ªé˜¶æ®µ")
            
            # 2. åˆ›å»ºç›®å½•ç»“æ„
            self.logger.info("\n[2/4] åˆ›å»ºç›®å½•ç»“æ„...")
            self._create_directory_structure(phases)
            
            # 3. ç”Ÿæˆæ¯å‘¨é¡µé¢
            self.logger.info("\n[3/4] ç”Ÿæˆæ¯å‘¨é¡µé¢...")
            self._generate_week_pages(phases)
            
            # 4. ç”Ÿæˆå…¨å±€é¡µé¢å’Œ sidebars
            self.logger.info("\n[4/4] ç”Ÿæˆå…¨å±€é¡µé¢å’Œ sidebars...")
            self._generate_global_pages()
            self._generate_sidebars(phases)
            
            self.logger.info("\n" + "=" * 60)
            self.logger.info("ç«™ç‚¹æ„å»ºå®Œæˆï¼")
            self.logger.info(f"è¾“å‡ºç›®å½•: {self.site_dir.absolute()}")
            self.logger.info("=" * 60)
            
            return True
            
        except Exception as e:
            self.logger.error(f"æ„å»ºå¤±è´¥: {e}")
            import traceback
            self.logger.debug(traceback.format_exc())
            return False
    
    def _create_directory_structure(self, phases: list[PhaseInfo]) -> None:
        """åˆ›å»ºç›®å½•ç»“æ„"""
        # åˆ›å»º docs ç›®å½•
        self.docs_dir.mkdir(parents=True, exist_ok=True)
        self.logger.info(f"  åˆ›å»ºç›®å½•: {self.docs_dir}")
        
        # ä¸ºæ¯å‘¨åˆ›å»ºç›®å½•
        for phase in phases:
            for week in phase.weeks:
                week_dir = self.docs_dir / 'weeks' / f'{week.number:02d}'
                week_dir.mkdir(parents=True, exist_ok=True)
                self.logger.debug(f"  åˆ›å»ºç›®å½•: {week_dir}")
    
    def _generate_week_pages(self, phases: list[PhaseInfo]) -> None:
        """ç”Ÿæˆæ¯å‘¨é¡µé¢"""
        total_weeks = sum(len(phase.weeks) for phase in phases)
        processed = 0
        
        for phase in phases:
            for week in phase.weeks:
                processed += 1
                self.logger.info(f"  [{processed}/{total_weeks}] Week {week.number:02d}: {week.title}")
                
                week_dir = self.docs_dir / 'weeks' / f'{week.number:02d}'
                
                # ç”Ÿæˆå„é¡µé¢
                self._write_file(week_dir / 'index.mdx', self.content_generator.generate_week_index(week))
                self._write_file(week_dir / 'chapter.mdx', self.content_generator.generate_chapter(week))
                self._write_file(week_dir / 'assignment.mdx', self.content_generator.generate_assignment(week))
                self._write_file(week_dir / 'rubric.mdx', self.content_generator.generate_rubric(week))
                self._write_file(week_dir / 'code.mdx', self.content_generator.generate_code(week))
                self._write_file(week_dir / 'anchors.mdx', self.content_generator.generate_anchors(week))
                self._write_file(week_dir / 'terms.mdx', self.content_generator.generate_terms(week))
    
    def _generate_global_pages(self) -> None:
        """ç”Ÿæˆå…¨å±€é¡µé¢"""
        self.logger.info("  ç”Ÿæˆå…¨å±€é¡µé¢...")
        
        self._write_file(self.docs_dir / 'index.mdx', self.content_generator.generate_index(self.repo_root))
        self._write_file(self.docs_dir / 'syllabus.mdx', self.content_generator.generate_syllabus())
        self._write_file(self.docs_dir / 'campusflow.mdx', self.content_generator.generate_campusflow())
        self._write_file(self.docs_dir / 'glossary.mdx', self.content_generator.generate_glossary())
        self._write_file(self.docs_dir / 'style-guide.mdx', self.content_generator.generate_style_guide())
    
    def _generate_sidebars(self, phases: list[PhaseInfo]) -> None:
        """ç”Ÿæˆ sidebars.ts (ä»…å½“æ–‡ä»¶ä¸å­˜åœ¨æ—¶)"""
        sidebars_path = self.site_dir / 'sidebars.ts'
        # å¦‚æœ sidebars.ts å·²å­˜åœ¨ï¼Œä¸è¦è¦†ç›–å®ƒ
        if sidebars_path.exists():
            self.logger.debug(f"  sidebars.ts å·²å­˜åœ¨ï¼Œè·³è¿‡ç”Ÿæˆ")
            return
        sidebars_content = self.sidebars_generator.generate(phases)
        self._write_file(sidebars_path, sidebars_content)
    
    def _write_file(self, path: Path, content: str) -> None:
        """å†™å…¥æ–‡ä»¶"""
        try:
            path.write_text(content, encoding='utf-8')
            self.logger.debug(f"  å†™å…¥æ–‡ä»¶: {path}")
        except Exception as e:
            self.logger.warning(f"  å†™å…¥æ–‡ä»¶å¤±è´¥: {path} - {e}")


# =============================================================================
# å‘½ä»¤è¡Œå‚æ•°è§£æ
# =============================================================================

def parse_args() -> argparse.Namespace:
    """è§£æå‘½ä»¤è¡Œå‚æ•°"""
    parser = argparse.ArgumentParser(
        description='ä» chapters/ ç›®å½•è‡ªåŠ¨ç”Ÿæˆ Docusaurus ç«™ç‚¹å†…å®¹',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog='''
ç¤ºä¾‹:
    python scripts/build_site.py
    python scripts/build_site.py --verbose
    python scripts/build_site.py --site-dir ./my-site --chapters-dir ./content
        '''
    )
    
    parser.add_argument(
        '--site-dir',
        type=str,
        default='site',
        help='ç«™ç‚¹è¾“å‡ºç›®å½• (é»˜è®¤: site)'
    )
    
    parser.add_argument(
        '--chapters-dir',
        type=str,
        default='chapters',
        help='chapters ç›®å½•è·¯å¾„ (é»˜è®¤: chapters)'
    )
    
    parser.add_argument(
        '--shared-dir',
        type=str,
        default='shared',
        help='shared ç›®å½•è·¯å¾„ (é»˜è®¤: shared)'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='å¯ç”¨è¯¦ç»†è¾“å‡º'
    )
    
    return parser.parse_args()


# =============================================================================
# ä¸»å‡½æ•°
# =============================================================================

def main() -> int:
    """ä¸»å‡½æ•°"""
    args = parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logger = setup_logging(args.verbose)
    
    # è§£æè·¯å¾„
    repo_root = Path.cwd()
    site_dir = repo_root / args.site_dir
    chapters_dir = repo_root / args.chapters_dir
    shared_dir = repo_root / args.shared_dir
    
    # éªŒè¯ç›®å½•å­˜åœ¨
    if not chapters_dir.exists():
        logger.error(f"chapters ç›®å½•ä¸å­˜åœ¨: {chapters_dir}")
        return 1
    
    if not shared_dir.exists():
        logger.warning(f"shared ç›®å½•ä¸å­˜åœ¨: {shared_dir}")
        shared_dir = chapters_dir  # ä½¿ç”¨ chapters ä½œä¸º fallback
    
    # åˆ›å»ºç«™ç‚¹æ„å»ºå™¨
    builder = SiteBuilder(
        site_dir=site_dir,
        chapters_dir=chapters_dir,
        shared_dir=shared_dir,
        repo_root=repo_root,
        logger=logger
    )
    
    # æ„å»ºç«™ç‚¹
    success = builder.build()
    
    return 0 if success else 1


if __name__ == '__main__':
    sys.exit(main())
