# 统计学与 Agentic 数据分析 — 16周教学大纲

> **核心理念**：AI 可以帮你跑统计检验，但不懂业务场景和数据背后的意义，只会得到错误的结论。
> 
> **设计参考**：
> - 课程结构参考（按“从直觉到推断，再到建模与因果”的学习曲线）：
>   - MITx MicroMasters `6.419x Data Analysis: Statistical Modeling and Computation in Applications`（数据分析与计算视角）：[MIT Open Learning](https://openlearning.mit.edu/news/mitx-micromasters-program-statistics-and-data-science-announces-new-data-analysis-elective)
>   - Stanford `STATS 200: Introduction to Statistical Inference`（推断的数学框架）：[Stanford course site](https://web.stanford.edu/class/stats200/index.html)
>   - Harvard `STAT 110: Probability`（概率直觉与计数法）：[STAT 110](https://stat110.hsites.harvard.edu/)
> - 观点参考（用于课程叙事主线）：
>   - **Judea Pearl**：数据本身不说话，因果推断让数据说话
>   - **Andrew Gelman**：模型的检查比模型的拟合更重要
>   - **David Donoho**：数据科学是统计学的延续，不是替代
>   - **Bradley Efron**：不确定性量化与重采样的重要性
>   - **吴恩达**：数据-centric AI，数据质量优先

---

## 课程定位

- **目标学生**：已具备基础 Python 能力（本课程不讲 Python 入门），需要数据分析能力但非统计专业
- **课程时长**：16 周
- **技术栈**：Python + pandas + numpy + scipy + statsmodels + scikit-learn + matplotlib/seaborn
- **项目形式**：个人/小组数据分析报告 + 期末数据故事展示
- **AI 理念**：AI 是分析加速器，但人类负责提问、解释和判断

---

## 设计理念：AI 时代的统计素养

### 统计学大家对 AI 的核心观点（观点概括，避免无出处引语）

**Judea Pearl（因果推断先驱）**：
- 观点概括：相关性不等于因果性；要回答“如果做了/没做会怎样”，需要显式的因果假设与识别策略（如因果图）。

**Andrew Gelman（哥伦比亚大学，贝叶斯统计）**：
- 观点概括：模型拟合之后更重要的是模型检查与诊断；不要迷信单一分数或单一模型。

**David Donoho（斯坦福大学，数据科学教育推动者）**：
- 观点概括：数据科学与统计学高度重叠；关键能力不只在建模，还在数据准备、探索、可视化与可复现分析流程。

**Bradley Efron（Bootstrap 贡献者）**：
- 观点概括：在复杂数据与复杂模型下，不确定性量化仍然是核心；重采样思想为很多场景提供了工程上可行的近似。

**吴恩达（Data-centric AI）**：
- 观点概括：很多真实项目的瓶颈在数据质量与数据流程（收集、标注、清洗、验证），而不在“再换一个更大模型”。

### 本课程的回应

基于以上观点，本课程强调三个核心能力：

1. **因果思维**（不只是相关性）
2. **模型批判**（不只是模型拟合）
3. **数据质量意识**（不只是数据量）

---

## 16 周课程结构

| 阶段 | 周次 | 主题 | 能力目标 |
|------|------|------|----------|
| **阶段一：数据探索基础** | 01-04 | 从数据到问题 | 数据清洗、描述统计、可视化 |
| **阶段二：统计推断** | 05-08 | 从样本到总体 | 假设检验、置信区间、效应量 |
| **阶段三：预测建模** | 09-12 | 从过去到未来 | 回归、分类、模型评估 |
| **阶段四：高级专题** | 13-15 | 从相关到因果 | 因果推断、贝叶斯、大数据统计 |
| **阶段五：综合实战** | 16 | 期末展示 | 完整数据项目展示 |

---

## 阶段一：数据探索基础（Week 01-04）

### Week 01：数据思维入门 —— 从"看数字"到"问问题"

**核心理念**：统计学不是计算，是提问（Andrew Gelman）

**核心内容**：
- 统计学的三个核心问题：描述（Description）、推断（Inference）、预测（Prediction）
- 数据类型：数值型 vs 分类型；连续 vs 离散
- Python 数据工具链：pandas 入门
- 探索性思维：从数据中发现问题，而非只验证假设

**AI 融合**：
- 观察 AI 自动生成数据摘要
- 讨论：AI 生成的描述性统计是否有用？哪些信息被遗漏了？

**实践**：
- 加载真实数据集（Titanic、COVID-19、房价数据等）
- 初步数据探索报告

**贯穿项目**：选择期末项目数据集

---

### Week 02：一页分布报告 —— 从"一个均值"到"看见数据的形状"

**核心理念**：一图胜千言，但错误的图误导万千（Edward Tufte）

**核心内容**：
- 集中趋势：均值、中位数、众数（何时用哪个？）
- 离散程度：标准差、方差、IQR
- 分布形状：偏度、峰度、箱线图
- 可视化原则：诚实、清晰、高效
- matplotlib / seaborn / plotly 基础

**重点强调**：
- 均值 vs 中位数的选择（异常值影响）
- 可视化的误导性（Y轴截断、面积误导）

**AI 融合**：
- AI 自动生成可视化
- 批判性评估：AI 选的图表类型合适吗？是否诚实？

---

### Week 03：数据清洗与准备 —— 从"原始数据"到"可分析数据"

**核心理念**：脏数据是分析的最大敌人，而 AI 无法替你判断"脏"的标准

**核心内容**：
- 缺失值：MCAR、MAR、MNAR（缺失机制）
- 缺失值处理策略：删除 vs 填充 vs 预测（各有利弊）
- 异常值检测：统计方法（IQR、Z-score）vs 业务规则
- 数据转换：标准化、归一化、对数变换
- 特征编码：One-hot、Label、Target encoding

**重点强调**（吴恩达 Data-centric AI）：
- 80% 的时间花在数据准备上
- 数据质量 > 数据数量
- 记录每一个数据清洗决策（可复现性）

**AI 融合**：
- AI 辅助发现异常模式
- 人工判断：这是真正的异常还是有价值的发现？

---

### Week 04：从"看数字"到"讲故事"——EDA 叙事与假设清单

**核心理念**：EDA 不是正式分析的前奏，它就是分析的核心（John Tukey）

**核心内容**：
- EDA 方法论：迭代、可视化、假设生成
- 相关分析：Pearson、Spearman、Kendall
- 分组比较：groupby 分析、透视表
- 多变量关系：散点图矩阵、热力图
- 时间序列初步（趋势、季节性）

**实践**：
- 完成项目数据集的全套 EDA
- 发现 3-5 个有趣的初步发现
- 生成新的研究假设

**里程碑**：
- EDA 报告提交（数据清洗 + 描述统计 + 可视化 + 初步发现）

---

## 阶段二：统计推断（Week 05-08）

### Week 05：为什么你的结论可能只是运气？——从"算数"到"量化不确定性"

**核心理念**：概率论是统计学的语法（Joe Blitzstein, Harvard STAT 110）

**核心内容**：
- 概率基础：条件概率、贝叶斯定理、独立性
- 常见分布：正态、二项、泊松、指数
- 中心极限定理：为什么它如此重要
- 抽样方法：随机、分层、整群
- 重采样思想（Bradley Efron 的 Bootstrap 铺垫）

**重点强调**：
- 正态分布的重要性（但不迷信正态）
- 大数定律 vs 中心极限定理

---

### Week 06：我们真的发现了差异吗？——从"p 值迷思"到"统计决策"

**核心理念**：p-value 不是真理的度量，而是证据的强度（Ronald Fisher）

**核心内容**：
- 假设检验框架：H0、H1、检验统计量
- p-value 的正确理解（不是 P(H0|data)）
- 单样本、双样本 t 检验
- 两类错误：α、β、统计功效
- 效应量：统计显著 vs 实际重要

**AI 陷阱重点**（Week 06 AI 审查训练）：
- p-hacking 问题（多重比较）
- 样本量不足导致的假阴性
- 前提假设未验证的问题

**实践**：
- 对项目数据做假设检验
- 解释 p-value 的业务含义
- 计算效应量（Cohen's d）

---

### Week 07：比较三组或更多——从"多次 t 检验"到"方差分解"

**核心理念**：相关性不是因果性，但它是因果性的线索（Judea Pearl）

**核心内容**：
- 方差分析（ANOVA）：比较多组均值
- 卡方检验：分类变量关联
- 相关矩阵 vs 因果图
- 偏相关：控制混杂变量
- 多重比较校正：Bonferroni、FDR

**重点强调**（Judea Pearl 的因果思维铺垫）：
- 相关 ≠ 因果：混杂变量、反向因果、共同原因
- Simpson's Paradox（辛普森悖论）

---

### Week 08：你到底有多确定？——区间估计与重采样

**核心理念**：点估计是猜测，区间估计才是诚实的科学（Bradley Efron）

**核心内容**：
- 置信区间：频率学派的区间估计
- Bootstrap（自助法）：Efron 的革命性贡献
- Permutation Test（置换检验）
- 贝叶斯可信区间简介（与置信区间的区别）
- 统计显著性的局限性

**AI 融合**：
- AI 可以快速做 Bootstrap，但学生需要理解：
  - 为什么 Bootstrap 有效？
  - 什么时候 Bootstrap 失效？

**里程碑**：
- 统计推断报告（假设检验 + Bootstrap + 置信区间 + 效应量）

---

## 阶段三：预测建模（Week 09-12）

### Week 09：回归不是预测工具,而是理解关系的工具

**核心理念**：回归不是预测工具，而是理解关系的工具（Andrew Gelman）

**核心内容**：
- 简单线性回归：最小二乘法原理
- 多元回归：多重共线性、变量选择
- 模型诊断：残差分析、QQ图、Cook's 距离
- 回归假设：LINE（线性、独立性、正态性、等方差）
- 多项式回归、交互项

**重点强调**（Gelman 的模型检查理念）：
- 残差图比 R² 更重要
- 模型的假设满足了吗？

**AI 融合**：
- AI 快速拟合多个模型
- 学生负责：诊断模型问题、解释系数含义

---

### Week 10：从准确率到 AUC——分类器的评估陷阱

**核心理念**：预测准确不等于理解，但好的模型必须可解释

**核心内容**：
- 逻辑回归：从回归到分类
- 分类评估指标：准确率、精确率、召回率、F1、ROC-AUC
- 混淆矩阵解读
- 类别不平衡问题
- 交叉验证：K-fold、留一法
- 数据泄漏与防御：用 Pipeline/ColumnTransformer 把预处理封装进交叉验证

**重点强调**：
- 不同评估指标适用于不同场景
- 过拟合与欠拟合
- 训练集 vs 测试集的重要性

---

### Week 11：从决策树到随机森林——用"群体智慧"提升预测

**核心理念**：机器学习是计算密集型的统计学（David Donoho）

**核心内容**：
- 统计建模 vs 机器学习
- 决策树与随机森林（可解释性）
- 特征工程：创建有意义的特征
- 超参数调优：网格搜索、随机搜索
- 模型集成：Bagging、Boosting 简介

**重点强调**（Donoho 的视角）：
- ML 不是魔法，是统计方法的扩展
- 可解释性 vs 预测力权衡

---

### Week 12：让模型说话——可解释AI与伦理审查

**核心理念**：不可解释的模型是危险的模型（欧盟 GDPR 的"解释权"）

**核心内容**：
- 可解释 AI（XAI）：特征重要性、SHAP、LIME
- 模型偏见：数据偏见、算法偏见
- 公平性指标：平等机会、统计均等
- 数据隐私：差分隐私简介
- 向非技术人员解释模型

**实践**：
- 为项目模型创建"解释报告"
- 检查模型是否存在偏见

**里程碑**：
- 预测建模报告（模型 + 评估 + 解释 + 伦理检查）

---

## 阶段四：高级专题（Week 13-15）

### Week 13：从相关到因果——为什么你的模型不会回答"如果……会怎样"

**核心理念**：数据本身不说话，因果推断让数据说话（Judea Pearl）

**核心内容**：
- 因果推断三层级：关联 → 干预 → 反事实
- 因果图（Causal Diagrams）：混杂、碰撞、链式结构
- d-分离与后门准则
- 随机对照试验（RCT）的金标准
- 观察研究中的因果推断：双重差分、工具变量简介

**重点强调**（Pearl 的核心贡献）：
- 没有因果假设，就没有因果结论
- 因果图帮助明确假设
- 相关性是因果的必要条件，但不是充分条件

**AI 时代的重要性**：
- AI 可以发现相关性，但只有人类可以确定因果
- 业务决策需要因果，不只是预测

---

### Week 14：贝叶斯视角——从"p 值游戏"到"信念更新"

**核心理念**：贝叶斯方法是科学家的思维方式（Andrew Gelman）

**核心内容**：
- 贝叶斯定理：先验 + 似然 = 后验
- 频率学派 vs 贝叶斯学派
- 先验分布的选择：信息性 vs 无信息
- MCMC 简介：Metropolis-Hastings、Gibbs
- 贝叶斯假设检验（Bayes Factor）
- 可信区间 vs 置信区间

**重点强调**（Gelman 的实用贝叶斯）：
- 贝叶斯方法在小样本的优势
- 层次模型（多水平模型）简介
- 先验敏感性分析

**AI 融合**：
- 贝叶斯方法在 AI 不确定性量化中的应用
- Bayesian Neural Networks 简介

---

### Week 15：高级统计计算——当数据太多、太快、太复杂时

**核心理念**：大数据需要新的统计思维（David Donoho）

**核心内容**：
- "50 Years of Data Science" 回顾
- 大数据的挑战：维度灾难、计算复杂度
- 在线算法与流式统计
- 降维技术：PCA、t-SNE、UMAP
- 聚类分析：K-means、层次聚类、DBSCAN
- A/B 测试设计：实验统计学

**重点强调**（Donoho 的数据科学定义）：
- 数据科学 = 统计 + 计算 + 领域知识
- 统计学是所有数据科学的基础

---

## 阶段五：综合实战（Week 16）

### Week 16：从分析到交付——完整数据项目的终章

**期末展示**（每组 10-15 分钟）：
- 研究问题与数据介绍（1 分钟）
- 分析方法与关键发现（5 分钟）
- 可视化亮点（3 分钟）
- AI 使用反思（2 分钟）
- Q&A（3-4 分钟）

**课程复盘**：
- 统计思维成长回顾（从描述到因果）
- AI 协作经验总结
- 从"会跑代码"到"会提问题"的转变

**最终提交**：
1. 终稿分析报告（`report.md` / `report.html`）
2. 数据集引用方式 + 清洗/分析脚本（可一键复现）
3. 展示材料（PPT/海报）
4. AI 使用日志（含审查清单与改动记录）

---

## 贯穿项目：StatLab —— 可复现分析报告流水线

### 项目设计理念

你每周不是“做一题”，而是在同一份项目上持续迭代，最后交付一份**可复现、可审计**的分析报告：

- **一键复现**：从原始数据到 `report.md` / `report.html`，用脚本生成，不靠手工复制粘贴。
- **决策可追溯**：清洗、建模、检验的关键选择要留下理由（写进报告或日志）。
- **human-in-the-loop**：AI 可以加速，但你要负责提出问题、检查假设、解释结论。

### 项目阶段（与周次对应）

| 阶段 | 周次 | StatLab 里程碑（报告导向） |
|------|------|----------------------------|
| 选题与数据 | 01-02 | 数据卡 + 初版描述统计报告 |
| EDA | 03-04 | 清洗决策记录 + EDA 叙事 + 假设清单 |
| 推断 | 05-08 | 检验/区间/重采样，报告写清“不确定性” |
| 建模 | 09-12 | 回归/分类/评估/解释，避免数据泄漏 |
| 因果与扩展 | 13-15 | 因果图 + 贝叶斯视角 + 计算专题 |
| 展示 | 16 | 终稿报告（含展示版） |

---

## AI 协作框架

### 四阶段渐进

| 阶段 | 周次 | 学生能力 | AI 角色 |
|------|------|----------|---------|
| 观察期 | 01-04 | 学习基础 | AI 演示代码 |
| 识别期 | 05-08 | 判断对错 | AI 生成，学生审查 |
| 协作期 | 09-12 | 主导解释 | AI 执行，学生决策 |
| 主导期 | 13-16 | 独立设计 | AI 辅助实现 |

### AI 审查检查清单（统计特定）

**数据问题**：
- [ ] AI 建议的清洗方法适合我的数据吗？
- [ ] 缺失值处理考虑了缺失机制吗？
- [ ] 异常值是真正的错误还是有趣的发现？

**分析问题**：
- [ ] AI 选的统计检验前提满足吗？
- [ ] p-value 小 = 重要吗？效应量如何？
- [ ] 多重比较校正了吗？

**因果问题**（Judea Pearl）：
- [ ] 相关 = 因果？考虑混杂变量了吗？
- [ ] 有因果图支持吗？
- [ ] 反向因果可能吗？

**模型问题**（Andrew Gelman）：
- [ ] 模型诊断做了吗？残差正常吗？
- [ ] 过拟合检查了吗？
- [ ] 模型可解释吗？

---

## 评估体系

| 维度 | 占比 | 说明 |
|------|------|------|
| **周作业** | 25% | 16 周数据分析任务 |
| **贯穿项目** | 30% | 期末数据分析报告（强调因果推断尝试） |
| **AI 协作能力** | 15% | AI 使用日志、批判性评估 |
| **期末展示** | 20% | 数据故事叙述、可视化、因果思维 |
| **课堂参与** | 10% | 讨论、Code Review、统计思维分享 |

---

## 参考文献与资源

### 统计学经典
- Pearl, J. (2018). *The Book of Why*. 
- Gelman, A., et al. (2013). *Bayesian Data Analysis*.
- Efron, B. & Hastie, T. (2016). *Computer Age Statistical Inference*.
- Donoho, D. (2017). "50 Years of Data Science". DOI: https://doi.org/10.1080/10618600.2017.1384734

### 课程参考
- Harvard STAT 110 (Joe Blitzstein): https://stat110.hsites.harvard.edu/
- MITx 6.419x Data Analysis (Statistical Modeling and Computation in Applications): https://www.edx.org/learn/data-analysis/massachusetts-institute-of-technology-data-analysis-statistical-modeling-and-computation-in-applications
- Stanford STATS 200: https://web.stanford.edu/class/stats200/index.html
- CMU 36-700 (example course site): https://www.stat.cmu.edu/~siva/teaching/700/

### AI 与统计
- 吴恩达 Data-centric AI
- Judea Pearl 的因果推断课程

---

**最后更新**：2026-02-11
