# 统计学与 Agentic 数据分析 — 16周教学大纲

> **核心理念**：AI 可以帮你跑统计检验，但不懂业务场景和数据背后的意义，只会得到错误的结论。
> 
> **设计灵感**：> - 顶级高校：MIT 6.419 Statistical Learning, Stanford STATS 200, Harvard STAT 110> - 统计学大佬观点：>   - **Judea Pearl**（图灵奖得主）："数据本身不说话，因果推断才是科学的核心">   - **Andrew Gelman**（贝叶斯统计权威）："模型的检查比模型的拟合更重要">   - **David Donoho**："数据科学是统计学的延续，不是替代"
>   - **Bradley Efron**（Bootstrap发明者）："在AI时代，统计推断的基本原理比以往更重要"
>   - **吴恩达**："数据-centric AI时代，统计思维是核心竞争力"

---

## 课程定位

- **目标学生**：有一定 Python 基础，需要数据分析能力但非统计专业
- **课程时长**：16 周
- **技术栈**：Python + pandas + numpy + scipy + statsmodels + scikit-learn + matplotlib/seaborn
- **项目形式**：个人/小组数据分析报告 + 期末数据故事展示
- **AI 理念**：AI 是分析加速器，但人类负责提问、解释和判断

---

## 设计理念：AI 时代的统计素养

### 统计学大关于 AI 的核心观点

**Judea Pearl（因果推断先驱）**：
> "机器学习和统计学沉迷于相关性，但科学的核心是因果关系。没有因果思维，AI 只是高级的模式匹配。"

**Andrew Gelman（哥伦比亚大学，贝叶斯统计权威）**：
> "模型的检查比模型的拟合更重要。AI 可以生成漂亮的模型，但只有通过严格的模型诊断，我们才能知道它是否可靠。"

**David Donoho（斯坦福大学，'50 Years of Data Science' 作者）**：
> "数据科学不是新学科，它是统计学的自然延续。在 AI 时代，统计推断的基本原理比以往任何时候都更重要。"

**Bradley Efron（斯坦福大学，Bootstrap 发明者）**：
> "大数据并没有让统计学过时，反而让统计推断的假设前提变得更加关键。没有统计思维，大数据只是大混乱。"

**吴恩达（Landing AI, Coursera）**：
> "数据-centric AI 时代，80% 的工作是数据准备和验证，只有 20% 是建模。统计思维是数据工程师的核心竞争力。"

### 本课程的回应

基于以上观点，本课程强调三个核心能力：

1. **因果思维**（不只是相关性）
2. **模型批判**（不只是模型拟合）
3. **数据质量意识**（不只是数据量）

---

## 16 周课程结构

| 阶段 | 周次 | 主题 | 能力目标 |
|------|------|------|----------|
| **阶段一：数据探索基础** | 01-04 | 从数据到问题 | 数据清洗、描述统计、可视化 |
| **阶段二：统计推断** | 05-08 | 从样本到总体 | 假设检验、置信区间、效应量 |
| **阶段三：预测建模** | 09-12 | 从过去到未来 | 回归、分类、模型评估 |
| **阶段四：高级专题** | 13-15 | 从相关到因果 | 因果推断、贝叶斯、大数据统计 |
| **阶段五：综合实战** | 16 | 期末展示 | 完整数据项目展示 |

---

## 阶段一：数据探索基础（Week 01-04）

### Week 01：数据思维入门 —— 从"看数字"到"问问题"

**核心理念**：统计学不是计算，是提问（Andrew Gelman）

**核心内容**：
- 统计学的三个核心问题：描述（Description）、推断（Inference）、预测（Prediction）
- 数据类型：数值型 vs 分类型；连续 vs 离散
- Python 数据工具链：pandas 入门
- 探索性思维：从数据中发现问题，而非只验证假设

**AI 融合**：
- 观察 AI 自动生成数据摘要
- 讨论：AI 生成的描述性统计是否有用？哪些信息被遗漏了？

**实践**：
- 加载真实数据集（Titanic、COVID-19、房价数据等）
- 初步数据探索报告

**贯穿项目**：选择期末项目数据集

---

### Week 02：描述性统计与数据可视化

**核心理念**：一图胜千言，但错误的图误导万千（Edward Tufte）

**核心内容**：
- 集中趋势：均值、中位数、众数（何时用哪个？）
- 离散程度：标准差、方差、IQR
- 分布形状：偏度、峰度、箱线图
- 可视化原则：诚实、清晰、高效
- matplotlib / seaborn / plotly 基础

**重点强调**：
- 均值 vs 中位数的选择（异常值影响）
- 可视化的误导性（Y轴截断、面积误导）

**AI 融合**：
- AI 自动生成可视化
- 批判性评估：AI 选的图表类型合适吗？是否诚实？

---

### Week 03：数据清洗与预处理

**核心理念**：脏数据是分析的最大敌人，而 AI 无法替你判断"脏"的标准

**核心内容**：
- 缺失值：MCAR、MAR、MNAR（缺失机制）
- 缺失值处理策略：删除 vs 填充 vs 预测（各有利弊）
- 异常值检测：统计方法（IQR、Z-score）vs 业务规则
- 数据转换：标准化、归一化、对数变换
- 特征编码：One-hot、Label、Target encoding

**重点强调**（吴恩达 Data-centric AI）：
- 80% 的时间花在数据准备上
- 数据质量 > 数据数量
- 记录每一个数据清洗决策（可复现性）

**AI 融合**：
- AI 辅助发现异常模式
- 人工判断：这是真正的异常还是有价值的发现？

---

### Week 04：探索性数据分析（EDA）综合

**核心理念**：EDA 不是正式分析的前奏，它就是分析的核心（John Tukey）

**核心内容**：
- EDA 方法论：迭代、可视化、假设生成
- 相关分析：Pearson、Spearman、Kendall
- 分组比较：groupby 分析、透视表
- 多变量关系：散点图矩阵、热力图
- 时间序列初步（趋势、季节性）

**实践**：
- 完成项目数据集的全套 EDA
- 发现 3-5 个有趣的初步发现
- 生成新的研究假设

**里程碑**：
- EDA 报告提交（数据清洗 + 描述统计 + 可视化 + 初步发现）

---

## 阶段二：统计推断（Week 05-08）

### Week 05：概率与分布 —— 随机性的语言

**核心理念**：概率论是统计学的语法（Joe Blitzstein, Harvard STAT 110）

**核心内容**：
- 概率基础：条件概率、贝叶斯定理、独立性
- 常见分布：正态、二项、泊松、指数
- 中心极限定理：为什么它如此重要
- 抽样方法：随机、分层、整群
- 重采样思想（Bradley Efron 的 Bootstrap 铺垫）

**重点强调**：
- 正态分布的重要性（但不迷信正态）
- 大数定律 vs 中心极限定理

---

### Week 06：假设检验基础 —— 用数据检验想法

**核心理念**：p-value 不是真理的度量，而是证据的强度（Ronald Fisher）

**核心内容**：
- 假设检验框架：H0、H1、检验统计量
- p-value 的正确理解（不是 P(H0|data)）
- 单样本、双样本 t 检验
- 两类错误：α、β、统计功效
- 效应量：统计显著 vs 实际重要

**AI 陷阱重点**（Week 06 AI 审查训练）：
- p-hacking 问题（多重比较）
- 样本量不足导致的假阴性
- 前提假设未验证的问题

**实践**：
- 对项目数据做假设检验
- 解释 p-value 的业务含义
- 计算效应量（Cohen's d）

---

### Week 07：比较与关联 —— 组间差异与变量关系

**核心理念**：相关性不是因果性，但它是因果性的线索（Judea Pearl）

**核心内容**：
- 方差分析（ANOVA）：比较多组均值
- 卡方检验：分类变量关联
- 相关矩阵 vs 因果图
- 偏相关：控制混杂变量
- 多重比较校正：Bonferroni、FDR

**重点强调**（Judea Pearl 的因果思维铺垫）：
- 相关 ≠ 因果：混杂变量、反向因果、共同原因
- Simpson's Paradox（辛普森悖论）

---

### Week 08：置信区间与重采样 —— 估计的不确定性

**核心理念**：点估计是猜测，区间估计才是诚实的科学（Bradley Efron）

**核心内容**：
- 置信区间：频率学派的区间估计
- Bootstrap（自助法）：Efron 的革命性贡献
- Permutation Test（置换检验）
- 贝叶斯可信区间简介（与置信区间的区别）
- 统计显著性的局限性

**AI 融合**：
- AI 可以快速做 Bootstrap，但学生需要理解：
  - 为什么 Bootstrap 有效？
  - 什么时候 Bootstrap 失效？

**里程碑**：
- 统计推断报告（假设检验 + Bootstrap + 置信区间 + 效应量）

---

## 阶段三：预测建模（Week 09-12）

### Week 09：回归分析 —— 用变量预测变量

**核心理念**：回归不是预测工具，而是理解关系的工具（Andrew Gelman）

**核心内容**：
- 简单线性回归：最小二乘法原理
- 多元回归：多重共线性、变量选择
- 模型诊断：残差分析、QQ图、Cook's 距离
- 回归假设：LINE（线性、独立性、正态性、等方差）
- 多项式回归、交互项

**重点强调**（Gelman 的模型检查理念）：
- 残差图比 R² 更重要
- 模型的假设满足了吗？

**AI 融合**：
- AI 快速拟合多个模型
- 学生负责：诊断模型问题、解释系数含义

---

### Week 10：分类与预测评估

**核心理念**：预测准确不等于理解，但好的模型必须可解释

**核心内容**：
- 逻辑回归：从回归到分类
- 分类评估指标：准确率、精确率、召回率、F1、ROC-AUC
- 混淆矩阵解读
- 类别不平衡问题
- 交叉验证：K-fold、留一法

**重点强调**：
- 不同评估指标适用于不同场景
- 过拟合与欠拟合
- 训练集 vs 测试集的重要性

---

### Week 11：机器学习入门 —— 统计学的延伸

**核心理念**：机器学习是计算密集型的统计学（David Donoho）

**核心内容**：
- 统计建模 vs 机器学习
- 决策树与随机森林（可解释性）
- 特征工程：创建有意义的特征
- 超参数调优：网格搜索、随机搜索
- 模型集成：Bagging、Boosting 简介

**重点强调**（Donoho 的视角）：
- ML 不是魔法，是统计方法的扩展
- 可解释性 vs 预测力权衡

---

### Week 12：模型解释与伦理 —— 让模型可被理解

**核心理念**：不可解释的模型是危险的模型（欧盟 GDPR 的"解释权"）

**核心内容**：
- 可解释 AI（XAI）：特征重要性、SHAP、LIME
- 模型偏见：数据偏见、算法偏见
- 公平性指标：平等机会、统计均等
- 数据隐私：差分隐私简介
- 向非技术人员解释模型

**实践**：
- 为项目模型创建"解释报告"
- 检查模型是否存在偏见

**里程碑**：
- 预测建模报告（模型 + 评估 + 解释 + 伦理检查）

---

## 阶段四：高级专题（Week 13-15）

### Week 13：因果推断入门 —— 从相关到因果

**核心理念**：数据本身不说话，因果推断让数据说话（Judea Pearl）

**核心内容**：
- 因果推断三层级：关联 → 干预 → 反事实
- 因果图（Causal Diagrams）：混杂、碰撞、链式结构
- d-分离与后门准则
- 随机对照试验（RCT）的金标准
- 观察研究中的因果推断：双重差分、工具变量简介

**重点强调**（Pearl 的核心贡献）：
- 没有因果假设，就没有因果结论
- 因果图帮助明确假设
- 相关性是因果的必要条件，但不是充分条件

**AI 时代的重要性**：
- AI 可以发现相关性，但只有人类可以确定因果
- 业务决策需要因果，不只是预测

---

### Week 14：贝叶斯统计 —— 更新信念的艺术

**核心理念**：贝叶斯方法是科学家的思维方式（Andrew Gelman）

**核心内容**：
- 贝叶斯定理：先验 + 似然 = 后验
- 频率学派 vs 贝叶斯学派
- 先验分布的选择：信息性 vs 无信息
- MCMC 简介：Metropolis-Hastings、Gibbs
- 贝叶斯假设检验（Bayes Factor）
- 可信区间 vs 置信区间

**重点强调**（Gelman 的实用贝叶斯）：
- 贝叶斯方法在小样本的优势
- 层次模型（多水平模型）简介
- 先验敏感性分析

**AI 融合**：
- 贝叶斯方法在 AI 不确定性量化中的应用
- Bayesian Neural Networks 简介

---

### Week 15：大数据与统计计算 —— 数据科学的工具箱

**核心理念**：大数据需要新的统计思维（David Donoho）

**核心内容**：
- "50 Years of Data Science" 回顾
- 大数据的挑战：维度灾难、计算复杂度
- 在线算法与流式统计
- 降维技术：PCA、t-SNE、UMAP
- 聚类分析：K-means、层次聚类、DBSCAN
- A/B 测试设计：实验统计学

**重点强调**（Donoho 的数据科学定义）：
- 数据科学 = 统计 + 计算 + 领域知识
- 统计学是所有数据科学的基础

---

## 阶段五：综合实战（Week 16）

### Week 16：期末展示与课程复盘

**期末展示**（每组 10-15 分钟）：
- 研究问题与数据介绍（1 分钟）
- 分析方法与关键发现（5 分钟）
- 可视化亮点（3 分钟）
- AI 使用反思（2 分钟）
- Q&A（3-4 分钟）

**课程复盘**：
- 统计思维成长回顾（从描述到因果）
- AI 协作经验总结
- 从"会跑代码"到"会提问题"的转变

**最终提交**：
1. 完整分析报告（Jupyter Notebook）
2. 数据集和清洗脚本
3. 展示材料（PPT/海报）
4. AI 使用日志

---

## 贯穿项目：数据因果探索者

### 项目设计理念

基于 Judea Pearl 的因果思维，项目强调：
- 不只是发现相关性
- 更要思考因果关系
- 使用因果图明确假设

### 项目阶段

| 阶段 | 周次 | 里程碑 |
|------|------|--------|
| 选题与数据 | 01-02 | 数据集获取、初步探索 |
| EDA | 03-04 | EDA 报告、假设生成 |
| 推断 | 05-08 | 统计检验、Bootstrap、置信区间 |
| 建模 | 09-12 | 预测模型、模型解释 |
| 因果 | 13-15 | 因果图、因果推断尝试 |
| 展示 | 16 | 期末展示 |

---

## AI 协作框架

### 四阶段渐进

| 阶段 | 周次 | 学生能力 | AI 角色 |
|------|------|----------|---------|
| 观察期 | 01-04 | 学习基础 | AI 演示代码 |
| 识别期 | 05-08 | 判断对错 | AI 生成，学生审查 |
| 协作期 | 09-12 | 主导解释 | AI 执行，学生决策 |
| 主导期 | 13-16 | 独立设计 | AI 辅助实现 |

### AI 审查检查清单（统计特定）

**数据问题**：
- [ ] AI 建议的清洗方法适合我的数据吗？
- [ ] 缺失值处理考虑了缺失机制吗？
- [ ] 异常值是真正的错误还是有趣的发现？

**分析问题**：
- [ ] AI 选的统计检验前提满足吗？
- [ ] p-value 小 = 重要吗？效应量如何？
- [ ] 多重比较校正了吗？

**因果问题**（Judea Pearl）：
- [ ] 相关 = 因果？考虑混杂变量了吗？
- [ ] 有因果图支持吗？
- [ ] 反向因果可能吗？

**模型问题**（Andrew Gelman）：
- [ ] 模型诊断做了吗？残差正常吗？
- [ ] 过拟合检查了吗？
- [ ] 模型可解释吗？

---

## 评估体系

| 维度 | 占比 | 说明 |
|------|------|------|
| **周作业** | 25% | 16 周数据分析任务 |
| **贯穿项目** | 30% | 期末数据分析报告（强调因果推断尝试） |
| **AI 协作能力** | 15% | AI 使用日志、批判性评估 |
| **期末展示** | 20% | 数据故事叙述、可视化、因果思维 |
| **课堂参与** | 10% | 讨论、Code Review、统计思维分享 |

---

## 参考文献与资源

### 统计学经典
- Pearl, J. (2018). *The Book of Why*. 
- Gelman, A., et al. (2013). *Bayesian Data Analysis*.
- Efron, B. & Hastie, T. (2016). *Computer Age Statistical Inference*.
- Donoho, D. (2017). "50 Years of Data Science"

### 课程参考
- Harvard STAT 110 (Joe Blitzstein)
- MIT 6.419 Statistical Learning
- Stanford STATS 200
- CMU 36-700/705 Probability & Statistics

### AI 与统计
- 吴恩达 Data-centric AI
- Judea Pearl 的因果推断课程

---

**最后更新**：2025 年 2 月
