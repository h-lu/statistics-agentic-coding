# Week 12 作业：让模型说话——可解释AI与伦理审查

> "With great power comes great responsibility."
> — Spider-Man's Uncle Ben (and also every ML engineer in 2026)

本周作业要求你**完整走一遍模型解释与伦理审查流程**：从特征重要性到 SHAP 局部解释，从偏见检测到公平性量化，从隐私风险到伦理审查清单，从技术术语到"说人话"。你不再只是报告"AUC = 0.85"，而是学会回答"为什么这个样本被拒"、"模型是否公平"、"隐私如何保护"、"如何向客户解释"。

---

## 作业结构

| 层级 | 内容 | 建议时间 |
|------|------|----------|
| 基础作业（必做） | SHAP 可解释性、公平性指标计算、伦理审查清单 | 4-5 小时 |
| 进阶作业（选做） | 偏见来源分析、差分隐私实现 | 1-2 小时 |
| 挑战作业（可选） | StatLab 模型解释与伦理审查完整流水线 | 2-3 小时 |
| AI 协作练习（可选） | 审查 AI 生成的 SHAP 分析 | 1 小时 |

---

## 基础作业（必做）

### 任务 1：从特征重要性到 SHAP——解释单个预测（30 分）

**目标**：理解全局解释与局部解释的区别，掌握 SHAP 基本用法

**背景**：小北的随机森林 AUC = 0.85。产品经理问："**你能告诉我，为什么张三的申请被拒了吗？**"

小北输出了特征重要性：
```
income: 0.45
credit_history_age: 0.32
debt_to_income: 0.23
```

产品经理摇头："**我知道收入重要，但我想知道——对张三这个样本，收入贡献了多少？**"

老潘说："**特征重要性是全局的，SHAP 是局部的**。"

**步骤**：

1. **训练一个分类模型**：
   - 使用你的数据集（分类任务，如违约预测、流失预测）
   - 训练随机森林或逻辑回归
   - 计算 AUC 和准确率

2. **提取特征重要性（全局解释）**：
   - 使用 `feature_importances_` 或系数
   - 创建特征重要性表（Top 10）
   - 写一段分析（100 字）：
     - 特征重要性告诉你什么？
     - 它无法回答什么问题？

3. **计算 SHAP 值（局部解释）**：
   - 使用 `shap.TreeExplainer`（树模型）或 `shap.LinearExplainer`（线性模型）
   - 计算 SHAP 值
   - 对 3 个不同样本（预测为正类、负类、边界）提取 SHAP 值

4. **可视化 SHAP 解释**：
   - **全局解释**：`summary_plot`——哪些特征最重要、影响方向是什么
   - **局部解释**：`force_plot`——某个样本的预测是如何构成的
   - 保存图表到 `report/` 目录

5. **连接 Week 08**：
   - Week 08 你学过**置信区间**
   - 解释：SHAP 值有不确定性吗？
   - 如何用 Bootstrap 估计 SHAP 值的置信区间？

6. **提交** `shap_explanation.md`，包含：
   - 模型性能（AUC、准确率）
   - 特征重要性表（全局）+ 局限性分析
   - SHAP summary_plot 解读
   - 3 个样本的 force_plot 解读
   - 与 Week 08 置信区间的连接

**输入示例**：
```
特征: income, credit_history_age, debt_to_income, credit_inquiries, employment_length
目标: default（0=不违约，1=违约）
```

**输出示例**：
```
模型性能:
- AUC: 0.852
- 准确率: 0.780

特征重要性（全局）:
- income: 0.452（最重要）
- credit_history_age: 0.318
- debt_to_income: 0.230

全局解释的局限性:
特征重要性告诉我"收入在所有预测中平均贡献最多"，但无法回答"对
张三这个样本，收入贡献了多少"。张三可能收入很高但信用查询很多，
此时"信用查询"才是他被拒的主因，特征重要性看不出这一点。

SHAP Summary Plot 解读:
- 横轴：SHAP值（正值=提高违约概率，负值=降低违约概率）
- 纵轴：特征（按重要性排序）
- 颜色：特征值（红色=高，蓝色=低）
- 发现：高收入（红色）集中在负侧（降低违约概率），符合直觉
- 发现：信用查询多（红色）集中在正侧（提高违约概率）

样本 1（被拒，预测概率=0.82）:
- 基准值: 0.20（整体违约率）
- 收入贡献: +0.35（收入低，提高违约概率）
- 信用查询贡献: +0.20（近期查询多，提高违约概率）
- 信用历史贡献: -0.05（略好于平均，略微降低风险）
- 信用长度贡献: -0.03（略好于平均，略微降低风险）
- 最终预测: 0.20 + 0.35 + 0.20 - 0.05 - 0.03 = 0.67

如何向客户解释:
"您的申请被拒主要因为两点：第一，您的月收入（5000元）低于通过客户
的平均水平（8000元）；第二，您近6个月有3次信用卡查询，说明您可能在
申请其他贷款，这会增加违约风险。如果您能增加收入或减少近期查询，
通过概率会提升。"

与Week 08的连接:
SHAP值是从模型计算出来的，但模型本身有不确定性（来自训练数据）。
可以用Bootstrap估计SHAP值的置信区间：对训练数据做多次重采样，每次
训练模型并计算SHAP值，最后得到"收入贡献+0.35±0.05"（95% CI）。
```

**评分标准**：
- 模型训练正确（5 分）
- 特征重要性计算和局限性分析准确（7 分）
- SHAP 值计算正确（8 分）
- 可视化清晰（summary_plot + force_plot，6 分）
- 与 Week 08 置信区间连接正确（4 分）

---

### 任务 2：公平性指标计算——量化"不公平"（35 分）

**目标**：掌握公平性指标的计算方法，识别模型在不同群体上的性能差异

**背景**：小北算完 SHAP 值后，产品经理又问："**模型对男性和女性申请人的表现一样吗？**"

小北从来没想过这个问题。他赶紧算了一下：

```
男性 AUC: 0.890
女性 AUC: 0.780
```

小北脸色发白："**模型在女性群体上表现更差！**"

老潘点头："**你不仅要看整体 AUC，还要看不同群体的性能差异**。"

---

#### 子任务 2.1：差异影响比——通过率是否相等？（10 分）

**目标**：计算不同群体的通过率比，判断是否违反 80% 规则

**步骤**：

1. **按敏感特征划分数据**：
   - 选择一个敏感特征（性别、年龄组、地区等）
   - 将测试集按该特征分为两组（A 组、B 组）

2. **计算通过率**：
   - 计算每组预测为正类的比例（通过率）
   - 例如：男性通过率 = 22.0%，女性通过率 = 16.8%

3. **计算差异影响比**：
   - 公式：`通过率_A / 通过率_B`（通常用少数群体 / 多数群体）
   - 判断：是否 < 0.8（违反 80% 规则）？

4. **写诊断**（100 字）：
   - 差异影响比的含义是什么？
   - 是否违反 80% 规则？法律风险如何？

**输出示例**：
```
差异影响比（Disparate Impact）:
- 男性通过率（预测违约）: 0.220
- 女性通过率（预测违约）: 0.168
- 差异影响比（女性/男性）: 0.168 / 0.220 = 0.764

诊断: 0.764 < 0.8，违反80%规则，可能存在法律风险。女性的通过率
仅为男性的76.4%，说明模型对女性更严格。
```

**评分标准**：
- 数据划分和通过率计算正确（3 分）
- 差异影响比计算正确（3 分）
- 诊断准确、理解 80% 规则（4 分）

---

#### 子任务 2.2：平等机会差异——召回率是否相等？（10 分）

**目标**：计算不同群体的召回率差异，判断真正高风险者的识别率是否相等

**步骤**：

1. **计算每组的混淆矩阵**：
   - 使用 `sklearn.metrics.confusion_matrix`
   - 得到 TN, FP, FN, TP

2. **计算召回率（TPR）**：
   - 公式：`TPR = TP / (TP + FN)`
   - 含义：真正违约的人中被正确识别的比例

3. **计算平等机会差异**：
   - 公式：`|TPR_A - TPR_B|`
   - 判断：差异是否 > 0.05（5 个百分点）？

4. **写诊断**（100 字）：
   - 召回率差异的含义是什么？
   - 对业务的影响是什么（如放过更多坏人）？

**输出示例**：
```
平等机会差异（Equal Opportunity）:
- 男性召回率（真正违约的人中被识别的比例）: 0.850
- 女性召回率: 0.650
- 差异: 0.850 - 0.650 = 0.200

诊断: 模型在"识别真正高风险女性"方面表现更差——这可能导致更多
"假阴性"（实际会违约但被放过），对金融机构风险更大。
```

**评分标准**：
- 混淆矩阵计算正确（3 分）
- 召回率计算正确（3 分）
- 诊断准确、理解业务影响（4 分）

---

#### 子任务 2.3：均等几率检查——FPR 和 TPR 都要相等？（10 分）

**目标**：检查不同群体的假阳性率，判断是否满足均等几率

**步骤**：

1. **计算假阳性率（FPR）**：
   - 公式：`FPR = FP / (FP + TN)`
   - 含义：实际不违约但被误判为违约的比例（被"冤枉"的比例）

2. **检查均等几率**：
   - 条件 1：`|TPR_A - TPR_B| < 0.05`
   - 条件 2：`|FPR_A - FPR_B| < 0.05`
   - 判断：两个条件都满足吗？

3. **写诊断**（100 字）：
   - 均等几率是否满足？
   - 如果不满足，是 TPR 差异还是 FPR 差异导致的？

**输出示例**：
```
均等几率检查（Equalized Odds）:
- 男性假阳性率（被误判为违约的比例）: 0.120
- 女性假阳性率: 0.180
- FPR 差异: 0.060

诊断: |TPR差异|=0.200 > 0.05 且 |FPR差异|=0.060 > 0.05，均等几率
不满足。女性的假阳性率更高（被"冤枉"的比例更高）。
```

**评分标准**：
- FPR 计算正确（3 分）
- 均等几率检查逻辑正确（3 分）
- 诊断准确、理解双重歧视（4 分）

---

#### 子任务 2.4：连接 Week 10——混淆矩阵与公平性（5 分）

**目标**：理解混淆矩阵是公平性指标的基础

**写一段分析（150 字）**：

1. **混淆矩阵与公平性指标的关系**：
   - 每个群体都有独立的混淆矩阵
   - 公平性指标本质上是"比较不同群体的混淆矩阵指标"

2. **具体例子**：
   - 用你的数据说明：不同群体的混淆矩阵有什么差异？
   - 这些差异如何转化为公平性指标？

**输出示例**：
```
与Week 10的连接:
混淆矩阵是公平性指标的基础。每个群体都有独立的混淆矩阵：
- 男性: [[TN_m, FP_m], [FN_m, TP_m]]
- 女性: [[TN_f, FP_f], [FN_f, TP_f]]

公平性指标本质上是"比较不同群体的混淆矩阵指标"：
- 差异影响比 = (TP_f+FP_f)/总f ÷ (TP_m+FP_m)/总m
- 平等机会 = TP_f/实际正f vs TP_m/实际正m
- 均等几率 = TP率+FP率都要相近
```

**评分标准**：
- 理解混淆矩阵与公平性的关系（3 分）
- 用具体数据说明（2 分）

---

#### 改进建议（附加项，不计分但建议完成）

基于以上分析，列出 2-3 条改进建议：

**输出示例**：
```
改进建议:
1. 数据层面: 收集更多女性样本，平衡训练数据
2. 算法层面: 使用公平性约束的模型（如Fairlearn）
3. 后处理: 调整阈值，使两组通过率接近（会牺牲整体性能）
4. 检测代理变量: 检查是否有与性别强相关的特征（如职位、地区）
```

---

### 任务 3：伦理审查清单——系统化评估风险（35 分）

**目标**：使用伦理审查清单系统化评估模型风险，识别偏见、隐私和可复现性问题

**背景**：小北确认了模型在女性群体上表现更差。老潘说："**偏见只是风险之一，你需要系统化评估所有风险**。"

老潘拿出一个**伦理审查清单**：
- 数据偏见
- 算法偏见
- 代理变量
- 公平性指标
- 隐私风险
- 可复现性
- 结论边界

**步骤**：

1. **完成伦理审查清单**：

   | 风险类别 | 检查项 | 你的答案 | 证据 |
   |---------|--------|----------|------|
   | **数据偏见** | 训练数据是否存在历史歧视？ | [ ] 是 / [ ] 否 / [ ] 不确定 | 分析历史违约率、样本代表性 |
   | **算法偏见** | 模型是否放大数据中的模式？ | [ ] 是 / [ ] 否 | 不同群体性能差异 > 10%? |
   | **代理变量** | 是否存在敏感属性的代理变量？ | [ ] 是 / [ ] 否 | 相关性分析（>0.5为代理） |
   | **公平性指标** | 差异影响比是否 ≥ 0.8？ | [ ] 是 / [ ] 否 | 差异影响比值 |
   | **隐私风险** | 数据发布是否使用差分隐私？ | [ ] 是 / [ ] 否 | 是否可能反演个体信息？ |
   | **可复现性** | 模型是否能被独立验证？ | [ ] 是 / [ ] 否 | 随机种子、代码、数据是否记录？ |
   | **结论边界** | 模型的局限性是否明确？ | [ ] 是 / [ ] 否 | 是否说明"模型不能回答什么"？ |

2. **代理变量检测**：
   - 计算每个特征与敏感特征的相关性
   - 找出相关性 > 0.5 的特征（候选代理变量）
   - 用 SHAP 依赖图验证（是否间接编码敏感信息）

3. **隐私风险评估**：
   - 分析：攻击者能否通过模型预测反推个体信息？
   - 示例：如果模型告诉你"收入 5 万、年龄 30 岁的申请人通过率 80%"，攻击者能否通过反复查询确定某个特定个体的信息？

4. **可复现性检查**：
   - 是否设置了 `random_state`？
   - 是否记录了数据来源、清洗步骤、模型参数？
   - 其他人能否用你的代码复现结果？

5. **结论边界明确化**：
   - 写一段"模型能回答什么、不能回答什么"（150 字）
   - 包含：
     - 模型能预测什么
     - 模型不能预测什么（因果关系、特殊场景、伦理判断）

6. **提交** `ethics_review_checklist.md`，包含：
   - 完整的伦理审查清单（每项都有答案+证据）
   - 代理变量检测结果（相关性表、SHAP 依赖图）
   - 隐私风险评估分析
   - 可复现性检查结果
   - 结论边界说明（模型能/不能回答什么）

**输出示例**：
```
伦理审查清单:

1. 数据偏见: [✓] 存在
   证据: 历史数据中，女性申请人被拒比例（35%）高于男性（25%），
   说明训练数据本身存在历史歧视。模型会"学会"这个模式。

2. 算法偏见: [✓] 存在
   证据: 女性AUC（0.780）vs 男性AUC（0.890），差异0.110 > 0.10，
   说明模型在女性群体上表现显著更差。

3. 代理变量: [✓] 存在
   证据: 与gender相关性>0.5的特征：
   - occupation_nurse (0.72): 护士中女性比例更高
   - zip_code_10001 (0.58): 某些地区女性更多
   - income (-0.51): 历史收入差距

   SHAP依赖图验证: occupation_nurse的SHAP值与gender强相关
   （护士的SHAP值总是负的，说明它在间接编码性别信息）。

4. 公平性指标: [✗] 不满足
   证据: 差异影响比=0.764 < 0.8，违反80%规则。

5. 隐私风险: [!] 中等风险
   证据: 模型公开部署后，攻击者可以通过反复查询（收入5万、
   年龄30岁、收入5.1万、年龄30岁...）逐步反推出某特定个体的
   敏感信息（模型反演攻击）。建议：
   - 限制查询频率
   - 发布统计数据时使用差分隐私

6. 可复现性: [✓] 满足
   证据:
   - random_state=42已设置
   - 数据来源: "credit_data_2024.csv"
   - 清洗步骤: 记录在data_cleaning.log
   - 模型参数: 记录在model_config.json

7. 结论边界: [✓] 明确
   见下方"模型能/不能回答什么"。

模型能回答的:
- 基于历史数据预测违约概率（相关性）
- 识别哪些特征与违约相关（特征重要性、SHAP）
- 估计不同群体的风险分布（公平性分析）

模型不能回答的:
- 因果关系: "提高收入是否会降低违约？"模型只预测相关性，
  不回答因果。收入低可能是"能力问题"的代理，提高收入不改变能力。
- 特殊场景: 训练数据中未见过的场景（如经济危机、政策变化）
- 伦理判断: "是否应该拒绝某个客户"（这是业务决策，不是模型决策）
- 干预建议: "如何提高通过率"（模型只识别模式，不验证因果关系）

建议改进措施:
1. 数据层面: 收集更多女性样本，重新平衡训练数据
2. 特征工程: 删除或弱化代理变量（occupation_nurse, zip_code）
3. 算法层面: 使用公平性约束的模型（如fairlearn.reductions）
4. 后处理: 为女性群体调整阈值（牺牲男性性能，提升公平性）
5. 隐私保护: 使用差分隐私发布统计数据（ε=1.0）
```

**评分标准**：
- 审查清单完整（每项都有答案+证据，10 分）
- 代理变量检测正确（8 分）
- 隐私风险评估合理（7 分）
- 可复现性检查完整（5 分）
- 结论边界说明清晰（5 分）

---

## 进阶作业（选做）

### 任务 4：偏见来源分析——数据、算法与反馈循环（25 分）

**目标**：深入理解模型偏见的三个来源，识别偏见在数据-算法-部署中的传递路径

**背景**：阿码好奇："**偏见是从哪来的？是数据的问题，还是算法的问题？**"

老潘说："**偏见有三个来源：数据偏见（历史歧视）、算法偏见（放大模式）、反馈循环（自我实现）。**"

**步骤**：

1. **数据偏见分析**：
   - 检查训练数据是否存在历史歧视
   - 对比不同群体的目标变量分布（如违约率、录用率）
   - 分析：样本是否代表性？（某些群体样本过少？）

2. **算法偏见分析**：
   - 比较线性模型和树模型的群体性能差异
   - 分析：复杂模型（随机森林）是否比简单模型（逻辑回归）更偏向某些群体？
   - 解释：为什么复杂模型可能放大数据中的模式？

3. **反馈循环模拟**：
   - 写一段分析（200 字），回答：
     - 如果模型预测某女性申请人"高风险"并拒绝她，会发生什么？
     - 她不会出现在训练数据中（因为没有"真实标签"）
     - 未来模型会更自信地拒绝女性——这是自我实现的预言
   - 设计一个缓解策略：如何打破反馈循环？

4. **案例分析**：
   - 选择一个真实案例（如 COMPAS 算法、招聘 AI、信用评分）
   - 分析：偏见的来源是什么？（数据、算法、反馈循环）
   - 评估：案例中的公平性问题如何被识别和解决？

5. **提交** `bias_source_analysis.md`，包含：
   - 数据偏见分析（目标变量分布、样本代表性）
   - 算法偏见分析（线性 vs 树模型的群体性能差异）
   - 反馈循环分析和缓解策略
   - 真实案例研究

**输出示例**：
```
数据偏见分析:
训练数据中不同群体的目标变量分布:
- 男性: 违约率=25%, 样本数=1200
- 女性: 违约率=35%, 样本数=800

诊断:
1. 历史歧视: 女性违约率更高（35% vs 25%），可能是历史上
   金融机构对女性更严格，导致女性只能接受高利率贷款，进而更易违约
2. 样本不平衡: 女性样本（800）少于男性（1200），模型在女性
   群体上表现不稳定
3. MNAR风险: 某些女性申请人可能根本未被批准（无历史记录），
   导致缺失不是随机的（MNAR）

算法偏见分析:
不同模型在女性群体上的性能:
- 逻辑回归: AUC=0.820, 召回率=0.720
- 随机森林: AUC=0.780, 召回率=0.650
- XGBoost: AUC=0.770, 召回率=0.630

诊断:
1. 复杂模型（随机森林、XGBoost）在女性群体上表现更差
2. 原因: 复杂模型更容易过拟合训练数据中的历史歧视
3. 线性模型更稳健，因为它的"假设约束"更强（不会记住每个噪声）

反馈循环模拟:
场景: 模型预测某女性申请人"高风险"，银行拒绝贷款
后果:
1. 她无法建立信用历史（因为没有贷款）
2. 未来申请时，模型仍预测"高风险"（因为缺乏正向样本）
3. 她永远无法走出"高风险"标签——自我实现的预言

缓解策略:
1. 保留部分"高风险"样本：即使模型预测高风险，仍批准一小部分，
   观察真实标签，打破反馈循环
2. 定期重新训练：每月更新模型，纳入新样本（包括被拒样本的代理信息）
3. 差异化阈值：对女性群体使用更低的阈值（牺牲男性性能，提升公平性）
4. 人类审核：对高风险女性申请进行人工复核，纠正模型偏见

真实案例: COMPAS算法（司法量刑）

背景:
COMPAS（Correctional Offender Management Profiling for Alternative Sanctions）
是美国使用的"再犯风险预测"系统。

偏见来源:
1. 数据偏见: 训练数据中，非裔美国人被逮捕率更高（历史上警力
   部署不均），模型学会"种族 → 高风险"
2. 代理变量: 虽然种族变量被删除，但模型通过"社会经济地位"、
   "教育水平"、"邮政编码"等代理变量间接推断种族
3. 反馈循环: COMPAS预测高风险的人更容易被逮捕（警察更关注他们），
   形成自我实现的预言

公平性问题:
- 非裔美国人的假阳性率（被误判为高风险）是白人的2倍
- 非裔美国人的假阴性率（实际高风险但被误判为低风险）更低，
  说明模型对白人更"宽容"

解决措施:
- ProPublica调查曝光后，COMPAS供应商修正了算法
- 使用公平性约束的模型（equalized odds postprocessing）
- 透明度要求：法院必须告知被告"COMPAS评分"及依据
```

**评分标准**：
- 数据偏见分析深入（7 分）
- 算法偏见分析准确（7 分）
- 反馈循环模拟合理（6 分）
- 真实案例研究完整（5 分）

---

### 任务 5：差分隐私实现——通过噪声保护隐私（20 分）

**目标**：理解差分隐私的基本原理，实现简单的差分隐私机制

**背景**：阿码在第 2 节看到了隐私风险。老潘说："**差分隐私通过添加噪声保护隐私**。"

阿码好奇："**加了噪声，数据还有用吗？**"

老潘说："**关键在于'控制噪声量'——ε 越小，隐私保护越强，但数据实用性越低**。"

**步骤**：

1. **实现拉普拉斯机制**：
   - 选择一个统计量（如收入均值、违约率）
   - 计算全局敏感度 Δf = max(统计量) - min(统计量)
   - 添加拉普拉斯噪声：`noise ~ Laplace(0, Δf/ε)`
   - 输出：私有统计量 = 真实统计量 + noise

2. **对比不同 ε 值**：
   - 尝试 ε = [0.1, 0.5, 1.0, 5.0, 10.0]
   - 对比：真实统计量 vs 私有统计量的差异
   - 分析：ε 越小，噪声越大，隐私保护越强

3. **验证隐私保护**：
   - 模拟攻击：攻击者能否从私有统计量中确定"某条记录是否存在"？
   - 示例：加入/删除一条记录，私有统计量的变化是否显著？
   - 判断：如果变化 < 噪声水平，则隐私保护有效

4. **连接 SmartNoise SDK（可选）**：
   - 安装 `smartnoise-synth`
   - 使用 `PrivateReader` 执行私有 SQL 查询
   - 对比：手动添加噪声 vs SmartNoise 自动添加噪声

5. **提交** `differential_privacy.md`，包含：
   - 拉普拉斯机制实现代码
   - 不同 ε 值的对比表（真实值 vs 私有值 vs 差异）
   - 隐私保护验证分析
   - ε 选择建议（如何平衡隐私和实用性）

**输出示例**：
```
拉普拉斯机制实现:
统计量: 收入均值
真实值: 58500 元
全局敏感度: Δf = 200000 - 0 = 200000（假设收入范围[0, 20万]）

不同ε值的对比:

ε  | 噪声尺度(Δf/ε) | 私有均值 | 差异  | 隐私保护强度
---|----------------|----------|-------|-------------
0.1| 2000000        | 124567  | +66067| 极强（几乎无信息）
0.5| 400000         | 82134   | +23634| 强
1.0| 200000         | 72345   | +13845| 中等（推荐）
5.0| 40000          | 61234   | +2734 | 弱
10.0| 20000         | 59876   | +1376 | 极弱（几乎无保护）

观察:
- ε=0.1: 噪声太大，私有均值(124567)远离真实值(58500)，数据无实用价值
- ε=1.0: 噪声适中，私有均值(72345)在真实值附近波动，仍有参考价值
- ε=10.0: 噪声很小，私有均值(59876)接近真实值，但隐私保护弱

ε选择建议:
- ε=1.0被认为是"可接受的平衡点"
- 高敏感数据（医疗、 genomic）: ε=0.1-0.5
- 一般敏感数据（收入、消费）: ε=1.0-5.0
- 低敏感数据（匿名化统计数据）: ε=5.0-10.0

隐私保护验证:
攻击场景: 攻击者想知道"张三（收入5万）是否在数据集中"

方法1: 加入张三后，观察私有均值变化
- 加入前: 私有均值=72345 (ε=1.0)
- 加入后: 私有均值=73101
- 变化: +756 < 噪声水平(200000)

结论: 攻击者无法确定"张三是否在数据集中"，因为变化量小于噪声，
差分隐私保护有效。

方法2: 反复查询攻击
如果攻击者可以无限次查询（ε=1.0 每次），总隐私损失=1.0×查询次数
- 查询1次: ε=1.0，隐私损失低
- 查询100次: ε=100.0，隐私损失高，几乎无保护

结论: 必须限制查询频率或设置隐私预算上限（如总ε≤10）

SmartNoise SDK对比:
手动添加噪声 vs SmartNoise自动添加噪声:
- 手动: 需要自己计算敏感度、添加噪声，容易出错
- SmartNoise: 自动计算敏感度、添加噪声，确保总隐私损失≤ε

推荐: 生产环境使用SmartNoise，学习时手动实现加深理解
```

**评分标准**：
- 拉普拉斯机制实现正确（7 分）
- 不同 ε 值对比完整（6 分）
- 隐私保护验证合理（4 分）
- ε 选择建议准确（3 分）

---

## 挑战作业（可选）

### 任务 6：StatLab 模型解释与伦理审查完整流水线（40 分）

**目标**：将你的 StatLab 报告扩展到模型解释与伦理审查，产出完整的可信建模章节

**背景**：到上周为止，StatLab 报告已经有了数据卡、描述统计、清洗日志、EDA 叙事、假设检验、不确定性量化、回归分析、分类评估、树模型。但老潘问："**如果你的读者不是统计学博士，而是产品经理、客户、合规官员，他们能看懂吗？**"

小北想了想："**呃……我用了'AUC = 0.85'、'SHAP 值'、'差异影响比'这些术语，他们可能看不懂**。"

老潘点头："**你需要用客户能懂的语言解释模型**。"

**要求**：

1. **在 report.md 中添加"模型解释与伦理审查"章节**，包含：
   - 研究问题：模型是否可解释、是否存在偏见、如何保护隐私
   - SHAP 可解释性：全局解释 + 局部解释
   - 公平性评估：不同群体的性能差异 + 公平性指标
   - 偏见来源分析：数据偏见、算法偏见、代理变量
   - 伦理审查清单：完整的风险评估
   - 向非技术读者解释：客户版、产品经理版、合规部门版

2. **使用示例代码**：
   - 参考 `examples/12_statlab_xai.py`
   - 或使用 `starter_code/solution.py` 作为参考

3. **可视化**：
   - SHAP summary_plot（全局解释）
   - SHAP force_plot（局部解释）
   - 公平性对比图（群体性能条形图）
   - 代理变量相关性热力图

4. **提交**：
   - 更新的 `report.md`（添加模型解释与伦理审查章节）
   - XAI 代码文件 `xai_ethics.py`
   - 所有可视化图表文件

**输出示例结构**：
```markdown
## 模型解释与伦理审查

### 研究问题
前几章我们建立了预测模型并评估了性能，但没有回答三个关键问题：
1. 模型是否可解释？能否向用户解释"为什么是这个预测"？
2. 模型是否存在偏见？是否对某些群体不公平？
3. 模型的局限性是什么？哪些场景下会失效？

本章使用 **SHAP（SHapley Additive exPlanations）** 进行可解释性分析，
并对不同群体进行公平性评估。

### SHAP 可解释性

#### 全局解释：哪些特征最重要？

SHAP 全局解释（summary_plot）展示了所有特征的重要性与影响方向：

![SHAP 全局解释](shap_summary.png)

**解读**:
- 横轴：SHAP 值（正值表示提高预测值，负值表示降低预测值）
- 颜色：特征值（红色=高，蓝色=低）
- 最重要的特征: {feature_1}、{feature_2}
- 发现: {观察模式，如"高收入降低违约概率"}

#### 局部解释：为什么是这个预测？

SHAP 局部解释（force_plot）展示了单个预测的"推理路径"：

![SHAP 局部解释](shap_force_sample_0.png)

**如何向客户解释**:
> "您的{'通过/拒绝'}主要因为 [1-2 个最显著特征]。[具体原因]。
> 如果您能[改进建议]，通过概率会提升。"

### 公平性评估

我们检查了模型在不同敏感特征（{敏感特征列表}）上的表现差异。

#### 性能差异表

| 敏感特征 | 群体 A | 群体 B | AUC 差异 | 通过率 A | 通过率 B | 差异影响比 |
|---------|--------|--------|----------|----------|----------|------------|
| {特征1}  | {值}   | {值}   | {值}     | {值}     | {值}     | {值}       |

**解读**:
- ⚠️ **{敏感特征}**: AUC 差异为 {值}，说明模型在不同群体上的性能存在显著差异
- ⚠️ **{敏感特征}**: 差异影响比 = {值} < 0.8，不符合 80% 规则，可能存在法律风险

### 偏见来源分析

模型偏见有三个主要来源：

1. **数据偏见**: [分析训练数据是否存在历史歧视]
2. **算法偏见**: [分析模型是否放大数据中的模式]
3. **代理变量**: [检测与敏感特征高度相关的代理变量]

**代理变量检测结果**:
- {proxy_1}: 与{敏感特征}相关性 = {值}
- {proxy_2}: 与{敏感特征}相关性 = {值}

### 伦理审查清单

| 风险类别 | 检查项 | 状态 |
|---------|--------|------|
| **数据偏见** | 训练数据是否存在历史歧视？ | [ ] 需检查 |
| **算法偏见** | 模型是否放大数据中的模式？ | [ ] 需检查 |
| **代理变量** | 是否存在敏感属性的代理变量？ | [ ] 需检查 |
| **公平性指标** | 差异影响比是否 ≥ 0.8？ | [ ] 需检查 |
| **隐私风险** | 数据发布是否使用差分隐私？ | [ ] 需检查 |
| **可复现性** | 模型是否能被独立验证？ | [ ] ✅ |
| **结论边界** | 模型的局限性是否明确？ | [ ] ✅ |

### 向非技术读者解释

#### 客户版（说人话）

> "您的{'通过/拒绝'}主要因为 [原因1] 和 [原因2]。[具体解释，用客户能懂的语言]。
>
> 模型的局限性：[简单说明，如'模型基于历史数据，无法预测特殊情况']"

#### 产品经理版（关注性能和风险）

> "模型性能：
> - 整体 AUC = {值}，准确率 = {值}
> - 不同群体性能差异：[说明]
> - 主要风险：[公平性、隐私等]
> - 改进建议：[数据、算法、后处理]"

#### 合规部门版（关注法律和伦理）

> "公平性审计：
> - 差异影响比 = {值}（是否合规）
> - 差异影响比 = {值} < 0.8，不符合 80% 规则，我们已 [改进措施]
>
> 隐私保护：
> - 数据发布使用差分隐私（ε = {值}），符合 GDPR 要求
> - 可复现性：随机种子、代码、数据来源均有记录"
```

**评分标准**：
- 报告结构完整（10 分）
- SHAP 分析深入（8 分）
- 公平性评估完整（8 分）
- 伦理审查清单齐全（6 分）
- 向非技术读者解释清晰（8 分）

---

## AI 协作练习（可选）

### 任务 7：审查 AI 生成的 SHAP 分析（25 分）

**背景**：根据 `shared/ai_progression.md`，Week 12 属于**"协作期"**（Week 09-12）——AI 辅助建模与评估，但关键决策由你主导。你需要学会审查 AI 生成的可解释性分析。

**步骤**：

1. **获取 AI 生成的代码**：
   - 使用你喜欢的 AI 工具（如 ChatGPT、Claude 等）
   - 输入以下提示词：
     ```
     我有一个信用评分数据集，已经训练了随机森林模型（AUC=0.85）。
     请帮我用 SHAP 进行模型解释，包括：
     1. 计算 SHAP 值
     2. 绘制 summary_plot（全局解释）
     3. 解释一个样本的预测（force_plot）
     4. 分析哪些特征最重要
     ```

2. **保存 AI 原始输出**，将其保存为 `ai_original_shap_code.txt`

3. **使用审查清单**：

   检查 AI 代码是否包含以下内容：
   - [ ] 是否使用了正确的 SHAP 解释器（TreeExplainer for 树模型）？
   - [ ] 是否检查了 SHAP 值的可加性（基准值 + 贡献 = 预测值）？
   - [ ] 是否警告"SHAP 值 ≠ 因果关系"？
   - [ ] 是否分析了 SHAP 值的不确定性（置信区间/标准差）？
   - [ ] 是否连接了特征重要性和 SHAP 值的区别？
   - [ ] 可视化是否有清晰的标注（标题、轴标签、图例）？
   - [ ] 是否提供了"如何向客户解释"的示例？
   - [ ] 是否检查了代理变量（与敏感特征相关的特征）？

4. **写一份审查报告** `ai_shap_review.md`，包含：
   - AI 原始代码（摘要，150 字）
   - 缺失项列表（按严重性分类：高/中/低）
   - 代码问题分析（如有）
   - 你的修正版代码（补充缺失检查、修正错误）
   - 反思（200 字）：
     - AI 在 SHAP 分析上表现如何？
     - 哪些工程实践 AI 容易遗漏？
     - AI 会主动警告"SHAP ≠ 因果"吗？
     - 你认为人类必须检查哪些部分？

**评分标准**：
- 审查全面性（10 分）
- 问题分类合理（5 分）
- 修正版代码正确（7 分）
- 反思深入（3 分）

**审查清单示例**：
```
AI SHAP 代码审查结果:

缺失项（严重性：高）:
- ❌ 未警告"SHAP值≠因果关系"（可能误导业务决策）
- ❌ 未检查SHAP值的不确定性（SHAP值是估计值，有误差）
- ❌ 未说明特征重要性和SHAP值的区别（AI混淆了全局和局部解释）

缺失项（严重性：中）:
- ⚠️ 未提供"如何向客户解释"的示例（技术语言，客户听不懂）
- ⚠️ 未检查代理变量（与敏感特征相关的特征）
- ⚠️ 可视化缺少清晰标注（无标题、轴标签）

缺失项（严重性：低）:
- ℹ️ 未使用matplotlib中文显示（中文标签显示为方框）
- ℹ️ 未保存图表到文件（只是plt.show()，无法插入报告）

代码问题:
- ⚠️ AI使用了LinearExplainer解释随机森林（应该用TreeExplainer，更快更准确）
- ⚠️ AI未设置随机种子（SHAP值计算有随机性，结果不可复现）

AI 在SHAP分析上的表现:
- 优点: API使用正确、能生成基本可视化、能识别重要特征
- 缺点: 容易混淆全局/局部解释、不会主动警告因果陷阱、
  不会提供业务场景的解释模板

人类必须检查的部分:
1. SHAP值≠因果关系的警告（AI不会主动加）
2. 不确定性量化（Bootstrap估计SHAP值的置信区间）
3. 向非技术读者解释（AI只会用技术术语）
4. 代理变量检测（AI不会主动检查敏感特征）
```

---

## StatLab 集成

**要求**：本周所有基础作业的产出应整合到你的 StatLab 报告中

**具体操作**：

1. 在你的 `report.md` 中添加"模型解释与伦理审查"章节
2. 使用任务 6 的模板结构
3. 包含以下内容：
   - SHAP 可解释性（全局 + 局部）
   - 公平性评估（群体性能差异 + 公平性指标）
   - 偏见来源分析（数据、算法、代理变量）
   - 伦理审查清单（完整的风险评估）
   - 向非技术读者解释（三个版本：客户、产品经理、合规部门）

---

## 提交方式

1. 将所有文件放入 `chapters/week_12/assignment/` 目录
2. 文件命名规范：
   - `shap_explanation.md`
   - `fairness_metrics.md`
   - `ethics_review_checklist.md`
   - `bias_source_analysis.md`（进阶）
   - `differential_privacy.md`（进阶）
   - `xai_ethics.py` + `report.md`（挑战）
   - `ai_original_shap_code.txt`（AI 协作）
   - `ai_shap_review.md`（AI 协作）
3. 确保所有 Markdown 文档使用清晰的章节结构
4. 可视化图表可以嵌入文档或单独提交

---

## 作业提示

1. **SHAP 值 ≠ 因果关系**：收入重要不代表"提高收入会降低违约"，SHAP 是模型依赖，不是因果机制

2. **特征重要性是全局的，SHAP 是局部的**：特征重要性只回答"整体上哪些特征重要"，SHAP 能回答"对某个样本，每个特征贡献了多少"

3. **公平性没有万能定义**：差异影响比、平等机会、均等几率是不同的公平性定义，根据业务场景选择

4. **删除敏感变量不够**：即使删除性别，模型可能通过代理变量（职位、邮政编码）间接学到性别

5. **差分隐私是隐私保护，不是数据质量**：ε 越小，隐私保护越强，但数据实用性越低，需要权衡

6. **向非技术读者解释**：不要用"SHAP 值"或"AUC"，用客户能懂的语言（"低于平均水平"、"近期查询多"）

7. **伦理审查不是一次做完**：每次建模前、中、后都要检查偏见、公平性、隐私、可复现性

8. **AI 是加速器，不是决策者**：AI 可以计算 SHAP 值、绘制图表，但警告因果陷阱、检查代理变量、向客户解释的责任由你承担

9. **如果遇到困难**：可以参考 `starter_code/solution.py`（如果存在），但不要直接复制粘贴

---

## 常见错误

- ❌ 直接解释 SHAP 值为因果（"收入贡献 +0.3，所以提高收入会降低违约"）
- ❌ 只看特征重要性，不看 SHAP（无法解释单个样本）
- ❌ 只看整体 AUC，不看群体性能差异（忽略偏见）
- ❌ 删除敏感变量以为解决偏见（未检测代理变量）
- ❌ 差异影响比 < 0.8，却说"模型公平"（未识别法律风险）
- ❌ 向客户解释用"SHAP 值"或"AUC"（对方听不懂）
- ❌ 未说明模型能/不能回答什么（过度承诺模型能力）
- ❌ 未设置 `random_state`（SHAP 值不可复现）
- ❌ 未警告"SHAP 值有不确定性"（假装精确）
- ❌ 伦理审查清单只是打勾（没有证据支撑）
- ❌ 向非技术读者只有一版解释（客户、产品经理、合规部门需要不同的语言）
