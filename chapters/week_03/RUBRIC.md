# Week 03 评分标准（Rubric）

## 评分维度与权重

| 维度 | 权重 | 说明 |
|------|------|------|
| 缺失值处理 | 25% | 机制判断准确、策略选择合理、记录完整 |
| 异常值处理 | 25% | 检测方法正确、业务规则合理、分类清晰 |
| 特征变换 | 25% | 方法选择恰当、实现正确、解释清晰 |
| 清洗日志 | 15% | 格式规范、内容完整、可追溯 |
| 代码质量 | 10% | 可读性、注释、复用性 |

---

## 详细评分标准

### 1. 缺失值处理（25 分）

| 评分项 | 分值 | 优秀（A） | 良好（B） | 合格（C） | 不合格（F） |
|--------|------|-----------|-----------|-----------|-------------|
| 缺失概览 | 5 | 计算所有列的缺失率和缺失数，按缺失率排序 | 计算了主要列的缺失率 | 只计算了部分列 | 未计算或计算错误 |
| 模式分析 | 10 | 对缺失率>5%的列，分析至少2个相关字段的分布差异，用数据支持判断 | 分析了至少1个相关字段 | 简单提及但未用数据分析 | 未进行模式分析 |
| 机制判断 | 5 | 正确区分 MCAR/MAR/MNAR，判断有依据 | 基本正确，依据不够充分 | 判断有误但能自圆其说 | 判断明显错误或缺失 |
| 策略选择 | 5 | 策略与机制匹配，理由充分（如 MAR 用分组填充） | 策略基本合理 | 策略与机制不完全匹配 | 策略明显不当（如全部填0） |

**验证方式**：
- 检查脚本 `01_missing_analysis.py` 的输出
- 检查 report.md 中的缺失值处理表格
- 测试：用锚点数据验证缺失率计算是否正确

---

### 2. 异常值处理（25 分）

| 评分项 | 分值 | 优秀（A） | 良好（B） | 合格（C） | 不合格（F） |
|--------|------|-----------|-----------|-----------|-------------|
| 检测方法 | 8 | 正确使用 IQR 方法，记录 Q1/Q3/IQR/上下界 | 使用正确但记录不完整 | 方法正确但计算有误 | 方法选择不当（如对偏斜数据用 Z-score） |
| 业务规则 | 10 | 设计至少3类规则（错误/VIP/待确认），规则有业务逻辑 | 设计2-3类规则 | 只有删除/保留两类 | 无业务规则，直接删除所有异常点 |
| 处理决策 | 7 | 不同类别有不同处理策略，记录清晰 | 有分类处理但记录不够详细 | 处理策略单一 | 全部删除或全部保留 |

**验证方式**：
- 检查脚本 `02_outlier_detection.py` 的输出
- 检查异常值分类表格
- 测试：用锚点数据验证 IQR 计算和分类逻辑

---

### 3. 特征变换（25 分）

| 评分项 | 分值 | 优秀（A） | 良好（B） | 合格（C） | 不合格（F） |
|--------|------|-----------|-----------|-----------|-------------|
| 数值缩放 | 10 | 根据分布选择 StandardScaler/MinMaxScaler，记录变换前后对比 | 方法选择基本合理 | 方法选择有瑕疵但可用 | 方法明显不当（如对偏斜数据用 StandardScaler 且无说明） |
| 类别编码 | 10 | 正确区分 nominal/ordinal，选择对应编码方式 | 基本正确 | 有混淆但能运行 | 对 nominal 用 label 编码 |
| 函数封装 | 5 | 写成可复用函数，返回变换器和变换后数据 | 有函数封装但不够完整 | 有函数但无法复用 | 全是脚本，无函数封装 |

**验证方式**：
- 检查脚本 `03_feature_transform.py`
- 检查变换前后描述统计对比
- 测试：函数是否能应用到新数据

---

### 4. 清洗日志（15 分）

| 评分项 | 分值 | 优秀（A） | 良好（B） | 合格（C） | 不合格（F） |
|--------|------|-----------|-----------|-----------|-------------|
| 格式规范 | 5 | 使用 markdown 表格，结构清晰 | 格式基本规范 | 有表格但格式混乱 | 无表格或纯文本 |
| 内容完整 | 6 | 每个决策包含：问题、策略、理由、替代方案、影响 | 包含主要要素（问题、策略、理由） | 缺少部分要素 | 只有策略，无其他信息 |
| 可追溯性 | 4 | 有时间戳，决策与代码可对应 | 有基本对应关系 | 对应关系模糊 | 无法对应到具体代码 |

**验证方式**：
- 检查 report.md 中的清洗日志章节
- 对比日志与脚本的一致性

---

### 5. 代码质量（10 分）

| 评分项 | 分值 | 优秀（A） | 良好（B） | 合格（C） | 不合格（F） |
|--------|------|-----------|-----------|-----------|-------------|
| 可读性 | 4 | 变量名清晰，逻辑分段，有适当空行 | 基本可读 | 变量名随意，逻辑混乱 | 难以阅读 |
| 注释 | 3 | 关键步骤有注释，解释"为什么" | 有注释但不够详细 | 只有少量注释 | 无注释 |
| 复用性 | 3 | 函数封装良好，参数化设计 | 有函数封装 | 硬编码较多 | 无法复用 |

---

## 等级标准

| 等级 | 分数区间 | 描述 |
|------|----------|------|
| **优秀（A）** | 90-100% | 所有要求完成，有额外思考。缺失机制判断准确，异常值分类有创意，特征变换方法选择有依据，清洗日志详细可追溯。 |
| **良好（B）** | 80-89% | 核心要求完成，minor issues。各任务基本完成，但某些方面（如模式分析深度、业务规则设计）可以更深入。 |
| **合格（C）** | 70-79% | 基本完成，有明显不足。如缺失机制判断有误、异常值全部删除、编码方式选择不当等。 |
| **待改进（F）** | <70% | 未完成核心要求。如缺少关键任务、代码无法运行、清洗日志缺失等。 |

---

## 检查清单（供助教/自测使用）

### 缺失值处理
- [ ] 计算了所有列的缺失率和缺失数
- [ ] 对缺失率>5%的列进行了模式分析
- [ ] 判断了缺失机制（MCAR/MAR/MNAR）
- [ ] 选择了与机制匹配的处理策略
- [ ] 记录了选择理由

### 异常值处理
- [ ] 使用 IQR 方法检测异常值
- [ ] 记录了 Q1/Q3/IQR/上下界
- [ ] 设计了业务规则对异常值分类
- [ ] 不同类别有不同的处理策略
- [ ] 记录了处理决策

### 特征变换
- [ ] 对数值特征进行了缩放
- [ ] 方法选择有依据（StandardScaler/MinMaxScaler）
- [ ] 对类别特征进行了编码
- [ ] 正确区分 nominal/ordinal
- [ ] 写成了可复用的函数

### 清洗日志
- [ ] 日志追加到 report.md
- [ ] 使用 markdown 表格格式
- [ ] 包含问题、策略、理由、替代方案、影响
- [ ] 有时间戳
- [ ] 决策与代码可对应

### 代码质量
- [ ] 变量名清晰
- [ ] 有适当注释
- [ ] 函数封装良好
- [ ] 代码可运行

---

## 常见扣分点

| 问题 | 扣分 | 说明 |
|------|------|------|
| 缺失值全部填 0 | -10 | 未分析机制，直接填 0 |
| 异常值全部删除 | -10 | 未分类，直接删除 |
| 对 nominal 用 label 编码 | -8 | 编码方式错误 |
| 清洗日志缺失 | -15 | 无日志或日志不完整 |
| 代码无法运行 | -20 | 有语法错误或依赖缺失 |
| 未提交到 git | -5 | 无 commit 记录 |

---

## 加分项（最高 +10 分）

| 加分项 | 分值 | 说明 |
|--------|------|------|
| 缺失机制启发式判断函数 | +5 | 实现了任务 5 的函数 |
| 填充策略对比分析 | +5 | 完成了任务 6 的对比实验 |
| 清洗流水线封装 | +5 | 实现了任务 7 的 DataCleaner 类 |
| 单元测试 | +3 | 为关键函数编写了测试 |
| 可视化 | +2 | 用图表展示清洗前后对比 |

---

## 自动化测试锚点

以下测试用例用于验证作业实现：

```python
# tests/test_week03.py

import pandas as pd
import numpy as np

def test_missing_rate_calculation():
    """测试缺失率计算正确。"""
    df = pd.DataFrame({
        'a': [1, 2, np.nan, 4],
        'b': [1, 2, 3, 4]
    })
    missing_rate = df.isna().mean()
    assert missing_rate['a'] == 0.25
    assert missing_rate['b'] == 0.0

def test_iqr_outlier_detection():
    """测试 IQR 异常值检测正确。"""
    data = [1, 2, 3, 4, 5, 6, 7, 8, 9, 100]  # 100 是异常值
    Q1 = np.percentile(data, 25)
    Q3 = np.percentile(data, 75)
    IQR = Q3 - Q1
    upper = Q3 + 1.5 * IQR
    assert 100 > upper  # 100 应该被检测为异常值

def test_standard_scaler():
    """测试 StandardScaler 变换正确。"""
    from sklearn.preprocessing import StandardScaler
    data = [[1], [2], [3]]
    scaler = StandardScaler()
    scaled = scaler.fit_transform(data)
    assert np.isclose(scaled.mean(), 0)
    assert np.isclose(scaled.std(), 1, atol=0.1)
```

---

**评分人**：____________ **日期**：____________ **总分**：____________
