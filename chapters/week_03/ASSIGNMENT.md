# Week 03 作业：数据清洗与准备

> **提交前自查**：你的清洗决策有记录吗？你的代码能从头到尾复现吗？你的缺失值处理有理由吗？你的异常值删除有依据吗？

---

## 作业目标

本周你将学会把"原始数据"变成"可分析数据"，并记录每一个清洗决策。完成作业后，你将能够：

1. 诊断缺失值的类型（MCAR、MAR、MNAR），选择合适的处理策略
2. 用 IQR 和 Z-score 检测异常值，并区分"错误"与"发现"
3. 理解数据转换的目的（标准化、归一化、对数变换）
4. 掌握特征编码的基本方法（One-hot、Label encoding）
5. 编写清洗日志，让分析变得可复现、可审计

---

## 数据集

继续使用 **Palmer Penguins** 数据集（seaborn 内置）：

```python
import seaborn as sns

penguins = sns.load_dataset("penguins")
```

数据集包含 344 只企鹅的 7 个字段，其中部分字段有缺失值：
- `species`：物种（Adelie、Gentoo、Chinstrap）
- `island`：岛屿
- `bill_length_mm`：嘴峰长度（毫米）
- `bill_depth_mm`：嘴峰深度（毫米）
- `flipper_length_mm`：鳍肢长度（毫米）
- `body_mass_g`：体重（克）
- `sex`：性别

---

## 基础练习（必做，60 分）

### 练习 1：缺失值诊断（15 分）

诊断 penguins 数据集的缺失模式，判断缺失值的类型。

**要求**：
1. 创建一个 `missing_summary` 函数，生成缺失值概览表，包含：
   - 缺失数量
   - 缺失比例（百分比）
   - 缺失位置的前 10 个索引

2. 写一段分析（3-5 句话），回答以下问题：
   - 哪些字段有缺失？缺失率分别是多少？
   - 这些缺失值可能是 MCAR、MAR 还是 MNAR？为什么？
   - 如果缺失率超过 30%，你会怎么做？

**输出示例**：
```
              missing_count  missing_%
sex                    11        3.2
bill_length_mm          2        0.6
bill_depth_mm           2        0.6
flipper_length_mm       2        0.6
body_mass_g             2        0.6
```

**评分点**：
- [ ] 缺失值概览表正确，包含缺失数量和比例
- [ ] 缺失率计算正确（`缺失数 / 总行数 * 100`）
- [ ] 能合理判断缺失值的类型（MCAR/MAR/MNAR），并给出理由
- [ ] 分析清晰，能解释"缺失率超过 30% 意味着什么"

**常见错误**：
- ❌ 直接说"缺失率低所以是 MCAR"，没有考虑缺失模式
- ❌ 没有检查缺失位置，无法判断是否随机
- ❌ 只给数字不解释，没有说明"这个缺失率意味着什么"

**提示**：
- 可以用 `df.isna().sum()` 计算缺失数量
- 可以用 `df.isna().mean() * 100` 计算缺失比例
- 可以用 `df[df['column'].isna()].index` 查看缺失位置

---

### 练习 2：缺失值处理策略（15 分）

根据练习 1 的诊断结果，选择合适的缺失值处理策略。

**要求**：
1. 对 penguins 数据集的缺失值进行处理：
   - 对于 `sex` 字段：删除缺失行（缺失率 3.2%，删除影响不大）
   - 对于数值型字段（`bill_length_mm` 等）：保留缺失值，分析时忽略

2. 对比处理前后的统计量：
   - 处理前的均值、中位数、样本量
   - 处理后的均值、中位数、样本量

3. 写一段分析（3-5 句话），回答以下问题：
   - 删除和填充对均值、中位数的影响有多大？
   - 为什么选择"删除"而不是"填充"？
   - 如果缺失率是 20%，你的选择会变吗？

**输出示例**：
```
                处理前    处理后
样本量           344      333
均值           43.9     44.0
中位数         44.0     44.1
```

**评分点**：
- [ ] 处理策略合理，基于缺失率选择删除或填充
- [ ] 对比分析正确，能计算处理前后的统计量
- [ ] 分析清晰，能解释"删除 vs 填充"的影响
- [ ] 能根据业务场景选择合适的策略

**常见错误**：
- ❌ 直接填充所有缺失值，没有考虑缺失机制
- ❌ 填充成 0 或均值，没有说明理由
- ❌ 只给数字不解释，没有说明"这个策略意味着什么"

**提示**：
- 可以用 `df.dropna(subset=['sex'])` 选择性删除
- 可以用 `df['column'].mean()` 计算均值
- 可以用 `df['column'].median()` 计算中位数

---

### 练习 3：异常值检测（15 分）

用 IQR 和 Z-score 两种方法检测异常值。

**要求**：
1. 实现 `detect_outliers_iqr` 函数，用 IQR 规则检测异常值：
   - 计算下界：Q1 - 1.5 × IQR
   - 计算上界：Q3 + 1.5 × IQR
   - 返回异常值的布尔 Series

2. 实现 `detect_outliers_zscore` 函数，用 Z-score 检测异常值：
   - 计算 Z-score：`(x - mean) / std`
   - 返回 `|Z-score| > 3` 的布尔 Series

3. 对比两种方法的结果：
   - 各检测到多少个异常值？
   - 两种方法的检测结果一致吗？如果不一致，为什么？

4. 写一段分析（3-5 句话），回答以下问题：
   - 两种方法各有什么优势？
   - 如果数据有偏态，应该用哪种方法？
   - 检测到的异常值是"错误"还是"发现"？

**输出示例**：
```
IQR 规则检测到 0 个异常值
Z-score 规则检测到 0 个异常值
```

**评分点**：
- [ ] IQR 规则实现正确，公式准确
- [ ] Z-score 实现正确，阈值合理
- [ ] 对比分析清晰，能解释两种方法的差异
- [ ] 能判断异常值是"错误"还是"发现"

**常见错误**：
- ❌ IQR 公式错误（例如用 Q75/Q25 而不是差值）
- ❌ Z-score 阈值设置不合理（如 2 或 5）
- ❌ 只给数字不解释，没有说明"检测结果意味着什么"

**提示**：
- 可以用 `series.quantile(0.25)` 和 `series.quantile(0.75)` 计算 Q1 和 Q3
- 可以用 `np.abs((series - series.mean()) / series.std())` 计算 Z-score
- 可以用 `outliers.sum()` 统计异常值数量
- **注意**：如果 `series.std() == 0`（常量列），Z-score 会除零，需要先处理这种情况

---

### 练习 4：数据转换（15 分）

对 penguins 数据集进行标准化和归一化。

**要求**：
1. 选择两个数值型变量（如 `bill_length_mm` 和 `body_mass_g`）进行：
   - **标准化**：减去均值，除以标准差
   - **归一化**：缩放到 [0, 1] 区间

2. 对比转换前后的统计量：
   - 原始数据的均值、标准差、最小值、最大值
   - 标准化后的均值、标准差
   - 归一化后的最小值、最大值

3. 写一段分析（3-5 句话），回答以下问题：
   - 标准化和归一化有什么区别？
   - 什么时候应该用标准化？什么时候用归一化？
   - 如果有一个新数据点（如新企鹅），如何应用转换？

**输出示例**：
```
              原始数据    标准化后    归一化后
均值           43.9        0.0        0.42
标准差          5.5        1.0        0.14
最小值         32.1       -2.1        0.0
最大值         59.6        2.9        1.0
```

**评分点**：
- [ ] 标准化实现正确，公式准确
- [ ] 归一化实现正确，缩放正确
- [ ] 对比分析清晰，能解释两种转换的差异
- [ ] 能说明标准化和归一化的适用场景

**常见错误**：
- ❌ 标准化公式错误（例如除以方差而不是标准差）
- ❌ 归一化公式错误（例如没有减去最小值）
- ❌ 只给数字不解释，没有说明"转换的目的是什么"

**提示**：
- 可以用 `(series - series.mean()) / series.std()` 进行标准化
- 可以用 `(series - series.min()) / (series.max() - series.min())` 进行归一化
- 或者使用 `sklearn.preprocessing.StandardScaler` 和 `MinMaxScaler`

---

## 进阶练习（选做，30 分）

### 练习 5：综合清洗流程（20 分）

把上述练习整合成一个完整的清洗流水线。

**要求**：
1. 创建一个 `DataCleaner` 类，包含以下方法：
   - `diagnose_missing()`：诊断缺失值
   - `handle_missing()`：处理缺失值
   - `detect_outliers()`：检测异常值
   - `transform_data()`：数据转换

2. 编写一个脚本，完成以下任务：
   - 读取 penguins 数据集
   - 诊断缺失值和异常值
   - 处理缺失值
   - 进行数据转换
   - 保存清洗后的数据

3. 生成一份清洗日志（Markdown 格式），包含：
   - 缺失值处理决策和理由
   - 异常值处理决策和理由
   - 数据转换记录

**输出示例**（`cleaning_log.md` 片段）：
```markdown
# 数据清洗日志

## 缺失值处理
- **sex**：删除缺失行（原因：缺失率仅 3.2%，删除影响不大）

## 异常值处理
- **body_mass_g**：保留所有值（原因：IQR 规则未检测到异常值）

## 数据转换
- **bill_length_mm**：标准化（原因：与 body_mass_g 在同一尺度下比较）
```

**评分点**：
- [ ] `DataCleaner` 类结构清晰，方法划分合理
- [ ] 清洗流程完整，能从头到尾运行
- [ ] 清洗日志格式正确，内容完整
- [ ] 每个清洗决策都有理由

**常见错误**：
- ❌ 代码结构混乱，没有封装成类
- ❌ 清洗日志太简单，没有记录决策理由
- ❌ 代码只 print 不写文件

**提示**：
- 可以用 `class DataCleaner:` 封装清洗逻辑
- 可以用 `self.log = []` 记录清洗决策
- 可以用 `Path("output/cleaning_log.md").write_text()` 写入文件

---

### 练习 6：特征编码（10 分）

对 penguins 数据集的分类变量进行编码。

**要求**：
1. 对 `species` 字段进行 One-hot 编码：
   - 使用 `pd.get_dummies()` 或 `sklearn.preprocessing.OneHotEncoder`
   - 设置 `drop_first=True` 避免多重共线性

2. 对 `island` 字段进行 Label 编码：
   - 使用 `sklearn.preprocessing.LabelEncoder`
   - 创建一个映射表，记录编码关系

3. 写一段分析（3-5 句话），回答以下问题：
   - One-hot 编码和 Label 编码有什么区别？
   - 什么时候应该用 One-hot？什么时候用 Label？
   - `species` 和 `island` 各适合哪种编码？为什么？

**输出示例**：
```
One-hot 编码（species）：
  species_Chinstrap  species_Gentoo
0                  0               0
1                  0               0
...

Label 编码（island）：
  Biscoe -> 0
  Dream -> 1
  Torgersen -> 2
```

**评分点**：
- [ ] One-hot 编码实现正确，使用了 `drop_first`
- [ ] Label 编码实现正确，有映射表
- [ ] 分析清晰，能解释两种编码的区别
- [ ] 能根据变量类型选择合适的编码

**常见错误**：
- ❌ One-hot 编码没有设置 `drop_first=True`
- [ ] Label 编码没有记录映射表
- ❌ 只给编码结果不解释，没有说明"为什么选这个编码"

**提示**：
- 可以用 `pd.get_dummies(df['species'], prefix='species', drop_first=True)` 进行 One-hot 编码
- 可以用 `LabelEncoder().fit_transform(df['island'])` 进行 Label 编码
- 可以用 `dict(zip(le.classes_, le.transform(le.classes_)))` 创建映射表

---

## 挑战练习（选做，10 分）

### 练习 7：AI 清洗代码审查（10 分）

下面这段代码是某个 AI 工具生成的"数据清洗"代码。请审查它并修复问题。

```python
# AI 生成的代码（故意包含 3 个问题）
import pandas as pd
import seaborn as sns

penguins = sns.load_dataset("penguins")

# 问题 1：直接填充所有缺失值为 0
penguins.fillna(0, inplace=True)

# 问题 2：删除所有"看起来奇怪"的值
penguins = penguins[penguins['body_mass_g'] < 6000]

# 问题 3：对分类变量进行 Label 编码
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
penguins['species'] = le.fit_transform(penguins['species'])
```

**要求**：
1. **审查清单**（打钩）：
   - [ ] 填充缺失值为 0 合理吗？为什么？
   - [ ] 删除"看起来奇怪"的值有依据吗？为什么？
   - [ ] 对 `species` 用 Label 编码合适吗？为什么？
   - [ ] 有没有记录清洗决策？
   - [ ] 代码能复现吗？

2. **修复代码**：写一段修复后的代码，让清洗更合理

3. **审查报告**：写一段简短说明（300 字以内），你发现了哪些问题，为什么要修复

**评分点**：
- [ ] 审查清单完整，能识别至少 3 个问题
- [ ] 修复后的代码符合本周学到的清洗原则
- [ ] 审查报告清晰，能解释为什么要修复

**提示**：
- 回顾本周学到的内容：缺失值机制、异常值类型、特征编码
- 思考：填充 0 对统计量的影响？删除异常值的依据？Label 编码的适用场景？
- 修复后的代码应该包含清洗日志

---

## 提交要求

### 必交内容（基础练习）

1. **`exercise1_missing_diagnosis.py`**：缺失值诊断的代码
2. **`exercise2_missing_strategy.py`**：缺失值处理的代码
3. **`exercise3_outlier_detection.py`**：异常值检测的代码
4. **`exercise4_data_transformation.py`**：数据转换的代码

### 选交内容（进阶/挑战练习）

5. **`exercise5_cleaning_pipeline.py`**：综合清洗流程的代码
6. **`cleaning_log.md`**：生成的清洗日志
7. **`exercise6_feature_encoding.py`**：特征编码的代码
8. **`exercise7_ai_review.md`**：AI 清洗代码审查报告 + 修复后的代码

### 代码质量要求

- [ ] 代码能从头到尾运行，不报错
- [ ] 有适当的注释，关键步骤有说明
- [ ] 变量命名清晰，不使用 `a`、`b`、`tmp` 这类无意义名称
- [ ] 没有硬编码的绝对路径

### 可复现性要求

- [ ] 清洗后的数据保存为文件（如 `output/penguins_cleaned.csv`）
- [ ] 如果使用随机操作，设置随机种子
- [ ] 附上一份 `README.md`，说明如何运行你的代码

---

## 需要帮助？

如果你遇到困难，可以参考 `starter_code/solution.py` 中的参考实现。但请先自己尝试，再去看答案——直接复制无法建立真正的理解。

常见问题：

**Q: 我应该删除缺失值还是填充？**
A: 取决于缺失率和缺失机制：
- 缺失率 < 5%：直接删除
- 缺失率 5%-30%：考虑填充（中位数/前向填充）
- 缺失率 > 30%：小心！可能需要删除整列

**Q: IQR 和 Z-score，我应该用哪个？**
A: 两种方法各有优势：
- IQR：对分布形态不做假设，更稳健（推荐先用这个）
- Z-score：假设数据近似正态，更敏感（适合对称分布）

**Q: 异常值应该删除吗？**
A: 不一定！先判断异常值的类型：
- 错误型：修正或删除
- 发现型：保留并单独分析
- 边界型：根据业务场景判断

**Q: 我可以使用 AI 工具吗？**
A: 本周建议先自己动手。AI 可以帮你解释概念、调试代码，但不要直接让 AI 生成整个解决方案——你跳过了"挣扎"的过程，也就跳过了真正的学习。

---

## 评分说明

- **基础练习 60 分**：必须完成，每题 15 分
- **进阶练习 30 分**：选做，练习 5 占 20 分，练习 6 占 10 分
- **挑战练习 10 分**：选做

总分不超过 100 分。完成基础练习即可获得 60 分，达到合格线。

详细评分标准见 `RUBRIC.md`。
