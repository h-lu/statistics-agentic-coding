# Week 13：从相关到因果——为什么你的模型不会回答"如果……会怎样"

> "Correlation does not imply causation."
> — Edward Tufte

<!-- 时代脉搏段落 -->
2025年，一位 Uber 数据科学家在博客中分享了一个令人困惑的发现：他们的推荐系统模型显示，向用户推送"附近有豪车可叫"的提示后，用户的下单率显著提高。产品团队兴奋地准备全面推广这个策略——直到一位因果推断专家画了一张因果图。

豪车多的区域往往是市中心的高收入地区，而高收入用户本来就更容易叫车。**不是"豪车提示导致了下单"，而是"高收入地区既有豪车也有更多订单"**。如果真的在低收区域强行推送"豪车提示"，不仅无效，还可能让用户感到困惑。这个发现为公司节省了数百万美元的错误营销投入。

这并不是孤例。同年，LinkedIn 在研究"技能认证对求职成功的影响"时发现：拥有认证的候选人确实更容易被录用。但因果分析显示，真正的原因是**主动去考认证的人本身就更有能力**——"能力 → 认证"和"能力 → 录用"的叉式结构让认证看起来"有效"，实际只是能力的代理变量。

因果推断（Causal Inference）在 2024-2025 年从学术研究迅速走向工业界主流。Netflix 报告他们用因果推断评估"个性化推荐对用户长期留存的影响"，发现优化点击率（相关）可能损害长期满意度（因果反向）。Amazon 在定价决策中引入因果图，避免将"高销量商品与高价相关"误解为"涨价能提高销量"。

本周，你要从"相关思维"升级到"因果思维"——从"模型说了什么"到"如果我们干预会怎样"。这是数据科学家的关键跃迁。

---

## 前情提要

上周（Week 12），小北学会了用 SHAP 解释模型预测："张三的申请被拒是因为收入低、信用查询多。"他也学会了检查模型是否对女性群体存在偏见，用公平性指标量化不公平程度，还知道了差分隐私可以保护个体隐私。

产品经理听完汇报后，点了点头，然后问了下一个问题："所以如果我们给张三提高 10% 的信用额度，他的违约概率会降多少？"

小北愣住了："呃……SHAP 值显示收入贡献了 -0.3，但这是'他的收入对预测的贡献'，不是'如果提高收入会怎样'……"

老潘在一旁开口："你上周学的 SHAP 只能告诉你'模型是怎么预测的'（模型依赖），但不能回答'如果我们改变某个因素，结果会如何'（因果效应）。这是**相关性 vs 因果性**的关键区别。"

阿码好奇："那有什么方法能回答'如果……会怎样'吗？"

"有，"老潘说，"**因果推断（Causal Inference）**。这周你要从'预测'升级到'干预'，从'模型说了什么'到'如果我们做了 X，会发生 Y 吗'。"

---

## 学习目标

完成本周学习后，你将能够：

1. 理解因果推断的三层级框架（关联 → 干预 → 反事实），识别相关性答案与因果性答案的区别
2. 掌握因果图（DAG，有向无环图）的基本语法，能用因果图表达变量间的因果假设
3. 理解混杂变量的定义与机制，能用因果图识别后门路径（spurious paths）
4. 掌握后门准则（Backdoor Criterion），能判断"调整哪些变量就能识别因果效应"
5. 理解随机对照试验（RCT）作为因果推断金标准的原理，以及为什么观察研究中需要因果图
6. 掌握倾向评分匹配（Propensity Score Matching）的基本思想，能用 Python 实现简单的匹配
7. 在 StatLab 报告中绘制因果图，明确说明"能回答什么（因果）、不能回答什么（相关）"
8. 审查 AI 生成的因果结论，识别"把相关当成因果"的常见错误

---

<!--
贯穿案例：优惠券效果的因果推断——从"用了优惠券的人消费更高"到"优惠券让消费提高了多少"

本周贯穿案例是一个经典场景：电商平台发现"使用优惠券的用户，平均消费金额比未使用的高 50 元"。产品经理问："优惠券真的有效吗？还是用优惠券的人本来就更愿意花钱？"

认知负荷预算：
- 本周新概念（4 个，预算上限 4 个）：
  1. 因果三层级（关联/干预/反事实） - 理解层次
  2. 因果图（DAG，混杂、碰撞、链式） - 理解/应用层次
  3. 后门准则 - 分析层次
  4. 倾向评分匹配 - 应用层次
- 结论：✅ 在预算内

回顾桥设计（至少 3 个，来自前 6+ 周）：
- [相关系数]（week_04）：在第 1 节，用"相关系数只能回答'两个变量是否相关'"引出"因果推断回答'如果改变 X，Y 会如何'"
- [混杂变量]（week_04）：在第 2-3 节，用"week_04 的混杂变量定义"连接"因果图中的混杂结构"
- [回归系数]（week_09）：在第 4 节，用"回归系数的陷阱（调整了不该调整的变量）"连接"后门准则（知道该调整什么）"
- [假设检验]（week_06）：在第 4 节，用"假设检验只能回答'差异是否显著'"引出"因果推断回答'差异是因果效应吗'"
- [置信区间]（week_08）：在第 5 节，用"置信区间量化不确定性"连接"因果效应的置信区间"
- [p 值陷阱]（week_06）：在第 1 节，用"p<0.05 不等于因果"引出"因果三层级"

AI 小专栏规划：
AI 小专栏 #1（放在第 1 节之后）：
- 主题：因果推断与 AI 决策系统——为什么 AI 优化的是"预测"，不是"决策"
- 连接点：与第 1 节"因果三层级"呼应，讨论 AI 推荐系统为什么容易把"相关"当成"因果"

AI 小专栏 #2（放在第 3 节之后）：
- 主题：因果图工具——从手绘 DAG 到自动化识别（DoWhy、CausalML）
- 连接点：与第 2-3 节"因果图与后门准则"呼应，介绍 Python 生态中的因果推断库

角色出场规划：
- 小北（第 1、3、5 节）：
  - 在第 1 节，把"用了优惠券的人消费更高"直接当成"优惠券有效"，引出"相关 ≠ 因果"
  - 在第 3 节，困惑于"到底该调整哪些变量"，引出后门准则的必要性
  - 在第 5 节，用简单匹配（直接找相似用户）发现样本太少，引出倾向评分匹配
- 阿码（第 2、4 节）：
  - 在第 2 节，追问"因果图怎么画？有没有规则？"引出 DAG 的三种基本结构
  - 在第 4 节，好奇"为什么要学这个？AI 不能直接告诉我因果效应吗？"引出因果推断的不可替代性
- 老潘（第 1、2、3、4 节）：
  - 在第 1 节，强调"模型只预测，不回答因果"，点破小北的误解
  - 在第 2 节，用工程视角解释"因果图就是显式的假设文档"
  - 在第 3 节，用"后门准则 vs 调整一切"的对比，展示盲目调整的危险
  - 在第 4 节，强调"因果推断不是替代统计检验，而是补充"

StatLab 本周推进：
- 上周状态：StatLab 报告有模型解释（SHAP）、公平性评估、伦理审查，但所有结论都是"相关性"（如"收入与违约相关"），没有回答"如果改变收入，违约会怎样"
- 本周改进：
  1. 在报告开头添加"研究问题与因果层级"：明确区分关联问题（"收入与违约相关吗"）和因果问题（"提高收入会降低违约吗"）
  2. 添加"因果假设图"：用 DAG 表达关键变量的因果假设（如收入 → 违约，混杂：年龄、地区）
  3. 添加"识别策略"：说明用后门准则选择调整集，为什么调整这些变量
  4. 用倾向评分匹配（或分层回归）估计因果效应
  5. 明确"结论边界"：哪些是因果结论，哪些只是相关发现
-->

---

## 1. 我们到底想知道什么？——因果三层级

小北跑进会议室，兴奋地说："我发现了一个规律！使用优惠券的用户，平均消费金额比未使用的高 50 元！所以优惠券真的有效！"

老潘抬头看了他一眼："你确定？"

"当然确定，"小北说，"我做了 t 检验，p < 0.001，差异非常显著！"

阿码举手："但会不会是……本来就更愿意花钱的人，才更愿意领取优惠券？"

老潘点点头："阿码说到点子上了。小北发现的是**关联（Association）**——用券和消费高相关，但未必是**因果（Causation）**——优惠券让消费提高。"

### 从"相关"到"因果"：三个问题层级

**Judea Pearl 的因果三层级**：

| 层级 | 问题类型 | 示例 | 能用什么方法回答 |
|------|---------|------|----------------|
| **1. 关联（Association）** | 变量 X 和 Y 相关吗？ | 用券用户消费更高吗？ | 相关分析、回归、假设检验 |
| **2. 干预（Intervention）** | 如果我们改变 X，Y 会如何？ | 如果给用户发券，消费会提高吗？ | 随机对照试验、因果推断 |
| **3. 反事实（Counterfactual）** | 如果当时没做 X，Y 会怎样？ | 如果这个用户没用券，他会消费多少？ | 反事实推理、个体因果效应 |

小北的问题是第 2 层级（干预）："如果给用户发券，消费会提高多少？"但他用的方法是第 1 层级（关联）："用券用户消费更高吗？"

**这就是陷阱——用"是否相关"的答案，回答"如果干预会怎样"的问题。**

### "哦！"时刻：冰淇淋与犯罪率

"等等，"小北突然想到了什么，"我记得你说过冰淇淋销量和犯罪率正相关……难道是吃冰淇淋让人犯罪？"

老潘笑了："好问题。这就是典型的'相关 ≠ 因果'。冰淇淋销量高的夏天，犯罪率也高——不是因为冰淇淋导致犯罪，而是因为**气温**同时影响了两者。"

老潘在白板上画了一张图：

```
气温 → 冰淇淋销量
  ↓
犯罪率
```

"你看，气温升高，大家更愿意出门买冰淇淋，也更愿意出门活动——包括犯罪活动。冰淇淋和犯罪率一起涨，但它们之间没有因果箭头。"

"哦！"小北恍然大悟，"所以优惠券和消费的差异，也可能是这样？有第三个变量在背后操纵？"

"没错，"老潘说，"比如**用户活跃度**——活跃用户既更愿意领券，也更愿意消费。你不调整活跃度，直接比较用券和未用券用户的消费，就像比较'夏天吃冰淇淋的人'和'冬天不吃冰淇淋的人'。"

### 反向因果：警察越多，犯罪越高？

阿码举手："我还有一个例子。我看过一个研究，说'警察多的地方，犯罪率更高'。难道是警察导致了犯罪？"

"这是**反向因果**的陷阱，"老潘说，"因果方向其实是反过来的：**犯罪多的地方，政府会派更多警察**。如果你裁警，犯罪不会下降——反而可能上升。"

小北在笔记本上写下三条：
1. **混杂变量**：冰淇淋 ← 气温 → 犯罪率（第三方同时影响两者）
2. **反向因果**：犯罪 → 警察（你搞反了因果方向）
3. **选择偏差**：MBA 毕业生收入高，但能考上 MBA 的人本来能力就强

"所以，"小北若有所思，"我看到的 50 元差异，可能混杂了'活跃用户本来就更爱领券也更爱花钱'？"

"对，"老潘说，"下一节我们要学如何用**因果图**把这些关系画出来，混杂变量就会自动浮现。"

### 用一个具体例子理解三层级

想象你在做优惠券 A/B 测试：

**第 1 层级：关联（Observation）**
- 问题："用券用户和未用券用户的消费差异是多少？"
- 答案：50 元（这是小北算出来的）
- 方法：观察数据、比较均值、t 检验
- **局限**：可能有混杂（活跃用户更愿意领券）

**第 2 层级：干预（Intervention）**
- 问题："如果我们给用户发券，他的消费会提高多少？"
- 答案：用因果推断方法（如倾向评分匹配）估计，可能是 30 元（不是 50）
- 方法：随机对照试验（RCT）、倾向评分匹配、工具变量
- **关键**：必须控制混杂变量（用户活跃度、历史消费等）

**第 3 层级：反事实（Counterfactual）**
- 问题："如果张三没用券，他会消费多少？"
- 答案：120 元（他用券后消费了 150 元，所以券的个体因果效应是 30 元）
- 方法：反事实推理（需要强假设）
- **最难的层级**：我们永远无法同时观察"同一个体在两种处理下的结果"

### 连接 Week 04：相关系数 ≠ 因果效应

Week 04 你学过**相关系数**——它衡量两个变量的线性关联强度，但**不回答因果方向**。

举例：
- 收入和违约的相关系数可能是 -0.3（负相关）
- 但这不意味着"提高收入会降低违约"——可能是"违约导致收入降低"（如破产）

因果推断要做的是：**在控制了混杂变量后，估计"如果改变 X，Y 会如何"**。

### 一个简单的因果图示例

老潘在白板上画了一张图：

```
用户活跃度 → 优惠券使用
    ↓           ↓
    消费金额 ←────┘
```

解释：
- **用户活跃度**影响"是否用券"（活跃用户更愿意领券）
- **用户活跃度**也影响"消费金额"（活跃用户本来就消费更高）
- 如果不调整活跃度，用券和消费的"关联"会夸大优惠券的因果效应

**这就是混杂变量的直观体现**。

---

> **AI 时代小专栏：因果推断与 AI 决策系统**
>
> 2024-2025 年，AI 领域出现了一个重要反思：**我们优化的是"预测"，不是"决策"**。Netflix 和 Spotify 的推荐系统可以非常准确地预测"用户会点击什么"，但它们无法回答"如果我们推荐这首歌，用户会多听多久"。
>
> 问题在于：**相关≠因果**。推荐系统学到的是"历史数据中的模式"——比如"喜欢爵士的人也喜欢古典"，但这不代表"推荐古典会让爵士用户听更多"。可能是"有品味的用户既喜欢爵士也喜欢古典"（混杂：品味）。
>
> LinkedIn 在 2024-2025 年的研究中发现了一个典型案例：他们的推荐系统基于"因果语言模型"（Causal Language Models，指 transformer 中的 left-to-right prediction）优化内容推荐，但这与统计学的"因果推断"是不同方向。传统推荐系统容易把"相关"当成"因果"——比如推荐"高薪但远距离"的工作时，用户点击率高（因为标题吸引人），但申请成功率低（通勤太远放弃）。**模型优化的是"用户点击推荐"，不是"用户求职成功"**。
>
> Uber 的数据科学家也曾分享过一个令人困惑的发现：他们的推荐模型显示，向用户推送"附近有豪车可叫"的提示后，下单率显著提高。但因果分析揭示：豪车多的区域往往是市中心高收入地区，而高收入用户本来就更容易叫车。**不是"豪车提示导致了下单"，而是"高收入地区既有豪车也有更多订单"**。这个发现为公司节省了数百万美元的错误营销投入。
>
> AI 的局限在于：**它只能在给定数据下预测，无法回答"如果干预会怎样"**。因果推断补上了这一块——它帮你识别"AI 学到的哪些模式是相关性的、哪些是因果性的"。所以你刚学的"因果三层级"和"混杂变量识别"在 AI 时代不是多余——它们是你判断 AI 结论是否可信的底线。
>
> 参考（访问日期：2026-02-13）：
> - [DoWhy - Microsoft 开源因果推断库](https://github.com/py-why/dowhy)
> - [CausalML - Uber 开源因果推断库](https://github.com/uber/causalml)
> - [DoWhy 文档](https://www.pywhy.org/dowhy/)
> - [CausalML 文档](https://causalml.readthedocs.io/)

---

## 2. 画一张因果图——让假设可视化

阿码看着老潘画的图，好奇地问："因果图怎么画？有什么规则吗？还是随便画？"

"当然有规则，"老潘说，"**DAG（Directed Acyclic Graph，有向无环图）**是因果推断的标准语言。箭头表示因果方向，不能有循环（你不能让你爷爷的出生依赖于你的出生）。"

### DAG 的三种基本结构

老潘继续在白板上画：

**结构 1：链式（Chain）——因果路径**

```
X → Y → Z
```

示例：教育 → 收入 → 健康水平

- 教育影响收入（因果）
- 收入影响健康（因果）
- 如果你调整了收入，教育和健康的关系会**消失**（这是中介，不是混杂）

**结构 2：叉式（Fork）——混杂变量**

```
      → X
Z <--
      → Y
```

示例：年龄 → 用券（年轻人更爱领券）
         → 消费（年轻人消费更高）

- Z 是**混杂变量**（同时影响 X 和 Y）
- X 和 Y 的关联**不是因果**，而是由 Z 引起的虚假关联
- **必须调整 Z**，才能识别 X → Y 的因果效应

**结构 3：对撞（Collider）——选择偏差的来源**

```
X → Z ← Y
```

示例：能力 → 录取 ← 运气

- 能力和运气都影响录取
- 如果你只看"被录取的人"，会发现能力和运气**负相关**（能力低的人运气一定好才能录取）
- 但如果你调整了 Z（录取），会**制造虚假关联**

**关键区别**：
- **叉式（混杂）**：调整 Z，X 和 Y 的关联变弱（正确）
- **对撞（选择偏差）**：调整 Z，X 和 Y 的关联变强（错误！）

小北举手："所以优惠券案例里，'用户活跃度'是混杂变量，因为它是叉式结构？"

"对，"老潘说，"但如果你调整了'使用频率'（中介变量），就像切断了因果路径，会低估优惠券的效应。"

"还有，"阿码补充，"如果你只分析'消费超过 100 元的人'（对撞变量筛选），可能会看到虚假关联。"

### 用 Python 画因果图

```python
# examples/02_causal_dag.py

import matplotlib.pyplot as plt
import networkx as nx

# 创建 DAG
dag = nx.DiGraph()

# 添加节点和边（优惠券案例）
dag.add_edges_from([
    ("用户活跃度", "优惠券使用"),
    ("用户活跃度", "消费金额"),
    ("历史消费", "优惠券使用"),
    ("历史消费", "消费金额"),
    ("优惠券使用", "消费金额"),
])

# 画图
plt.figure(figsize=(10, 6))
pos = nx.spring_layout(dag, seed=42)

# 画节点
nx.draw_networkx_nodes(dag, pos, node_color='lightblue',
                       node_size=3000, alpha=0.9)

# 画边
nx.draw_networkx_edges(dag, pos, edge_color='gray',
                      arrowsize=20, width=2, alpha=0.7)

# 画标签
nx.draw_networkx_labels(dag, pos, font_size=12,
                        font_family='sans-serif')

plt.title("优惠券案例的因果图（DAG）", fontsize=14)
plt.axis('off')
plt.savefig("report/causal_dag_coupon.png", dpi=150, bbox_inches='tight')
plt.show()
```

**解读这张图**：
- **优惠券使用 → 消费金额**：我们想估计的因果效应（箭头指向目标）
- **用户活跃度 → 优惠券使用**、**用户活跃度 → 消费金额**：活跃度是混杂变量（同时影响处理和结果）
- **历史消费 → 优惠券使用**、**历史消费 → 消费金额**：历史消费也是混杂变量

### 从 Week 04 的"多变量关系"到因果图

Week 04 你学过**多变量关系**——当时我们发现"简单两变量分析可能误导"，比如 MBA 毕业生收入高不是因为学位，而是因为能力。这个洞见正好是因果推断的基础：我们需要考虑**变量间的完整网络**，而不仅是 pairwise 关系。因果图就是把 Week 04 的"多变量关系"可视化，让你看到"谁影响谁"的完整地图。

### 从 Week 04 的"假设生成"到因果图

Week 04 你还学过**假设生成**——从数据中发现可能的因果模式。比如看到"收入与违约负相关"，你会假设"收入影响违约"。但这个假设可能错（反向因果）。因果图让这些假设显式化，你可以和团队讨论："箭头是单向的吗？"，"还有哪些变量没考虑？"，"这个因果方向合理吗？"。

### 从 Week 04 的"混杂变量"到 DAG

Week 04 你学过**混杂变量**的定义："同时影响自变量和因变量的第三方变量"。但没有可视化工具，你很难判断"哪些是混杂，哪些不是"。

**因果图的优势**：
- **可视化假设**：所有因果假设一目了然
- **识别路径**：你能看到"X 和 Y 之间有多少条路径"，哪些是因果路径，哪些是虚假路径
- **指导调整**：根据图的结构，决定"该调整哪些变量"

### 老潘的工程经验：因果图就是"假设文档"

"在公司里，"老潘说，"我们做因果推断前，一定会画 DAG。为什么？"

**第一，强制你明确假设**。你不能说"我觉得有混杂"，而要画出"谁影响谁"。

**第二，方便团队讨论**。产品经理、业务、算法都能看懂图，比代码容易沟通。

**第三，可追溯**。六个月后有人质疑"你当时为什么调整这个变量"，你能拿出图说"根据后门准则，这是必须调整的混杂"。

阿码点头："所以因果图不是为了好看，而是为了可复现、可审计？"

"对，"老潘说，"和代码注释、测试用例一样——好的数据科学项目，假设必须是显式的。"

---

## 3. 后门准则——该调整什么，不该调整什么

小北看着因果图，问了一个问题："那我应该调整哪些变量？活跃度？历史消费？还是把所有其他变量都调整了？"

"好问题，"老潘说，"这其实是一个反直觉的问题——**多调整不一定更好，甚至可能更糟糕**。"

阿码也在思考："对啊，多调整总没错吧？"

"大错特错，"老潘说，"**调整不当比不调整更危险**。你可能会调整了**中介变量（Mediator）**或**对撞变量（Collider）**，反而引入偏差。"

### 先看路径：因果路径 vs 后门路径

老潘在白板上画了一张简化的图：

```
用户活跃度 → 优惠券使用 → 消费金额
     ↑                           ↑
     └───────────────────────────┘
```

**这里有两种路径：**

**路径 1：因果路径**（前门路径）
- `优惠券使用 → 消费金额`
- 这是我们想估计的效应——**不能切断**

**路径 2：后门路径**（虚假关联路径）
- `优惠券使用 ← 用户活跃度 → 消费金额`
- 这是由混杂变量创造的虚假关联——**必须阻断**

**后门路径**的本质：它绕过了"前门"（因果箭头），从"后门"溜进来创造了虚假关联。

小北："所以我要阻断后门路径，但不能切断因果路径？"

"对，"老潘说，"这就是**后门准则**的核心思想。"

### 用一个生活类比理解后门路径

想象你想知道"这条河的水质如何"（因果效应）。你有两条路可以走：

**前门路**：直接从河道取水检测（因果路径：处理 → 结果）
**后门路**：从下水道溜进去（后门路径：处理 ← 混杂 → 结果）

后门路的问题是：你测到的不是河水本身，而是混杂了其他水源的水。要解决这个问题，你有两个办法：
1. **堵住后门**（调整混杂变量，阻断虚假路径）
2. **只从河道取水**（随机对照试验，切断处理和混杂的关联）

### 调整一切的陷阱：中介变量

老潘在白板上画了一张新图：

```
优惠券 → 使用频率 → 消费金额
  ↑                    ↑
用户活跃度 ──────────────┘
```

解释：
- **优惠券 → 使用频率 → 消费金额**：优惠券通过"提高使用频率"影响消费（频率是中介变量）
- **用户活跃度**：混杂变量（同时影响用券和消费）

**如果你调整了"使用频率"**：
- 优惠券对消费的**直接效应**会消失（因为路径被切断）
- 你会错误地得出"优惠券无效"的结论

小北："等等，那我不应该调整使用频率？但我以为调整更多变量总是更好的……"

"这就是陷阱，"老潘说，"**调整中介变量，就像在半路切断了因果链条**。你问的问题变成了'如果保持使用频率不变，优惠券是否有效'——但这不是你想知道的。你想知道的是'整体效应'，包括通过频率的间接效应。"

### 后门准则的三个条件（简化版）

老潘写下了一个定理：

**给定因果图 G 和处理变量 X、结果变量 Y，调整集 Z 满足后门准则，如果：**

1. **Z 中没有 X 的后代**（不能调整中介变量或结果变量）
2. **Z 阻断了所有 X → Y 的后门路径**
3. **Z 不打开任何新的虚假路径**（不调整对撞变量）

**优惠券案例的正确调整集**：
- **调整**：用户活跃度、历史消费（阻断后门路径）
- **不调整**：使用频率（中介变量，会切断因果路径）

### 用 DoWhy 自动识别后门调整集

```python
# examples/03_backdoor_criterion.py

import pandas as pd
from dowhy import CausalModel

# 加载数据
df = pd.read_csv("data/coupon_data.csv")

# 定义因果模型
causal_graph = """digraph {
    用户活跃度 -> 优惠券使用;
    用户活跃度 -> 消费金额;
    历史消费 -> 优惠券使用;
    历史消费 -> 消费金额;
    优惠券使用 -> 消费金额;
}"""

model = CausalModel(
    data=df,
    treatment="优惠券使用",
    outcome="消费金额",
    graph=causal_graph.replace('\n', ' ')
)

# 识别因果效应（自动应用后门准则）
identified_estimand = model.identify_effect()

print("=== 识别的因果效应 ===")
print(identified_estimand)
```

**DoWhy 的输出**（示例）：
```
Identified estimand:
Estimand type: nonparametric-ate
Estimand expression:
  d
------(Expectation(消费金额|优惠券使用,用户活跃度,历史消费))
d优惠券使用
```

解读：DoWhy 自动识别出需要调整"用户活跃度"和"历史消费"，这是后门准则的自动化应用。

### 从 Week 06 的"原假设与备择假设"到因果推断

Week 06 你学过**原假设与备择假设**——假设检验帮你判断"差异是否显著"。但有一个局限：它只能回答"是否有差异"，不能回答"差异的来源"。比如发现"用券用户消费高 50 元"显著（p<0.001），但你不知道"这 50 元里多少是因果效应、多少是混杂"。因果推断补充了这一缺口——它帮你回答"这差异有多大比例是因果"。

### 从 Week 09 的"回归陷阱"到后门准则

Week 09 你学过**回归分析**，但有一个陷阱：**如果你调整了不该调整的变量，回归系数会有偏差**。

举例：
- 你想估计"教育对收入的影响"
- 你在回归中调整了"职业类型"
- 但职业是**中介变量**（教育 → 职业 → 收入）
- 结果：教育的系数被低估（因为部分效应被"吸收"了）

**后门准则解决的问题**：
- Week 09 你可能"凭感觉"决定调整哪些变量
- 现在，你可以根据**因果图的科学规则**（后门准则）选择调整集

老潘："在公司里，我们从不'凭感觉'调整变量。每一步调整，都必须能在因果图上找到依据——要么是阻断后门路径，要么是已知的业务规则。"

---

> **AI 时代小专栏：因果图工具——从手绘 DAG 到自动化识别**
>
> 2024-2025 年，因果推断工具链快速成熟。Microsoft 的 DoWhy（2018年开源）和 Uber 的 CausalML（2019年开源）已成为 Python 生态的标准工具，让数据科学家不需要手写调整代码，而是用 API 完成识别、估计、鲁棒性检查的全流程。
>
> DoWhy 的核心优势是**模型无关的接口**：你提供因果图，它自动识别策略（后门、前门、IV），并支持多种估计方法（回归、匹配、IPW）。更重要的是，它能做**敏感性分析（Sensitivity Analysis）**——回答"如果存在未观察的混杂，结论会偏多少"，这是传统统计检验做不到的。
>
> CausalML 则侧重于**增量 uplift 建模**（Uplift Modeling），常用于营销场景（识别"优惠券敏感人群"）。它提供了因果森林（Causal Forests）、双机器学习（Double ML）等前沿方法，能处理高维特征的复杂场景。
>
> 但工具不能替代假设。因果推断的第一步永远是**画因果图**——你需要明确"谁影响谁"。AI 可以帮你识别后门路径、估计效应，但无法替你做"业务假设"（如"优惠券会影响消费，但消费不会反过来影响用券"）。所以你刚学的后门准则和因果图绘制在 AI 时代不是多余——它们是你使用因果推断工具的前提。
>
> 参考（访问日期：2026-02-13）：
> - [DoWhy 文档](https://www.pywhy.org/dowhy/)
> - [CausalML 文档](https://causalml.readthedocs.io/)
> - [DoWhy GitHub](https://github.com/py-why/dowhy)
> - [CausalML GitHub](https://github.com/uber/causalml)

---

## 4. 从识别到估计——优惠券真的有效吗？

老潘说："现在你知道了该调整什么（后门准则），下一步是**估计因果效应**。有两种常用方法：回归（带正确调整集）和倾向评分匹配。"

### 方法 1：回归（带后门调整集）

这是最简单的方法——用回归控制混杂变量：

```python
# examples/04_causal_estimation.py

import statsmodels.formula.api as smf

# 带后门调整的回归
model = smf.ols(
    "消费金额 ~ 优惠券使用 + 用户活跃度 + 历史消费",
    data=df
).fit()

print(model.summary())
```

**解读回归系数**：
- **优惠券使用的系数**：30 元（这是**调整后的因果效应估计**）
- **置信区间**：[20, 40] 元（调整后的不确定性）
- **p 值**：< 0.001（效应显著）

**对比未调整的结果**：
- 未调整（小北的错误）：50 元（被混杂夸大）
- 调整后（正确）：30 元（真实的因果效应）

### 方法 2：倾向评分匹配（Propensity Score Matching）

小北举手："但是回归假设线性关系，如果变量之间不是线性关系呢？"

"好问题，"老潘说，"这时可以用**倾向评分匹配**（Propensity Score Matching）。"

**倾向评分（Propensity Score）**是指"在给定特征下，接受处理的概率"。

**核心思想**：如果两个用户倾向评分相近（特征相似），但一个用券、一个不用，那他们的差异就是因果效应。

### 让我们一步步揭开匹配的魔法

```python
from sklearn.neighbors import NearestNeighbors
from sklearn.linear_model import LogisticRegression

# 第 1 步：估计倾向评分（用 Logistic 回归）
ps_model = LogisticRegression()
ps_model.fit(
    df[["用户活跃度", "历史消费"]],
    df["优惠券使用"]
)

df["propensity_score"] = ps_model.predict_proba(
    df[["用户活跃度", "历史消费"]]
)[:, 1]

# 第 2 步：匹配（为每个用券用户找未用券的"相似用户"）
treated = df[df["优惠券使用"] == 1]
control = df[df["优惠券使用"] == 0]

# 用 1:1 最近邻匹配
nn = NearestNeighbors(n_neighbors=1)
nn.fit(control[["propensity_score"]])

distances, indices = nn.kneighbors(
    treated[["propensity_score"]]
)

matched_control = control.iloc[indices.flatten()]

# 第 3 步：计算因果效应（ATT，处理组平均处理效应）
treated_outcome = treated["消费金额"].values
control_outcome = matched_control["消费金额"].values

att = (treated_outcome - control_outcome).mean()

print(f"优惠券的因果效应（ATT）: {att:.2f} 元")
```

**输出**（示例）：
```
优惠券的因果效应（ATT）: 28.50 元
```

**匹配的可视化**：

```python
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))

# 画匹配前的倾向评分分布
plt.subplot(1, 2, 1)
plt.hist(treated["propensity_score"], alpha=0.5, label="用券", bins=20)
plt.hist(control["propensity_score"], alpha=0.5, label="未用券", bins=20)
plt.xlabel("倾向评分")
plt.ylabel("人数")
plt.title("匹配前：倾向评分分布差异大")
plt.legend()

# 画匹配后的倾向评分分布
plt.subplot(1, 2, 2)
plt.hist(treated["propensity_score"], alpha=0.5, label="用券", bins=20)
plt.hist(matched_control["propensity_score"], alpha=0.5, label="匹配的未用券", bins=20)
plt.xlabel("倾向评分")
plt.ylabel("人数")
plt.title("匹配后：倾向评分分布接近")
plt.legend()

plt.tight_layout()
plt.savefig("report/propensity_score_matching.png", dpi=150, bbox_inches='tight')
plt.show()
```

**解读**：
- **匹配前**：用券用户的倾向评分普遍更高（本来就更活跃），直接比较会高估效应
- **匹配后**：两组的倾向评分分布接近（可比），差异就是因果效应

### 从 Week 08 的"置信区间"到因果效应区间

Week 08 你学过**置信区间**：量化估计的不确定性。因果推断也需要置信区间：

**用 Bootstrap 估计因果效应的置信区间**：

```python
import numpy as np

n_bootstraps = 1000
att_samples = []

for i in range(n_bootstraps):
    # 重采样
    treated_boot = treated.sample(n=len(treated), replace=True)
    control_boot = control.sample(n=len(control), replace=True)

    # 匹配并计算 ATT
    # ...（匹配代码同上）...
    att_samples.append(att_boot)

# 95% 置信区间
ci_low = np.percentile(att_samples, 2.5)
ci_high = np.percentile(att_samples, 97.5)

print(f"因果效应：{att:.2f} 元")
print(f"95% CI：[{ci_low:.2f}, {ci_high:.2f}] 元")
```

**输出**（示例）：
```
因果效应：28.50 元
95% CI：[20.30, 36.70] 元
```

### 回归 vs 匹配：该用哪个？

老潘给了一个对比表：

| 方法 | 优势 | 劣势 | 适用场景 |
|------|------|------|---------|
| **回归（带调整集）** | 简单、快速、可用标准误差 | 假设线性、容易模型错设 | 混杂变量少、关系简单 |
| **倾向评分匹配** | 不假设线性、可视化强、直觉清晰 | 丢弃无法匹配的样本、效率低 | 非线性关系、需要可比性检查 |

**实践建议**：
- 先用回归（快速得到基线）
- 再用匹配（检查稳健性）
- 如果两者接近，结论可靠
- 如果差异大，检查假设（模型形式、匹配质量）

### 阿码的好奇："AI 不能直接告诉我因果效应吗？"

阿码举手："我有个问题——为什么要学这个？AI 不能直接告诉我因果效应吗？"

老潘笑了："好问题。AI 能帮你算 p 值、跑回归、画图，但 AI 不能替你做三件事："

**第一，AI 不能替你画因果图。** 因果图来自**领域知识**（业务逻辑），不是数据。数据告诉你"用券和消费相关"，但只有业务专家告诉你"活跃用户更爱领券"。

**第二，AI 不能替你判断"该调整什么"。** 如果你不给 AI 因果图，它不知道哪些是混杂、哪些是中介、哪些是对撞。盲目调整一切比不调整更危险。

**第三，AI 不能替你解释因果效应。** 回归输出一个数字（30 元），但只有你能解释"这意味着什么""适用于谁""有什么限制"。

"所以，"老潘总结，"因果推断不是让 AI 替你思考，而是让你**更聪明地用 AI**——给它明确的因果假设，让它帮你计算和检查，但你负责解释和决策。"

---

## 5. 把因果推断写进报告——StatLab 进度

老潘说："现在你学会了因果推断的三步：画因果图、识别后门路径、估计因果效应。最后一步是——把这些写进你的 StatLab 报告。"

### StatLab 报告的因果推断章节

老潘在白板上写了一个模板：

```markdown
## 因果推断

### 研究问题

本章回答的因果问题是：

**"如果 [处理变量]，[结果变量] 会如何变化？"**

示例：如果给用户发放优惠券，他的消费金额会提高多少？

注意：这与关联问题不同。关联问题是"用券用户和未用券用户的消费差异"，而因果问题是"发券这个行为的因果效应"。

### 因果假设

我们用因果图（DAG）表达因果假设：

![因果图](causal_dag.png)

**图解**：
- **处理变量（X）**：优惠券使用（0=未使用，1=使用）
- **结果变量（Y）**：消费金额
- **混杂变量（Z）**：用户活跃度、历史消费（同时影响用券和消费）
- **因果路径**：优惠券 → 消费金额（我们想估计的效应）

### 识别策略

根据**后门准则（Backdoor Criterion）**，我们需要调整以下混杂变量：

- 用户活跃度（用券前 30 天的活跃天数）
- 历史消费（用券前 90 天的平均消费）

**调整理由**：
- 用户活跃度影响"是否用券"（活跃用户更愿意领券），也影响"消费金额"
- 历史消费影响"是否用券"（高消费用户更关注优惠），也影响"后续消费"

**不调整的变量**：
- 使用频率（中介变量）：优惠券通过提高使用频率影响消费，调整它会低估效应

### 因果效应估计

我们用两种方法估计因果效应，以检查稳健性。

#### 方法 1：带调整集的回归

| 变量 | 系数 | 95% CI | p 值 |
|------|------|--------|------|
| 优惠券使用 | **30.2** 元 | [20.5, 39.9] | <0.001 |
| 用户活跃度 | 5.1 元 | [3.2, 7.0] | <0.001 |
| 历史消费 | 0.3 元 | [0.2, 0.4] | <0.001 |

**解读**：在控制了用户活跃度和历史消费后，优惠券使消费金额提高 **30.2 元**（95% CI [20.5, 39.9] 元）。

#### 方法 2：倾向评分匹配

匹配质量检查：

![倾向评分分布（匹配前后）](propensity_score_matching.png)

匹配后的因果效应：

| 指标 | 估计值 | 95% CI |
|------|--------|--------|
| **ATT（处理组平均处理效应）** | **28.5** 元 | [20.3, 36.7] |

**解读**：优惠券的因果效应估计为 **28.5 元**（与回归结果接近，结论稳健）。

### 结论边界

**我们能回答的（因果结论）**：
- 给用户发放优惠券，会使他的消费金额提高约 **29 ± 8 元**（回归和匹配的平均）
- 这个结论在调整了混杂变量（活跃度、历史消费）后成立

**我们不能回答的（只是相关）**：
- 优惠券对所有用户的效果相同（我们估计的是平均效应，异质性未知）
- 长期效应（数据只有 3 个月，无法回答 1 年后的效应）
- 反事实（"如果这个用户没用券，他会消费多少"是个体反事实，无法直接观测）

**限制**：
- 存在未观察混杂的可能（如用户收入，如果数据中没有）
- 匹配会丢弃无法匹配的样本（可能影响外推性）
```

### Python 代码实现

```python
# examples/05_statlab_causal.py

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.formula.api as smf
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import NearestNeighbors
import networkx as nx

def causal_inference_report(df, treatment, outcome, confounders,
                         output_path="report"):
    """
    对 StatLab 数据集进行因果推断分析

    参数:
        df: 清洗后的数据
        treatment: 处理变量名（如 'coupon_used'）
        outcome: 结果变量名（如 'spending'）
        confounders: 混杂变量列表（如 ['activity', 'history_spend']）
        output_path: 输出路径
    """
    report = f"""
## 因果推断

### 研究问题

本章回答的因果问题是：

**"如果给用户发放{treatment}，{outcome}会提高多少？"**

注意：这与关联问题不同。关联问题是"用券用户和未用券用户的{outcome}差异"，而因果问题是"发券这个行为的因果效应"。

### 因果假设

我们用因果图（DAG）表达因果假设：

"""

    # ========== 1. 画因果图 ==========
    dag = nx.DiGraph()
    edges = []
    for conf in confounders:
        edges.append((conf, treatment))
        edges.append((conf, outcome))
    edges.append((treatment, outcome))

    dag.add_edges_from(edges)

    plt.figure(figsize=(10, 6))
    pos = nx.spring_layout(dag, seed=42)
    nx.draw_networkx_nodes(dag, pos, node_color='lightblue',
                           node_size=3000, alpha=0.9)
    nx.draw_networkx_edges(dag, pos, edge_color='gray',
                          arrowsize=20, width=2, alpha=0.7)
    nx.draw_networkx_labels(dag, pos, font_size=12,
                            font_family='sans-serif')
    plt.title("因果图（DAG）", fontsize=14)
    plt.axis('off')
    dag_path = f"{output_path}/causal_dag.png"
    plt.savefig(dag_path, dpi=150, bbox_inches='tight')
    plt.close()

    report += f"![因果图]({dag_path})\n\n"

    # ========== 2. 识别策略（后门准则）==========
    report += """### 识别策略

根据**后门准则（Backdoor Criterion）**，我们需要调整以下混杂变量：

"""

    for conf in confounders:
        report += f"- **{conf}**：同时影响处理和结果\n"

    report += f"""
**不调整的变量**：
- 中介变量（如使用频率）：调整它会切断因果路径

### 因果效应估计

我们用两种方法估计因果效应，以检查稳健性。

#### 方法 1：带调整集的回归

"""

    # ========== 3. 回归估计 ==========
    formula = f"{outcome} ~ {treatment} + {' + '.join(confounders)}"
    model = smf.ols(formula, data=df).fit()

    # 提取处理变量的系数
    coef = model.params[treatment]
    ci_low, ci_high = model.conf_int().loc[treatment]
    pval = model.pvalues[treatment]

    report += f"""
| 指标 | 估计值 | 95% CI | p 值 |
|------|--------|--------|------|
| {treatment} 的因果效应 | **{coef:.2f}** | [{ci_low:.2f}, {ci_high:.2f}] | {pval:.4f} |

**解读**：在控制了 {', '.join(confounders)} 后，{treatment} 对 {outcome} 的因果效应为 **{coef:.2f}**（95% CI [{ci_low:.2f}, {ci_high:.2f}]）。

"""

    # ========== 4. 倾向评分匹配 ==========
    report += """#### 方法 2：倾向评分匹配

"""

    # 估计倾向评分
    ps_model = LogisticRegression()
    ps_model.fit(df[confounders], df[treatment])
    df["propensity_score"] = ps_model.predict_proba(df[confounders])[:, 1]

    # 匹配
    treated = df[df[treatment] == 1]
    control = df[df[treatment] == 0]

    nn = NearestNeighbors(n_neighbors=1)
    nn.fit(control[["propensity_score"]])
    distances, indices = nn.kneighbors(treated[["propensity_score"]])
    matched_control = control.iloc[indices.flatten()]

    # 计算 ATT
    att = (treated[outcome].values - matched_control[outcome].values).mean()

    # Bootstrap 置信区间
    n_boot = 500
    att_samples = []
    for i in range(n_boot):
        treated_boot = treated.sample(n=len(treated), replace=True)
        control_boot = control.sample(n=len(control), replace=True)
        nn_boot = NearestNeighbors(n_neighbors=1)
        nn_boot.fit(control_boot[["propensity_score"]])
        _, indices_boot = nn_boot.kneighbors(treated_boot[["propensity_score"]])
        matched_boot = control_boot.iloc[indices_boot.flatten()]
        att_samples.append(
            (treated_boot[outcome].values - matched_boot[outcome].values).mean()
        )

    att_ci_low = np.percentile(att_samples, 2.5)
    att_ci_high = np.percentile(att_samples, 97.5)

    report += f"""
| 指标 | 估计值 | 95% CI |
|------|--------|--------|
| **ATT（处理组平均处理效应）** | **{att:.2f}** | [{att_ci_low:.2f}, {att_ci_high:.2f}] |

**解读**：倾向评分匹配估计的因果效应为 **{att:.2f}**（95% CI [{att_ci_low:.2f}, {att_ci_high:.2f}]），与回归结果接近，结论稳健。

### 结论边界

**我们能回答的（因果结论）**：
- {treatment} 对 {outcome} 的因果效应约为 **{(coef + att) / 2:.2f} ± {abs(coef - att) / 2:.2f}**（两种方法的平均）

**我们不能回答的（只是相关或未知）**：
- 个体因果效应（反事实）
- 长期效应（数据时间范围外）
- 未观察混杂（如 {treatment} 的随机分配机制）

**限制**：
- 存在未观察混杂的可能
- 匹配会丢弃无法匹配的样本
- 效应异质性未知

"""

    return report

# 使用示例
if __name__ == "__main__":
    df = pd.read_csv("data/coupon_data.csv")

    # 生成因果推断报告
    report_causal = causal_inference_report(
        df=df,
        treatment="优惠券使用",
        outcome="消费金额",
        confounders=["用户活跃度", "历史消费"],
        output_path="report"
    )

    # 追加到 report.md
    with open("report/report.md", "a", encoding="utf-8") as f:
        f.write(report_causal)

    print("✅ 因果推断章节已添加到 report/report.md")
```

### 本周改进总结

| 改动项 | 上周状态 | 本周改进 |
|--------|---------|---------|
| 研究问题 | 只区分"描述/推断/预测" | 增加"因果问题"（干预 vs 反事实） |
| 假设表达 | 隐式（没画因果图） | 显式因果图（DAG） |
| 识别策略 | 无 | 后门准则（科学选择调整集） |
| 效应估计 | 只报告关联（相关系数） | 报告因果效应（回归 + 匹配） |
| 结论边界 | 混淆（没说清相关 vs 因果） | 明确（区分因果结论和相关发现） |

老潘评价："这才是负责任的因果推断报告——不是夸大结论（'优惠券有效！'），而是诚实说明'我们能回答什么、不能回答什么'。"

---

## StatLab 进度

到上周为止，StatLab 报告已经有了数据卡、描述统计、清洗日志、EDA、假设检验、回归、分类、模型解释（SHAP）、公平性评估和伦理审查。

**但老潘发现了一个问题**：所有结论都是"相关性的"。比如：

- "收入与违约负相关"（相关系数）
- "年龄与消费正相关"（回归系数）
- "优惠券用户消费更高 50 元"（均值差）

产品经理会问："**如果我们给用户提高额度，违约会降吗？**""**如果我们给用户发券，消费会涨吗？**"

老潘指出："**这些问题是因果问题，不是相关问题。** 你学过的所有方法（相关分析、回归、假设检验）只能回答'变量是否相关'，不能回答'如果干预会怎样'。"

"这正好是本周'因果推断'派上用场的地方，"老潘说，"我们要在 StatLab 中添加一个**因果推断章节**。"

### StatLab 报告的因果推断升级

**第 1 步：明确研究问题的层级**

老潘要求在报告开头添加一个**问题分类表**：

| 问题类型 | 示例 | 能回答吗？用什么方法 |
|---------|------|-------------------|
| **描述** | "数据中违约率是多少？" | ✅ 描述统计 |
| **关联** | "收入与违约相关吗？" | ✅ 相关分析、回归 |
| **预测** | "这个用户会违约吗？" | ✅ 分类模型 |
| **干预（因果）** | "如果给用户提额，违约会降吗？" | ❌ 需要因果推断 |
| **反事实** | "如果这个用户没提额，他会违约吗？" | ❌ 需要反事实推理 |

**第 2 步：画因果图**

老潘说："因果推断的第一步永远是**画因果图**。这不只是给读者看，更是强迫你自己明确假设。"

示例因果图（提额案例）：

```
历史表现 → 提额决策 → 违约
    ↑          ↓
用户风险 ←──────┘
```

**第 3 步：选择识别策略**

根据因果图和后门准则，决定调整集：
- **需要调整**：用户风险、历史表现（混杂变量）
- **不能调整**：提额后的行为（中介变量）

**第 4 步：估计因果效应**

用本周学的方法（回归 + 匹配）估计提额对违约的因果效应。

**第 5 步：写清结论边界**

在报告末尾加一个**因果结论声明**：

> **因果结论**：在控制了用户风险和历史表现后，提额使违约率降低了 X 个百分点（95% CI [Y, Z]）。
>
> **限制**：这个结论假设没有未观察混杂（如用户收入），且只适用于短期效应（3 个月内）。

### 本周 StatLab 的改进总结

| 维度 | 上周状态 | 本周改进 |
|------|---------|---------|
| 问题分类 | 只区分"描述/推断/预测" | 增加"干预/反事实"层级 |
| 假设表达 | 隐式（没画图） | 显式因果图（DAG） |
| 识别策略 | 无 | 后门准则（科学选择调整集） |
| 效应估计 | 只报告关联（相关系数） | 报告因果效应（回归 + 匹配） |
| 结论边界 | 混淆（相关/因果不分） | 明确区分因果结论和相关发现 |

老潘总结："本周你完成的不是'加一个章节'，而是**升级了整个分析框架**——从'相关思维'到'因果思维'。这是数据科学家的关键跃迁。"

---

## Git 本周要点

本周必会命令：
- `git status`: 查看工作区状态
- `git diff`: 查看具体改动内容
- `git add -A`: 添加所有改动
- `git commit -m "feat: add causal inference section"`
- `git log --oneline -n 5`

常见坑：

**把"相关"当成"因果"**——小北最初发现"用券用户消费高 50 元"，直接下结论"优惠券有效"。解决方法：先画因果图，识别混杂变量，用后门准则选择调整集。

**盲目调整一切变量**——阿码以为"多调整总没错"，结果调整了中介变量（使用频率），低估了优惠券效应。解决方法：用因果图 + 后门准则，精确选择调整集。

**忘记画因果图**——没有因果图，假设是隐式的，无法讨论和审计。解决方法：因果推断的第一步永远是画 DAG，显式表达假设。

**混淆"处理组平均处理效应（ATT）"和"平均处理效应（ATE）"**——ATT 是"对被处理的人的平均效应"，ATE 是"对全人群的平均效应"。解决方法：在报告中标明你估计的是哪个。

**过度承诺因果结论**——说"优惠券有效"，但不说明"只对活跃用户有效""只有短期效应"。解决方法：明确结论边界（能回答什么、不能回答什么）。

Pull Request (PR)：
- Gitea 上也叫 Pull Request，流程等价 GitHub：push 分支 -> 开 PR -> review -> merge。

---

## 本周小结（供下周参考）

本周你从"相关思维"升级到"因果思维"——这是数据科学家的关键跃迁。你理解了**因果三层级**：关联（变量相关吗）、干预（如果改变会怎样）、反事实（如果当时没做会怎样）。小北的错误是用"关联方法"（比较均值）回答"干预问题"（优惠券有效吗）。

你学会了用**因果图（DAG）**表达因果假设。DAG 的三种基本结构（链式、叉式、对撞）帮你识别混杂变量（叉式结构）、中介变量（链式结构）和对撞变量（对撞结构）。**后门准则**给你一个科学的方法选择调整集——不能盲目调整一切，也不能不调整。

你掌握了两种**因果效应估计方法**：带调整集的回归（简单快速）和倾向评分匹配（灵活可检查）。小北最初发现的 50 元差异（未调整）被夸大了，调整混杂后真实的因果效应约 30 元。

最重要的是，你学会了在 StatLab 报告中添加**因果推断章节**：画因果图、明确识别策略、估计因果效应、写清结论边界。老潘强调，因果推断不是替代统计检验，而是**补充**——它回答的是不同类型的问题（干预 vs 相关）。

下周（Week 14），你要学习**贝叶斯统计**——从"频率学派的 p 值和置信区间"到"贝叶斯学派的后验分布和可信区间"。本周的"因果效应估计"会演化为下周的"贝叶斯因果推断"，因果图的"显式假设"会连接贝叶斯的"先验分布"。更重要的是，你要理解两种思维范式的差异：频率学派问"如果重复实验，结果会如何"，贝叶斯学派问"给定当前数据，信念应该如何更新"。

---

## Definition of Done（学生自测清单）

- [ ] 我能理解因果三层级（关联/干预/反事实）的区别
- [ ] 我能识别"相关≠因果"的常见陷阱（反向因果、混杂、选择偏差）
- [ ] 我能画简单的因果图（DAG），表达因果假设
- [ ] 我能识别因果图中的三种基本结构（链式、叉式、对撞）
- [ ] 我能理解什么是后门路径（虚假关联的来源）
- [ ] 我能应用后门准则选择正确的调整集
- [ ] 我能理解为什么不能盲目调整一切变量（中介/对撞陷阱）
- [ ] 我能用带调整集的回归估计因果效应
- [ ] 我能用倾向评分匹配估计因果效应（ATT）
- [ ] 我能检查匹配质量（倾向评分分布）
- [ ] 我能在 StatLab 报告中添加因果推断章节（因果图 + 识别策略 + 效应估计）
- [ ] 我能明确区分"因果结论"和"相关发现"
- [ ] 我能写清因果结论的边界（能回答什么、不能回答什么）
- [ ] 我能识别 AI 生成的结论中"把相关当成因果"的错误
- [ ] 我用 git 提交了本周的工作（至少一次 commit）
- [ ] 我理解从"相关思维"到"因果思维"是数据科学家的关键跃迁
