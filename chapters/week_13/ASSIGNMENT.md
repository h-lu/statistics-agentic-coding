# Week 13 作业：从相关到因果

> "Correlation does not imply causation."
> — Edward Tufte

本周作业要求你**完整走一遍因果推断流程**：从识别问题层级，到画因果图，到选择调整集，到估计因果效应，到审查 AI 生成的因果结论。你不再只是"发现相关"，而是学会回答"如果干预会怎样"——这是数据科学家的关键跃迁。

---

## 作业结构

| 层级 | 内容 | 建议时间 |
|------|------|----------|
| 基础作业（必做） | 因果三层级识别、画因果图（DAG）、后门准则应用、倾向评分匹配 | 4-5 小时 |
| 进阶作业（选做） | DoWhy 真实数据分析、匹配质量检查与 Bootstrap | 1-2 小时 |
| 挑战作业（可选） | 设计因果推断实验（识别策略 + 估计 + 敏感性分析） | 2-3 小时 |
| AI 协作练习（可选） | 审查 AI 生成的因果结论 | 1 小时 |

---

## 基础作业（必做）

### 任务 1：因果三层级识别（20 分）

**目标**：区分"关联"、"干预"和"反事实"三类问题

**步骤**：

1. 阅读以下研究问题，判断每个问题属于哪个层级：

   - 问题 A：使用优惠券的用户，平均消费金额比未使用的高多少？
   - 问题 B：如果给用户发放优惠券，他的消费金额会提高多少？
   - 问题 C：如果张三没有使用优惠券，他会消费多少？
   - 问题 D：教育水平和收入相关吗？
   - 问题 E：如果给员工提供培训，他的绩效会提高吗？
   - 问题 F：如果这个患者没有服用药物，他的血压会是多少？

2. 对每个问题，填写以下表格（保存为 `causal_levels.md`）：

   | 问题 | 层级（关联/干预/反事实） | 能用什么方法回答？ | 为什么这个方法有效？ |
   |------|------------------------|-------------------|-------------------|
   | A    |                        |                   |                     |
   | ...  |                        |                   |                     |

3. **关键区分**（写 150 字反思）：
   - 问题 A 和 B 有什么本质区别？
   - 为什么"相关"方法不能回答"干预"问题？
   - 举一个"把相关当成因果"的真实场景（可以是新闻、产品决策等）

**评分标准**：
- 层级判断正确（10 分，每题 1.5 分，表格完整性 1 分）
- 方法选择合理（5 分）
- 反思深入（5 分）

---

### 任务 2：画因果图（DAG）（30 分）

**目标**：用因果图表达因果假设，识别混杂、中介和对撞变量

**场景**：

某电商平台想评估"优惠券对消费的影响"。以下是业务团队给出的变量关系：

- **用户活跃度**（Activity）：活跃用户更愿意领取优惠券，也更愿意消费
- **历史消费**（History_Spend）：高消费用户更关注优惠，也更容易继续高消费
- **优惠券使用**（Coupon）：是否使用优惠券（0/1）
- **消费金额**（Spending）：消费金额（元）
- **使用频率**（Frequency）：优惠券使用后，用户可能更频繁访问应用
- **用户年龄**（Age）：年长用户消费更高，也更愿意使用优惠券

**步骤**：

1. **画因果图**（使用 networkx 或手绘后扫描）：
   - 节点：所有上述变量
   - 边：根据业务描述画出因果关系箭头
   - 标注：哪条边是"我们想估计的因果效应"？

2. **识别三种结构**：
   - **链式（中介）**：找出一条 X → M → Y 的路径
   - **叉式（混杂）**：找出同时影响 X 和 Y 的变量
   - **对撞（选择偏差）**：如果存在，找出 X → Z ← Y 的结构

3. **回答以下问题**（写入 `dag_analysis.md`）：
   - 如果我们直接比较"用券用户"和"未用券用户"的消费差异，会被哪些混杂变量影响？
   - "使用频率"是中介变量还是混杂变量？为什么？
   - 如果我们调整了"使用频率"，会发生什么？（会低估还是高估优惠券效应？）

4. **可视化提交**：
   - 保存因果图为 `causal_dag.png`（使用 networkx 或手绘）
   - 在图上标注：处理变量（X）、结果变量（Y）、混杂变量（Z）

**输入示例**：
```
变量关系描述：
- 活跃用户更愿意领券：Activity → Coupon
- 活跃用户消费更高：Activity → Spending
- 高消费用户更关注优惠：History_Spend → Coupon
- 高消费用户继续高消费：History_Spend → Spending
- 优惠券提高消费：Coupon → Spending
- 用券后访问更频繁：Coupon → Frequency
- 频繁访问提高消费：Frequency → Spending
```

**输出示例**：
```
因果图结构：
- 处理变量（X）：Coupon
- 结果变量（Y）：Spending
- 混杂变量（Z）：Activity, History_Spend
- 中介变量（M）：Frequency
- 后门路径：
  1. Coupon ← Activity → Spending
  2. Coupon ← History_Spend → Spending

结论：需要调整 Activity 和 History_Spend，但不能调整 Frequency（会切断因果路径）
```

**评分标准**：
- 因果图正确（10 分）
- 三种结构识别正确（10 分，每个 3-4 分）
- 问题回答准确（10 分）

---

### 任务 3：后门准则应用（25 分）

**目标**：给定因果图，判断需要调整哪些变量才能识别因果效应

**场景**：

评估"在线课程对考试成绩的影响"。因果图如下：

```
学习动机 → 在线课程使用
    ↓           ↓
考试成绩 ←──────┘
    ↑
家庭收入 ────────┘
```

变量说明：
- **在线课程使用**（Treatment）：是否使用在线课程（0/1）
- **考试成绩**（Outcome）：考试成绩（0-100 分）
- **学习动机**（Motivation）：学习动机评分（1-10 分）
- **家庭收入**（Income）：家庭年收入（万元）

**步骤**：

1. **识别因果路径和后门路径**：
   - 因果路径：在线课程 → 考试成绩
   - 后门路径 1：在线课程 ← 学习动机 → 考试成绩
   - 后门路径 2：在线课程 ← 学习动机 ← 家庭收入 → 考试成绩（假设收入影响动机）
   - 是否有其他后门路径？

2. **应用后门准则**：
   - 写出后门准则的三个条件（参考 CHAPTER.md）
   - 判断：需要调整哪些变量？
   - 判断：哪些变量**不能**调整（如果有中介或对撞）？

3. **对比分析**（写入 `backdoor_analysis.md`）：
   - **未调整**：直接比较使用和未使用在线课程的学生成绩差异
   - **错误调整**：调整了某个中介变量（假设"学习时长"是中介）
   - **正确调整**：根据后门准则调整混杂变量

   用表格对比三种情况的估计值（可以模拟数据或用示例数字）：

   | 调整策略 | 估计值 | 是否有偏？ | 原因 |
   |---------|--------|-----------|------|
   | 未调整   | +15 分 | 有偏 | 混杂未控制 |
   | 错误调整 | +5 分  | 有偏 | 中介被切断 |
   | 正确调整 | +10 分 | 无偏 | 后门路径被阻断 |

4. **用 DoWhy 验证**（可选）：
   - 安装 DoWhy：`pip install dowhy`
   - 用 `model.identify_effect()` 自动识别后门调整集
   - 对比你手动识别的结果

**评分标准**：
- 路径识别正确（8 分）
- 后门准则应用正确（10 分）
- 对比分析清晰（7 分）

---

### 任务 4：倾向评分匹配实现（25 分）

**目标**：用倾向评分匹配估计因果效应，检查匹配质量

**数据**：使用 `examples/04_causal_estimation.py` 中生成的优惠券数据

**步骤**：

1. **估计倾向评分**：
   - 用 Logistic 回归预测"使用优惠券的概率"
   - 特征：用户活跃度、历史消费（混杂变量）
   - 保存倾向评分到数据框

2. **执行匹配**：
   - 为每个"用券用户"（处理组）找一个"未用券用户"（对照组）
   - 匹配方法：1:1 最近邻匹配（基于倾向评分）
   - 卡尺：可选，设置最大距离阈值（如 0.05）

3. **匹配质量检查**（关键步骤）：
   - **匹配前**：画两组的倾向评分分布（两个直方图）
   - **匹配后**：画处理组和匹配对照组的倾向评分分布
   - **计算标准化差异**（Standardized Mean Difference, SMD）：
     - SMD = (均值处理 - 均值对照) / 合并标准差
     - 匹配后，SMD 应 < 0.1（表示平衡良好）

4. **估计因果效应（ATT）**：
   - 计算处理组和匹配对照组的平均消费差异
   - 用 Bootstrap 估计 95% 置信区间（500 次重采样）

5. **提交** `matching_report.md`，包含：
   - 倾向评分分布对比图（匹配前后）
   - 匹配前后协变量平衡表（SMD 对比）
   - 因果效应估计（ATT + 95% CI）
   - 解释：优惠券是否有效？效应量有多大？

**输入示例**：
```
原始数据：
user_id | activity | history_spend | coupon | spending
1       | 15       | 200           | 1       | 150
2       | 8        | 50            | 0       | 80
...
```

**输出示例**：
```
匹配质量检查：
- 匹配前 SMD（activity）：0.85 → 不平衡
- 匹配后 SMD（activity）：0.05 → 平衡
- 匹配前 SMD（history_spend）：0.92 → 不平衡
- 匹配后 SMD（history_spend）：0.03 → 平衡

因果效应估计：
- ATT：28.5 元
- 95% CI：[20.3, 36.7] 元
- 结论：在控制了用户活跃度和历史消费后，优惠券使消费金额提高约 29 元（置信区间不包含 0，效应显著）
```

**评分标准**：
- 倾向评分估计正确（5 分）
- 匹配实现正确（8 分）
- 匹配质量检查完整（8 分，可视化 4 分 + SMD 4 分）
- 效应估计和解释合理（4 分）

---

## 进阶作业（选做）

### 任务 5：用 DoWhy 分析真实数据集（30 分）

**目标**：使用 DoWhy 库完成端到端因果推断

**数据**：选择以下之一
- 你的 StatLab 数据集
- 公开数据集（如 `data/coupon_data.csv`）
- 使用 `examples/05_statlab_causal.py` 生成模拟数据

**步骤**：

1. **定义因果模型**：
   ```python
   from dowhy import CausalModel

   causal_graph = """digraph {
       activity -> coupon;
       activity -> spending;
       history_spend -> coupon;
       history_spend -> spending;
       coupon -> spending;
   }"""

   model = CausalModel(
       data=df,
       treatment="coupon",
       outcome="spending",
       graph=causal_graph
   )
   ```

2. **识别因果效应**：
   ```python
   identified_estimand = model.identify_effect()
   print(identified_estimand)
   ```

3. **估计因果效应**（至少用两种方法）：
   - 方法 1：基于回归的估计
   - 方法 2：倾向评分匹配
   - 对比两种方法的估计值

4. **敏感性分析（Refutation Tests）**：
   - **Placebo Treatment**：随机替换处理变量，效应应变为 0
   - **Random Common Cause**：添加随机混杂，效应应稳定
   - **Data Subset**：删除部分数据，效应应稳定

   ```python
   refute = model.refute_estimate(
       estimator=estimate,
       method_name="placebo_treatment_refuter"
   )
   print(refute)
   ```

5. **提交** `dowhy_analysis.md`，包含：
   - 因果图（GML 格式或可视化）
   - 识别的因果效应表达式
   - 两种方法的估计值对比
   - 敏感性分析结果（至少 2 个 refutation test）
   - 结论：因果效应估计是否稳健？

**评分标准**：
- DoWhy 模型定义正确（8 分）
- 识别和估计正确（10 分）
- 敏感性分析完整（8 分）
- 报告清晰（4 分）

---

### 任务 6：匹配质量深入检查（20 分）

**目标**：深入评估倾向评分匹配的质量，发现潜在问题

**步骤**：

1. **多种匹配方法对比**：
   - 1:1 最近邻匹配
   - 1:5 近邻匹配
   - 卡尺匹配（caliper = 0.05, 0.1）
   - 对比不同方法的 ATT 估计值和匹配率

2. **协变量平衡检查**（扩展）：
   - 计算匹配前后所有协变量的 SMD
   - 画 Love Plot（SMD 对比图，匹配前后）
   - 检查：是否所有协变量 SMD < 0.1？

3. **共同支撑域检查**：
   - 画处理组和对照组的倾向评分密度图
   - 标注"重叠区域"和"非重叠区域"
   - 计算：有多少比例的样本无法匹配？

4. **分层 vs 匹配**：
   - 用倾向评分分层（5 分位）
   - 计算各层的因果效应
   - 加权平均得到 ATE（平均处理效应）
   - 对比 ATT 和 ATE 的差异

5. **提交** `matching_quality_report.md`，包含：
   - 不同匹配方法的对比表
   - Love Plot（SMD 对比）
   - 共同支撑域可视化
   - 分层分析结果
   - 最终选择：哪种方法最合适？为什么？

**评分标准**：
- 多种匹配方法对比正确（5 分）
- 平衡检查完整（8 分，SMD + Love Plot）
- 共同支撑域分析（4 分）
- 分层分析（3 分）

---

## 挑战作业（可选）

### 任务 7：设计因果推断实验（35 分）

**目标**：从零设计一个因果推断研究，包含识别策略、估计和敏感性分析

**场景选择**（选择其一）：
- 你的 StatLab 数据集
- 你关心的实际问题（如"推荐系统对留存的影响"）
- 模拟数据（需有明确的因果机制）

**要求**：

1. **研究设计**（5 分）：
   - 明确研究问题（必须是因果问题："如果……会怎样"）
   - 定义处理变量（X）和结果变量（Y）
   - 列出潜在的混杂变量（至少 3 个）
   - 画因果图（DAG）

2. **识别策略**（10 分）：
   - 应用后门准则，确定调整集
   - 说明：为什么调整这些变量？
   - 说明：哪些变量不能调整？（中介/对撞）
   - 用 DoWhy 验证你的调整集

3. **因果效应估计**（10 分）：
   - 用至少两种方法估计因果效应：
     - 回归（带调整集）
     - 倾向评分匹配
     - 双重稳健估计（可选，加分项）
   - 报告：估计值、标准误、95% CI
   - 对比两种方法的结果

4. **敏感性分析**（5 分）：
   - 用 DoWhy 做至少 2 个 refutation test
   - 评估：如果存在未观察混杂，结论会如何变化？
   - E-value 计算（可选，高级）

5. **报告撰写**（5 分）：
   - 写一份完整的因果推断报告（Markdown 格式）
   - 包含：背景、因果图、识别策略、估计结果、敏感性分析、局限性、结论
   - 明确区分"因果结论"和"相关发现"

6. **代码提交**：
   - 提交可复现的 Python 脚本或 Jupyter Notebook
   - 代码有清晰注释
   - 使用固定随机种子确保可复现

**提交文件**：
- `causal_experiment_design.md`（研究设计 + 报告）
- `causal_analysis.py` 或 `causal_analysis.ipynb`（代码）

**评分标准**：
- 研究设计合理性（10 分，因果图 + 识别策略）
- 分析完整性（15 分，估计 + 敏感性分析）
- 报告质量（7 分，结构清晰 + 结论明确）
- 代码可复现性（3 分）

---

## AI 协作练习（可选）

### 任务 8：审查 AI 生成的因果结论（20 分）

**背景**：根据 `CLAUDE.md` 的 AI 融合渐进路径，Week 13 属于**"主导期"**（Week 13-16）——AI 作为结对分析伙伴。你需要学会审查 AI 生成的因果结论，识别"把相关当成因果"的常见错误。

**步骤**：

1. **获取 AI 生成的因果结论**：
   - 使用你喜欢的 AI 工具（如 ChatGPT、Claude 等）
   - 输入以下提示词：
     ```
     我有一份电商数据，包含以下变量：
     - coupon: 是否使用优惠券（0/1）
     - spending: 消费金额（元）
     - activity: 用户活跃度（活跃天数/月）
     - history_spend: 历史消费金额（元）

     数据显示：使用优惠券的用户平均消费 150 元，未使用的用户平均消费 100 元，差异为 50 元，p < 0.001。

     请分析：优惠券是否真的提高了消费？如果提高了，提高了多少？
     请给出具体的因果效应估计和解释。
     ```

2. **保存 AI 原始输出**，将其保存为 `ai_original_causal.txt`

3. **使用审查清单**：

   检查 AI 生成的结论：

   - [ ] **问题层级识别**：AI 是否区分了"关联"和"干预"？
   - [ ] **混杂变量**：AI 是否提到了混杂变量（活跃度、历史消费）？
   - [ ] **因果图**：AI 是否画了因果图（DAG）或明确表达因果假设？
   - [ ] **识别策略**：AI 是否说明了"为什么要调整这些变量"？
   - [ ] **效应估计**：AI 是否给出了因果效应估计（不只是均值差）？
   - [ ] **不确定性**：AI 是否报告了置信区间或标准误？
   - [ ] **结论边界**：AI 是否说明了"能回答什么、不能回答什么"？
   - [ ] **警告**：AI 是否警告了"相关 ≠ 因果"？

4. **写一份审查报告** `ai_causal_review.md`，包含：
   - **AI 原始结论**（摘要，100 字）
   - **问题列表**（按严重性分类：高/中/低）：
     - 高危：混淆相关与因果、未调整混杂、夸大结论
     - 中危：未报告不确定性、未说明识别策略
     - 低危：术语使用不严谨、缺少可视化
   - **你的修订版**（200-300 字）：
     - 正确区分关联问题和因果问题
     - 明确混杂变量和调整策略
     - 给出因果效应估计和置信区间
     - 说明结论边界
   - **给 AI 的改进建议**（100 字）：
     - 如果让它重新生成，你会怎么提示？
     - 哪些是人类必须负责的，AI 无法替代？

5. **反思**（150 字）：
   - AI 在因果推断任务上表现如何？
   - AI 容易犯哪些错误？（把相关当因果、忽略混杂、夸大结论）
   - 哪些环节是**人类必须主导**的？（画因果图、识别策略、解释边界）
   - 你会如何使用 AI 辅助因果推断？（让它计算/画图，你负责假设/决策）

**评分标准**：
- 审查全面性（10 分）
- 问题分类合理（5 分）
- 修订版结论准确（5 分）

**常见 AI 错误示例**（供参考）：

| 错误类型 | AI 可能的输出 | 为什么是错的 |
|---------|--------------|------------|
| 混淆相关与因果 | "优惠券使消费提高 50 元" | 这是均值差（关联），不是因果效应 |
| 忽略混杂 | "直接比较两组即可" | 不调整混杂，估计有偏 |
| 夸大结论 | "优惠券对所有人都有效" | 只估计了平均效应，异质性未知 |
| 未识别策略 | "回归结果显示……" | 没说明为什么调整这些变量（后门准则） |
| 缺少边界 | "结论成立" | 未说明假设（无未观察混杂）、外推性限制 |

---

## StatLab 集成

**要求**：本周所有基础作业的产出应整合到你的 StatLab 报告中

**具体操作**：

1. 在你的 `report.md` 中添加"因果推断"章节
2. 使用 `examples/05_statlab_causal.py` 作为参考或直接调用
3. 包含以下内容：
   - 研究问题的因果层级（关联/干预/反事实）
   - 因果图（DAG）
   - 识别策略（后门准则应用）
   - 因果效应估计（回归 + 匹配）
   - 匹配质量检查（SMD、可视化）
   - 结论边界（能回答什么、不能回答什么）

---

## 提交方式

1. 将所有文件放入 `chapters/week_13/assignment/` 目录
2. 文件命名规范：
   - `causal_levels.md`
   - `causal_dag.png`
   - `dag_analysis.md`
   - `backdoor_analysis.md`
   - `matching_report.md`
   - `matching_quality_report.md`（进阶）
   - `dowhy_analysis.md`（进阶）
   - `causal_experiment_design.md`（挑战）
   - `causal_analysis.py`（挑战）
   - `ai_original_causal.txt`（AI 协作）
   - `ai_causal_review.md`（AI 协作）
3. 确保所有 Markdown 文档使用清晰的章节结构

---

## 作业提示

### 常见错误

1. **把相关当成因果**：这是最危险的错误。如果你没有调整混杂，直接比较两组差异，这只是"关联"，不是"因果"。

2. **盲目调整一切**：不要调整中介变量（如"使用频率"），否则会切断因果路径，低估效应。使用后门准则科学地选择调整集。

3. **忽略匹配质量**：倾向评分匹配后，**必须检查平衡性**（SMD < 0.1）。如果匹配后仍然不平衡，估计可能有偏。

4. **混淆 ATT 和 ATE**：
   - ATT（Average Treatment Effect on the Treated）：处理组的平均处理效应
   - ATE（Average Treatment Effect）：全人群的平均处理效应
   - 倾向评分匹配通常估计的是 ATT

5. **忘记画因果图**：因果推断的第一步永远是画 DAG。没有因果图，你的假设是隐式的，无法讨论和审计。

6. **夸大结论**：
   - 不要说"优惠券有效"，要说"在控制了活跃度和历史消费后，优惠券使消费提高约 29 元（95% CI [20, 38]）"
   - 明确限制：只适用于观察期内的短期效应，假设无未观察混杂

### 检查清单

在提交作业前，问自己：

- [ ] 我区分了"关联问题"和"因果问题"吗？
- [ ] 我画了因果图（DAG）吗？
- [ ] 我用后门准则选择调整集了吗？
- [ ] 我检查匹配质量（SMD）了吗？
- [ ] 我报告了置信区间吗？
- [ ] 我明确说明了"能回答什么、不能回答什么"吗？
- [ ] 我没有把相关当成因果吗？
- [ ] 我的代码可以复现吗（固定随机种子）？

### AI 辅助建议

- **可以用 AI 做的事**：写代码、画图、计算 p 值和置信区间、生成可视化
- **人类必须做的事**：画因果图、识别混杂变量、选择调整集、解释结论边界、判断 AI 输出是否可靠
- **审查原则**：AI 给你的是一个"候选结论"，你必须用统计知识和领域知识验证它

### 推荐资源

- DoWhy 文档：https://www.pywhy.org/dowhy/
- CausalML 文档：https://causalml.readthedocs.io/
- 《Causal Inference in Statistics: A Primer》——Judea Pearl 等著
- 《Mastering Metrics》——Joshua Angrist 等著
