"""
ç¤ºä¾‹ï¼šå®Œæ•´çš„åˆ†ç±»æµæ°´çº¿â€”â€”ä»é¢„å¤„ç†åˆ°è¯„ä¼°

æœ¬ä¾‹æ¼”ç¤ºï¼š
1. ä½¿ç”¨ ColumnTransformer å¤„ç†æ··åˆæ•°æ®ç±»å‹
2. æ„å»º Pipelineï¼ˆé¢„å¤„ç† + é€»è¾‘å›å½’ï¼‰
3. K-fold åˆ†å±‚äº¤å‰éªŒè¯
4. ä¸åŸºçº¿æ¨¡å‹å¯¹æ¯”

è¿è¡Œæ–¹å¼ï¼špython3 chapters/week_10/examples/05_complete_pipeline.py
é¢„æœŸè¾“å‡ºï¼š
- äº¤å‰éªŒè¯ç»“æœï¼ˆå‡†ç¡®ç‡ã€F1ã€AUCï¼‰
- æ··æ·†çŸ©é˜µå’Œåˆ†ç±»æŠ¥å‘Š
- ä¸åŸºçº¿æ¨¡å‹å¯¹æ¯”
"""
from __future__ import annotations

import numpy as np
import pandas as pd
from sklearn.linear_model import LogisticRegression
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate
from sklearn.metrics import (
    confusion_matrix, classification_report,
    roc_auc_score, accuracy_score, f1_score
)
from sklearn.dummy import DummyClassifier

# è®¾ç½®éšæœºç§å­
np.random.seed(42)

# è®¾ç½®ä¸­æ–‡å­—ä½“
import matplotlib.pyplot as plt
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def generate_mixed_type_data(n_samples: int = 1000) -> pd.DataFrame:
    """
    ç”Ÿæˆæ··åˆæ•°æ®ç±»å‹ï¼ˆæ•°å€¼ + ç±»åˆ«ï¼‰çš„å®¢æˆ·æµå¤±æ•°æ®

    å‚æ•°:
        n_samples: æ ·æœ¬æ•°é‡

    è¿”å›:
        åŒ…å«æ•°å€¼å’Œç±»åˆ«ç‰¹å¾çš„ DataFrame
    """
    # æ•°å€¼ç‰¹å¾
    tenure_months = np.random.uniform(1, 72, n_samples)
    monthly_charges = np.random.uniform(20, 120, n_samples)
    total_charges = tenure_months * monthly_charges + np.random.normal(0, 50, n_samples)

    # ç±»åˆ«ç‰¹å¾
    contract_type = np.random.choice(['æœˆä»˜', 'ä¸€å¹´', 'ä¸¤å¹´'], n_samples, p=[0.5, 0.3, 0.2])
    payment_method = np.random.choice(['ç”µå­æ”¯ç¥¨', 'é‚®å¯„æ”¯ç¥¨', 'é“¶è¡Œè½¬è´¦', 'ä¿¡ç”¨å¡'], n_samples)
    internet_service = np.random.choice(['DSL', 'å…‰çº¤', 'æ— '], n_samples, p=[0.3, 0.5, 0.2])

    # ç”Ÿæˆç›®æ ‡å˜é‡ï¼ˆæµå¤±ï¼‰
    # åˆåŒæœŸè¶ŠçŸ­ã€æœˆè´¹è¶Šé«˜ï¼Œè¶Šå®¹æ˜“æµå¤±
    prob_churn = (
        0.8 * (contract_type == 'æœˆä»˜').astype(int) +
        0.3 * (contract_type == 'ä¸€å¹´').astype(int) +
        0.1 * (monthly_charges / 120) +
        0.05 * (tenure_months / 72)
    )
    prob_churn = np.clip(prob_churn, 0, 1)
    churn = np.random.binomial(1, prob_churn)

    # åˆ›å»º DataFrame
    df = pd.DataFrame({
        'tenure_months': tenure_months,
        'monthly_charges': monthly_charges,
        'total_charges': total_charges,
        'contract_type': contract_type,
        'payment_method': payment_method,
        'internet_service': internet_service,
        'churn': churn
    })

    # æ·»åŠ ä¸€äº›ç¼ºå¤±å€¼ï¼ˆæ¨¡æ‹ŸçœŸå®æ•°æ®ï¼‰
    missing_indices = np.random.choice(df.index, size=int(n_samples * 0.05), replace=False)
    df.loc[missing_indices, 'total_charges'] = np.nan

    return df


def build_classification_pipeline(
    numeric_features: list,
    categorical_features: list
) -> Pipeline:
    """
    æ„å»ºå®Œæ•´çš„åˆ†ç±» Pipeline

    å‚æ•°:
        numeric_features: æ•°å€¼ç‰¹å¾åˆ—è¡¨
        categorical_features: ç±»åˆ«ç‰¹å¾åˆ—è¡¨

    è¿”å›:
        sklearn Pipeline å¯¹è±¡
    """
    # æ•°å€¼ç‰¹å¾é¢„å¤„ç†ï¼šå¡«å……ç¼ºå¤±å€¼ + æ ‡å‡†åŒ–
    numeric_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='median')),
        ('scaler', StandardScaler())
    ])

    # ç±»åˆ«ç‰¹å¾é¢„å¤„ç†ï¼šå¡«å……ç¼ºå¤±å€¼ + One-Hot ç¼–ç 
    categorical_transformer = Pipeline(steps=[
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
    ])

    # ColumnTransformerï¼šå¯¹ä¸åŒåˆ—åº”ç”¨ä¸åŒé¢„å¤„ç†
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', numeric_transformer, numeric_features),
            ('cat', categorical_transformer, categorical_features)
        ],
        remainder='drop'  # ä¸¢å¼ƒæœªæŒ‡å®šçš„åˆ—
    )

    # å®Œæ•´ Pipeline
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', LogisticRegression(random_state=42, max_iter=1000))
    ])

    return pipeline


def evaluate_model(
    pipeline: Pipeline,
    X_train, y_train,
    X_test, y_test,
    model_name: str = "æ¨¡å‹"
) -> dict:
    """
    è¯„ä¼°æ¨¡å‹æ€§èƒ½

    è¿”å›:
        åŒ…å«å„ç§è¯„ä¼°æŒ‡æ ‡çš„å­—å…¸
    """
    # æ‹Ÿåˆ
    pipeline.fit(X_train, y_train)

    # é¢„æµ‹
    y_pred = pipeline.predict(X_test)
    y_proba = pipeline.predict_proba(X_test)[:, 1]

    # è®¡ç®—æŒ‡æ ‡
    cm = confusion_matrix(y_test, y_pred)
    tn, fp, fn, tp = cm.ravel()

    results = {
        'name': model_name,
        'confusion_matrix': cm,
        'accuracy': accuracy_score(y_test, y_pred),
        'precision': tp / (tp + fp) if (tp + fp) > 0 else 0,
        'recall': tp / (tp + fn) if (tp + fn) > 0 else 0,
        'f1': f1_score(y_test, y_pred),
        'auc': roc_auc_score(y_test, y_proba),
        'y_pred': y_pred,
        'y_proba': y_proba
    }

    return results


def cross_validate_pipeline(
    pipeline: Pipeline,
    X, y,
    n_folds: int = 5
) -> dict:
    """
    K-fold åˆ†å±‚äº¤å‰éªŒè¯

    è¿”å›:
        åŒ…å«äº¤å‰éªŒè¯ç»“æœçš„å­—å…¸
    """
    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)

    # è¯„ä¼°å¤šä¸ªæŒ‡æ ‡
    scoring = {
        'accuracy': 'accuracy',
        'f1': 'f1',
        'roc_auc': 'roc_auc',
        'recall': 'recall'
    }

    cv_results = cross_validate(
        pipeline, X, y,
        cv=skf,
        scoring=scoring,
        return_train_score=False
    )

    # æå–ç»“æœ
    results = {}
    for metric in scoring.keys():
        scores = cv_results[f'test_{metric}']
        results[metric] = {
            'mean': scores.mean(),
            'std': scores.std(),
            'values': scores
        }

    return results


def print_evaluation_summary(results: dict, cv_results: dict) -> None:
    """æ‰“å°è¯„ä¼°æ‘˜è¦"""
    print("\n" + "=" * 60)
    print(f"{results['name']}ï¼šè¯„ä¼°ç»“æœ")
    print("=" * 60)

    # æµ‹è¯•é›†æŒ‡æ ‡
    print(f"\nã€æµ‹è¯•é›†æ€§èƒ½ã€‘")
    print(f"  å‡†ç¡®ç‡: {results['accuracy']:.3f}")
    print(f"  ç²¾ç¡®ç‡: {results['precision']:.3f}")
    print(f"  å¬å›ç‡: {results['recall']:.3f}")
    print(f"  F1 åˆ†æ•°: {results['f1']:.3f}")
    print(f"  AUC: {results['auc']:.3f}")

    # æ··æ·†çŸ©é˜µ
    cm = results['confusion_matrix']
    print(f"\nã€æ··æ·†çŸ©é˜µã€‘")
    print(f"  {'':>12} {'é¢„æµ‹ä¸æµå¤±':>12} {'é¢„æµ‹æµå¤±':>12}")
    print(f"  {'å®é™…ä¸æµå¤±':>12} {cm[0, 0]:>12} {cm[0, 1]:>12}")
    print(f"  {'å®é™…æµå¤±':>12} {cm[1, 0]:>12} {cm[1, 1]:>12}")

    # äº¤å‰éªŒè¯ç»“æœ
    print(f"\nã€5-fold äº¤å‰éªŒè¯ã€‘")
    for metric, values in cv_results.items():
        print(f"  {metric:>10}: {values['mean']:.3f} Â± {values['std']:.3f}")


def main() -> None:
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ç¤ºä¾‹5: å®Œæ•´çš„åˆ†ç±»æµæ°´çº¿")
    print("=" * 60)

    # 1. ç”Ÿæˆæ•°æ®
    df = generate_mixed_type_data(n_samples=1000)

    print(f"\nğŸ“Š æ•°æ®æ¦‚è§ˆ:")
    print(df.head(10))
    print(f"\næ•°æ®ç±»å‹:")
    print(df.dtypes)
    print(f"\nç¼ºå¤±å€¼:")
    print(df.isnull().sum())
    print(f"\næµå¤±ç‡: {df['churn'].mean():.1%}")

    # 2. å‡†å¤‡æ•°æ®
    numeric_features = ['tenure_months', 'monthly_charges', 'total_charges']
    categorical_features = ['contract_type', 'payment_method', 'internet_service']

    X = df[numeric_features + categorical_features]
    y = df['churn']

    # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=42, stratify=y
    )

    print(f"\nâœ… æ•°æ®åˆ’åˆ†:")
    print(f"  è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬ (æµå¤±ç‡ {y_train.mean():.1%})")
    print(f"  æµ‹è¯•é›†: {len(X_test)} æ ·æœ¬ (æµå¤±ç‡ {y_test.mean():.1%})")

    # 3. æ„å»º Pipeline
    print(f"\nâœ… æ„å»º Pipeline...")
    pipeline = build_classification_pipeline(numeric_features, categorical_features)
    print(f"  Pipeline ç»“æ„:")
    print(f"    1. ColumnTransformer (é¢„å¤„ç†)")
    print(f"       - æ•°å€¼ç‰¹å¾: SimpleImputer(median) + StandardScaler")
    print(f"       - ç±»åˆ«ç‰¹å¾: SimpleImputer(most_frequent) + OneHotEncoder")
    print(f"    2. LogisticRegression(random_state=42)")

    # 4. äº¤å‰éªŒè¯
    print(f"\nâœ… è¿è¡Œ 5-fold äº¤å‰éªŒè¯...")
    cv_results = cross_validate_pipeline(pipeline, X, y, n_folds=5)

    # 5. æµ‹è¯•é›†è¯„ä¼°
    print(f"\nâœ… åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°...")
    results = evaluate_model(
        pipeline, X_train, y_train, X_test, y_test,
        model_name="é€»è¾‘å›å½’"
    )

    # 6. æ‰“å°ç»“æœ
    print_evaluation_summary(results, cv_results)

    # 7. ä¸åŸºçº¿å¯¹æ¯”
    print("\n" + "=" * 60)
    print("ä¸åŸºçº¿æ¨¡å‹å¯¹æ¯”")
    print("=" * 60)

    # åŸºçº¿ï¼šå¤šæ•°ç±»åˆ†ç±»å™¨
    dummy = DummyClassifier(strategy='most_frequent', random_state=42)
    dummy_results = evaluate_model(
        dummy, X_train, y_train, X_test, y_test,
        model_name="å¤šæ•°ç±»åŸºçº¿"
    )

    print(f"\n{'æŒ‡æ ‡':<15} {'åŸºçº¿æ¨¡å‹':>15} {'é€»è¾‘å›å½’':>15} {'æ”¹è¿›':>15}")
    print("-" * 60)
    print(f"{'å‡†ç¡®ç‡':<15} {dummy_results['accuracy']:>15.3f} {results['accuracy']:>15.3f} {(results['accuracy'] - dummy_results['accuracy']):>+15.1%}")
    print(f"{'å¬å›ç‡':<15} {dummy_results['recall']:>15.3f} {results['recall']:>15.3f} {(results['recall'] - dummy_results['recall']):>+15.1%}")
    print(f"{'F1 åˆ†æ•°':<15} {dummy_results['f1']:>15.3f} {results['f1']:>15.3f} {(results['f1'] - dummy_results['f1']):>+15.1%}")
    print(f"{'AUC':<15} {dummy_results['auc']:>15.3f} {results['auc']:>15.3f} {(results['auc'] - dummy_results['auc']):>+15.1%}")

    # 8. æŸ¥çœ‹ç³»æ•°ï¼ˆå¯è§£é‡Šæ€§ï¼‰
    print("\n" + "=" * 60)
    print("æ¨¡å‹å¯è§£é‡Šæ€§ï¼šç‰¹å¾é‡è¦æ€§")
    print("=" * 60)

    # è·å–ç‰¹å¾åï¼ˆOne-Hot ç¼–ç åï¼‰
    feature_names = numeric_features + list(
        pipeline.named_steps['preprocessor']
        .named_transformers_['cat']
        .named_steps['onehot']
        .get_feature_names_out(categorical_features)
    )

    # è·å–ç³»æ•°
    coefs = pipeline.named_steps['classifier'].coef_[0]

    # åˆ›å»ºç³»æ•°è¡¨
    coef_df = pd.DataFrame({
        'ç‰¹å¾': feature_names,
        'ç³»æ•°': coefs,
        '|ç³»æ•°|': np.abs(coefs)
    }).sort_values('|ç³»æ•°|', ascending=False)

    print(f"\nå‰ 10 ä¸ªæœ€é‡è¦çš„ç‰¹å¾:")
    print(coef_df.head(10).to_string(index=False))

    # 9. æ€»ç»“
    print("\n" + "=" * 60)
    print("æ€»ç»“")
    print("=" * 60)
    print(f"""
å®Œæ•´çš„åˆ†ç±»æµæ°´çº¿åŒ…å«ï¼š

1. æ•°æ®é¢„å¤„ç†ï¼š
   - æ•°å€¼ç‰¹å¾ï¼šå¡«å……ç¼ºå¤±å€¼ï¼ˆä¸­ä½æ•°ï¼‰+ æ ‡å‡†åŒ–
   - ç±»åˆ«ç‰¹å¾ï¼šå¡«å……ç¼ºå¤±å€¼ï¼ˆä¼—æ•°ï¼‰+ One-Hot ç¼–ç 

2. æ¨¡å‹è®­ç»ƒï¼š
   - é€»è¾‘å›å½’ï¼ˆå¯è§£é‡Šæ€§å¼ºï¼‰
   - æ­£åˆ™åŒ–é˜²æ­¢è¿‡æ‹Ÿåˆ

3. è¯„ä¼°æ–¹æ³•ï¼š
   - K-fold åˆ†å±‚äº¤å‰éªŒè¯ï¼ˆç¨³å¥ä¼°è®¡ï¼‰
   - å¤šæŒ‡æ ‡è¯„ä¼°ï¼ˆå‡†ç¡®ç‡ã€F1ã€AUCï¼‰
   - ä¸åŸºçº¿å¯¹æ¯”ï¼ˆè¯æ˜æ¨¡å‹ä»·å€¼ï¼‰

4. å·¥ç¨‹å®è·µï¼š
   - Pipeline é˜²æ­¢æ•°æ®æ³„æ¼
   - ColumnTransformer å¤„ç†æ··åˆç±»å‹
   - å¯å¤ç°çš„è®­ç»ƒæµç¨‹

å…³é”®ç»“æœï¼š
- æµ‹è¯•é›† AUC = {results['auc']:.3f}ï¼ˆ{ 'å¼º' if results['auc'] > 0.8 else 'ä¸­ç­‰' if results['auc'] > 0.7 else 'å¼±'}åŒºåˆ†èƒ½åŠ›ï¼‰
- äº¤å‰éªŒè¯æ ‡å‡†å·®è¾ƒå°ï¼ˆæ¨¡å‹ç¨³å®šï¼‰
- å¬å›ç‡æ˜¾è‘—ä¼˜äºåŸºçº¿ï¼ˆ{results['recall']:.1%} vs {dummy_results['recall']:.1%}ï¼‰
    """)

    print("\n" + "=" * 60)
    print("âœ… ç¤ºä¾‹5å®Œæˆ!")
    print("=" * 60)


if __name__ == "__main__":
    main()
