# Week 10 技术查证备忘录
生成日期：2026-02-16
来源：WebSearch + 官方文档查证

---

## 1. scikit-learn LogisticRegression

### 1.1 主要参数说明

| 参数 | 类型/默认值 | 说明 |
|------|------------|------|
| `solver` | `{'lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga'}`，默认 `'lbfgs'` | 优化算法选择 |
| `penalty` | `{'l1', 'l2', 'elasticnet', None}`，默认 `'l2'` | 正则化类型（1.8版本后弃用，改用 `l1_ratio`） |
| `C` | float，默认 1.0 | 正则化强度的倒数，越小正则化越强 |
| `class_weight` | dict 或 `'balanced'`，默认 None | 类别权重，用于处理类别不平衡 |
| `max_iter` | int，默认 100 | 最大迭代次数 |
| `tol` | float，默认 1e-4 | 收敛容差 |

### 1.2 Solver 选择最佳实践

| Solver | 适用场景 | 支持的 Penalty | 特点 |
|--------|----------|---------------|------|
| `'lbfgs'` | **默认推荐**，适用范围广 | L2, None | 拟牛顿法，适合小到中等数据集 |
| `'liblinear'` | 小数据集 | L1, L2 | 坐标下降法，适合小数据；**仅支持二分类**（多分类需用 OneVsRestClassifier） |
| `'newton-cg'` | 需要高精度 | L2, None | 牛顿法，计算 Hessian 矩阵，收敛快但计算量大 |
| `'newton-cholesky'` | 大样本量，稀疏特征 | L2, None | 适合 `n_samples >> n_features * n_classes`，内存消耗与 `(n_features * n_classes)^2` 成正比 |
| `'sag'` | 大数据集 | L2, None | 随机平均梯度下降，大数据集更快；需要特征缩放 |
| `'saga'` | 大数据集，需要 L1 | L1, L2, Elastic-Net, None | SAG 的改进版，支持所有惩罚类型；需要特征缩放 |

**官方推荐：**
- 小数据集：`'liblinear'`
- 大数据集（>10万样本）：`'sag'` 或 `'saga'`
- 多分类问题（`n_classes >= 3`）：除 `'liblinear'` 外都支持多项损失（multinomial）
- 需要 L1 正则化：必须使用 `'saga'` 或 `'liblinear'`

**⚠️ 重要提示：** `'sag'` 和 `'saga'` 需要特征缩放到相近尺度，否则收敛无法保证。建议使用 `sklearn.preprocessing` 中的 scaler 预处理数据。

### 1.3 正则化强度 C 的设置建议

- **C 的含义：** C 是正则化强度的倒数，`C = 1/λ`
  - 较小的 C → 较强的正则化 → 更简单的模型 → 防止过拟合
  - 较大的 C → 较弱的正则化 → 更复杂的模型 → 可能过拟合
  - `C=np.inf` → 无正则化

- **调参建议：**
  - 默认 `C=1.0` 是一个合理的起点
  - 常用搜索范围：`[0.001, 0.01, 0.1, 1, 10, 100]`
  - 使用 `LogisticRegressionCV` 进行自动交叉验证选择 C

### 1.4 类别不平衡时的 class_weight 用法

**`class_weight='balanced'` 的计算逻辑：**

```
weight = n_samples / (n_classes * np.bincount(y))
```

其中：
- `n_samples`: 样本总数
- `n_classes`: 类别数
- `np.bincount(y)`: 每个类别的样本数

**示例：**
```python
# 假设有 100 个样本，90 个类别 0，10 个类别 1
# weight_0 = 100 / (2 * 90) = 0.556
# weight_1 = 100 / (2 * 10) = 5.0
```

**自定义 class_weight：**
```python
# 手动指定权重
clf = LogisticRegression(class_weight={0: 1, 1: 10})

# 或使用 balanced
clf = LogisticRegression(class_weight='balanced')
```

**注意事项：**
- `class_weight` 会与 `sample_weight`（通过 `fit()` 传入）相乘
- `'balanced'` 启发式方法灵感来自 King & Zen (2001) 的 "Logistic Regression in Rare Events Data"

### 1.5 常见陷阱

| 陷阱 | 说明 | 解决方案 |
|------|------|----------|
| ConvergenceWarning | 迭代次数不足 | 增加 `max_iter`（如 1000 或 10000） |
| liblinear 不支持多分类 | 直接使用会报错 | 改用 `'lbfgs'` 或其他 solver，或用 `OneVsRestClassifier` 包装 |
| sag/saga 不收敛 | 特征尺度差异大 | 使用 `StandardScaler` 或 `MinMaxScaler` 预处理 |
| L1 + liblinear 的 dual 参数 | L1 时不支持 dual=True | 保持 `dual=False`（默认） |

### 1.6 推荐代码模板

```python
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline

# 基础用法（小数据集）
clf = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42)

# 带正则化调参
clf = LogisticRegression(solver='lbfgs', C=0.1, max_iter=1000, random_state=42)

# 类别不平衡处理
clf = LogisticRegression(
    solver='lbfgs', 
    class_weight='balanced',
    max_iter=1000, 
    random_state=42
)

# 完整 Pipeline（推荐）
pipeline = Pipeline([
    ('scaler', StandardScaler()),  # sag/saga 必需，其他 solver 也建议
    ('clf', LogisticRegression(
        solver='lbfgs',
        class_weight='balanced',
        max_iter=1000,
        random_state=42
    ))
])
```

---

## 2. 分类评估指标 sklearn.metrics

### 2.1 Confusion Matrix 混淆矩阵

**基本用法：**
```python
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_true, y_pred)
# 返回: array([[TN, FP],
#              [FN, TP]])

# 获取各个元素
tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
```

**归一化选项：**
```python
# normalize='true': 按行归一化（每行和为1，显示 Recall）
# normalize='pred': 按列归一化（每列和为1，显示 Precision）  
# normalize='all':  全局归一化（总和为1）

cm_normalized = confusion_matrix(y_true, y_pred, normalize='true')
```

**可视化：**
```python
from sklearn.metrics import ConfusionMatrixDisplay

ConfusionMatrixDisplay.from_predictions(y_true, y_pred)
# 或
ConfusionMatrixDisplay.from_estimator(model, X_test, y_test)
```

### 2.2 Precision, Recall, F1-Score

**基本用法：**
```python
from sklearn.metrics import precision_score, recall_score, f1_score

precision = precision_score(y_true, y_pred)
recall = recall_score(y_true, y_pred)
f1 = f1_score(y_true, y_pred)
```

**多分类时的 average 参数：**

| average 值 | 含义 | 适用场景 |
|-----------|------|----------|
| `'binary'` | 仅计算正类的指标 | 二分类（默认） |
| `'micro'` | 全局计算（总 TP/FP/FN） | 类别不平衡，关注总体 |
| `'macro'` | 各类别指标的无权平均 | 每类同等重要 |
| `'weighted'` | 按支持度加权的平均 | 类别不平衡，考虑各类样本数 |
| `None` | 返回各类别指标数组 | 需要每类详细分析 |

**⚠️ 重要提示：**
- `micro` 平均在多分类时会使 Precision = Recall = F1 = Accuracy
- `weighted` 平均的 F-score 可能不在 Precision 和 Recall 之间
- 二分类时默认 `average='binary'`，多分类必须指定其他 average 值

**zero_division 参数：**
```python
# 当 precision/recall 分母为0时的处理方式
precision_score(y_true, y_pred, zero_division=0)    # 返回 0
precision_score(y_true, y_pred, zero_division=1.0)  # 返回 1.0
precision_score(y_true, y_pred, zero_division='warn')  # 返回 0 并警告（默认）
precision_score(y_true, y_pred, zero_division=np.nan)  # 返回 nan（1.3+）
```

**综合报告：**
```python
from sklearn.metrics import classification_report

print(classification_report(y_true, y_pred, target_names=['class_0', 'class_1']))
```

### 2.3 ROC Curve 和 ROC AUC Score

**⚠️ 关键区别：y_proba vs y_pred**

| 输入 | 用途 | 结果 |
|------|------|------|
| `y_pred` (离散 0/1) | 仅能获得一个点 | ROC 曲线只有一条折线，AUC 计算不准确 |
| `y_proba[:, 1]` (概率) | 遍历所有阈值 | 完整的 ROC 曲线，准确的 AUC |

**正确用法：**
```python
from sklearn.metrics import roc_curve, roc_auc_score, RocCurveDisplay

# 获取预测概率
y_proba = model.predict_proba(X_test)[:, 1]  # 正类的概率

# 计算 ROC 曲线
fpr, tpr, thresholds = roc_curve(y_test, y_proba)

# 计算 AUC
auc_score = roc_auc_score(y_test, y_proba)

# 可视化
RocCurveDisplay.from_predictions(y_test, y_proba)
# 或
RocCurveDisplay.from_estimator(model, X_test, y_test)
```

**多分类 ROC AUC：**
```python
# One-vs-Rest 策略
roc_auc_score(y_test, y_proba, multi_class='ovr', average='macro')
```

**AUC 解读：**
- AUC = 0.5：随机猜测（无区分能力）
- AUC = 1.0：完美分类
- AUC > 0.8：较好
- AUC > 0.9：优秀

### 2.4 评估指标选择指南

| 场景 | 推荐指标 | 原因 |
|------|----------|------|
| 类别平衡 | Accuracy | 简单直观 |
| 类别不平衡 | Precision, Recall, F1, AUC-ROC, AUC-PR | Accuracy 会误导 |
| 关注假阳性（如垃圾邮件） | Precision | 减少误报 |
| 关注假阴性（如疾病诊断） | Recall | 减少漏报 |
| 需要阈值独立评估 | AUC-ROC, AUC-PR | 评估整体排序能力 |
| 极端不平衡（<1%） | AUC-PR (Average Precision) | ROC 可能过于乐观 |

---

## 3. 类别不平衡处理

### 3.1 class_weight='balanced' 计算逻辑

**公式：**
```
weight_class = n_samples / (n_classes * n_samples_in_class)
```

**示例计算：**
```python
import numpy as np
from sklearn.utils.class_weight import compute_class_weight

# 假设数据: 900 个 0 类，100 个 1 类
y = [0] * 900 + [1] * 100

weights = compute_class_weight(
    class_weight='balanced',
    classes=np.unique(y),
    y=y
)
# 结果: array([0.555..., 5.0])
# 计算: 1000/(2*900)=0.556, 1000/(2*100)=5.0
```

### 3.2 sample_weight 的使用场景

**与 class_weight 的区别：**

| 特性 | class_weight | sample_weight |
|------|--------------|---------------|
| 作用对象 | 类别 | 单个样本 |
| 传入方式 | 构造函数 | fit() 方法 |
| 用途 | 处理类别不平衡 | 处理样本质量差异、重要性差异 |
| 关系 | 两者相乘作为最终权重 | 两者相乘作为最终权重 |

**使用示例：**
```python
from sklearn.utils.class_weight import compute_sample_weight

# 自动生成 balanced 的 sample_weight
sample_weight = compute_sample_weight('balanced', y_train)

# 自定义 sample_weight（如给近期样本更高权重）
sample_weight = np.ones(len(y_train))
sample_weight[-100:] = 2.0  # 最近100个样本权重加倍

model.fit(X_train, y_train, sample_weight=sample_weight)
```

### 3.3 其他处理不平衡的方法

| 方法 | 说明 | sklearn 实现 |
|------|------|-------------|
| 过采样 (SMOTE) | 合成少数类样本 | `imblearn.over_sampling.SMOTE` |
| 欠采样 | 减少多数类样本 | `imblearn.under_sampling.RandomUnderSampler` |
| 阈值调整 | 降低正类预测阈值 | 手动调整 `predict_proba` 阈值 |
| 集成方法 | EasyEnsemble, BalanceCascade | `imblearn.ensemble` |

**⚠️ 注意：** `class_weight` 和 `sample_weight` 不改变数据分布，只是调整损失函数权重。需要真正改变样本数量时请使用采样方法。

---

## 4. 完整代码示例

```python
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    confusion_matrix, classification_report,
    roc_auc_score, RocCurveDisplay,
    precision_recall_fscore_support
)

# 1. 数据准备
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 2. 构建 Pipeline（包含特征缩放和分类器）
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('clf', LogisticRegression(
        solver='lbfgs',
        class_weight='balanced',  # 处理类别不平衡
        max_iter=1000,
        C=1.0,
        random_state=42
    ))
])

# 3. 训练
pipeline.fit(X_train, y_train)

# 4. 预测
y_pred = pipeline.predict(X_test)
y_proba = pipeline.predict_proba(X_test)[:, 1]

# 5. 评估
print("Confusion Matrix:")
print(confusion_matrix(y_test, y_pred))

print("\nClassification Report:")
print(classification_report(y_test, y_pred))

print(f"\nROC AUC: {roc_auc_score(y_test, y_proba):.4f}")

# 6. 可视化 ROC 曲线
RocCurveDisplay.from_predictions(y_test, y_proba)
```

---

## 5. 参考链接

1. [LogisticRegression 官方文档](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)
2. [分类评估指标指南](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics)
3. [compute_class_weight 文档](https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html)
4. [ROC AUC 解释](https://medium.com/data-science/interpreting-roc-curve-and-roc-auc-for-classification-evaluation-28ec3983f077)

---

*备注：本文档基于 scikit-learn 1.8 版本查证，部分参数可能随版本更新有所变化。*
