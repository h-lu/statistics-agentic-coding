# Week 10 作业评分标准

## 评分总览

| 层级 | 分值范围 | 核心要求 |
|------|---------|---------|
| **基础层** | 0-60 分 | 训练逻辑回归模型，计算评估指标 |
| **进阶层** | 0-30 分 | 处理类别不平衡，绘制 ROC 曲线 |
| **挑战层** | 0-10 分 | Pipeline 防数据泄漏，完整报告 |
| **总计** | 0-100 分 | 满分 100 分（挑战层为加分项） |

---

## 基础层评分（60 分）

### 任务 1：训练逻辑回归模型（30 分）

| 评分项 | 分值 | 评分标准 |
|--------|------|---------|
| 正确划分训练/测试集 | 8 分 | 4 分：使用 train_test_split<br>4 分：test_size 和 random_state 设置正确 |
| 使用逻辑回归模型 | 8 分 | 4 分：导入 LogisticRegression<br>4 分：调用 fit() 和 predict() |
| 计算准确率 | 6 分 | 6 分：准确率计算正确，输出格式清晰 |
| 报告目标变量分布 | 8 分 | 4 分：计算了流失/不流失比例<br>4 分：为后续分析做铺垫（如提及类别不平衡） |

**扣分项**：
- 使用线性回归做分类：-8 分
- 没有划分数据直接在全部数据上训练：-4 分
- 代码无法运行：-10 分

---

### 任务 2：混淆矩阵与评估指标（30 分）

| 评分项 | 分值 | 评分标准 |
|--------|------|---------|
| 混淆矩阵计算正确 | 6 分 | 6 分：调用 confusion_matrix，输出正确 |
| 评估指标计算完整 | 10 分 | 4 分：精确率、召回率、F1 全部计算<br>6 分：数值正确 |
| 正确解读 TP/TN/FP/FN | 8 分 | 4 分：解释了每个术语的含义<br>4 分：解读与混淆矩阵输出一致 |
| 指标选择理由合理 | 6 分 | 3 分：给出了选择某个指标的理由<br>3 分：理由与业务场景匹配（如流失预测优先召回率） |

**扣分项**：
- 混淆精确率和召回率：-4 分
- 只给出数字没有分析：-3 分
- 忽略类别不平衡对准确率的影响：-2 分

---

## 进阶层评分（30 分）

### 任务 3：处理类别不平衡（15 分）

| 评分项 | 分值 | 评分标准 |
|--------|------|---------|
| 训练并评估傻瓜基线 | 5 分 | 5 分：使用 DummyClassifier，计算并对比指标 |
| 尝试至少一种处理方法 | 5 分 | 3 分：调整类别权重或阈值<br>2 分：方法选择合理 |
| 正确解读指标变化 | 5 分 | 3 分：指出哪些指标改善/变差<br>2 分：解释了精确率-召回率的权衡关系 |

**加分项**：
- 尝试两种处理方法并对比：+3 分
- 使用图表展示对比结果：+2 分

---

### 任务 4：ROC 曲线与 AUC（15 分）

| 评分项 | 分值 | 评分标准 |
|--------|------|---------|
| 正确计算 ROC 曲线和 AUC | 5 分 | 5 分：调用 roc_curve 和 roc_auc_score，数值正确 |
| 正确绘制 ROC 曲线 | 5 分 | 2 分：包含模型和基线（对角线）<br>2 分：坐标轴标签正确<br>1 分：图例清晰 |
| 理解 AUC 与准确率的区别 | 5 分 | 3 分：解释了 AUC 的含义（排序能力）<br>2 分：说明了何时 AUC 更有用（类别不平衡/排序场景） |

**扣分项**：
- ROC 曲线缺少坐标轴标签或图例：-2 分
- 只画了模型的曲线，没有对比基线：-1 分

---

## 挑战层评分（10 分 + 加分）

### 任务 5：Pipeline + 交叉验证（10 分）

| 评分项 | 分值 | 评分标准 |
|--------|------|---------|
| 正确使用 Pipeline | 4 分 | 2 分：Pipeline 包含预处理和模型<br>2 分：步骤顺序正确 |
| 交叉验证评估 | 3 分 | 3 分：使用 cross_val_score，scoring='roc_auc' |
| 解释数据泄漏与 Pipeline | 3 分 | 2 分：解释了数据泄漏的概念<br>1 分：说明了 Pipeline 的防御作用 |

---

### 任务 6（加分）：完整分类报告（额外 5-10 分）

| 评分项 | 分值 | 评分标准 |
|--------|------|---------|
| 报告结构完整 | 3 分 | 3 分：包含所有必要部分（指标、混淆矩阵、理由、局限性） |
| 指标选择理由清晰 | 3 分 | 3 分：理由合理，与业务场景匹配 |
| 诚实地列出局限性 | 2 分 | 2 分：指出了模型的具体局限（如召回率低、未考虑非线性） |
| 格式规范 | 2 分 | 2 分：Markdown 格式清晰，易于阅读 |

---

## AI 协作练习（可选，额外 2-5 分）

| 评分项 | 分值 | 评分标准 |
|--------|------|---------|
| 审查清单完成 | 2 分 | 2 分：勾选了 AI 结论中的问题 |
| 修订版质量 | 3 分 | 3 分：修订版准确、完整，修正了识别出的问题 |

---

## 评分维度说明

### 1. 代码正确性（40%）
- 代码可以运行，无语法错误
- 使用正确的 API 和参数
- 输出结果正确

### 2. 概念理解（30%）
- 正确解读混淆矩阵和评估指标
- 理解类别不平衡对准确率的影响
- 理解数据泄漏的概念和防御方法

### 3. 分析与表达（20%）
- 用自己的话解释分析结果
- 指标选择理由合理、清晰
- 报告结构完整、逻辑清晰

### 4. 工程实践（10%）
- 使用 Pipeline 防止数据泄漏
- 代码结构清晰、可读性好
- 提交物完整（代码 + 输出 + 分析）

---

## 常见错误与扣分标准

| 错误类型 | 扣分 | 说明 |
|---------|------|------|
| 用线性回归做分类 | -5 到 -10 分 | 分类问题应该用逻辑回归 |
| 混淆精确率和召回率 | -3 分 | 基本概念混淆 |
| 只看准确率，不考虑类别不平衡 | -2 到 -5 分 | 准确率在类别不平衡时会误导 |
| 交叉验证前做预处理 | -3 分 | 这是数据泄漏 |
| 只给代码没有分析 | -20% | 分析和代码同等重要 |
| 代码无法运行 | -10 分 | 需要确保代码可运行或注明是伪代码 |

---

## 优秀作业示例特征

一份优秀的作业应该：

1. **代码部分**：
   - 代码结构清晰，有适当注释
   - 使用了正确的 API 和参数
   - 输出结果格式化，易于阅读

2. **分析部分**：
   - 用自己的话解释结果（不是复制粘贴）
   - 指标选择理由与业务场景匹配
   - 诚实地指出模型局限性

3. **工程实践**：
   - 使用 Pipeline 防止数据泄漏
   - 用交叉验证评估模型稳定性
   - 代码可复现（设置 random_state）

4. **报告格式**：
   - Markdown 格式清晰
   - 表格和图表标注完整
   - 结论有数据支撑

---

## 反馈建议模板

在给作业反馈时，可以使用以下模板：

```
【优点】
- （具体表扬，如：正确使用了 Pipeline，混淆矩阵解读清晰）

【待改进】
- （具体问题，如：混淆了精确率和召回率，需要再复习一下定义）
- （具体建议，如：建议在报告中加入对类别不平衡的讨论）

【总分】X/100
```

---

## 测试与验证

作业中的关键检查点应该能被 `tests/` 目录中的测试覆盖：

- `test_logistic_regression()`：验证逻辑回归训练
- `test_metrics()`：验证评估指标计算
- `test_pipeline()`：验证 Pipeline 使用
- `test_roc_auc()`：验证 ROC 和 AUC 计算

评分时可以运行这些测试来验证代码正确性。

---

## 最后提醒

评分的目的是帮助学生学习，而不仅仅是打分。在评分时：
1. 指出具体的错误和改进方向
2. 鼓励学生用自己的话解释概念
3. 认可学生的努力和进步

记住 Week 10 的核心目标：**理解准确率陷阱，学会用多维度评估分类模型，识别并防御数据泄漏。**
