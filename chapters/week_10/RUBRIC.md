# Week 10 评分标准（Rubric）

## 评分维度与权重

| 维度 | 权重 | 说明 |
|------|------|------|
| 逻辑回归与系数解释 | 30% | 正确理解分类动机、准确解释优势比 |
| 分类评估指标 | 30% | 混淆矩阵、精确率/召回率/F1、与基线对比 |
| ROC-AUC 与阈值分析 | 20% | 理解 AUC 直觉、掌握阈值权衡 |
| Pipeline 与数据泄漏 | 20% | 正确使用 Pipeline 防止数据泄漏 |

---

## 详细评分标准

### 1. 逻辑回归与系数解释（30 分）

| 评分项 | 分值 | 优秀（A） | 良好（B） | 合格（C） | 不合格（F） |
|--------|------|-----------|-----------|-----------|-------------|
| 识别线性回归问题 | 8 | 准确识别预测值超出[0,1]、误差项假设不成立、Sigmoid 函数作用 | 基本识别问题 | 部分识别 | 未识别或识别错误 |
| 逻辑回归拟合正确 | 5 | API 使用正确、预测概率提取准确、结果验证完整 | 拟合基本正确 | 拟合有瑕疵 | 拟合错误 |
| 优势比计算正确 | 7 | exp(β) 计算准确、95% CI 正确构造 | 计算基本正确 | 计算有瑕疵 | 计算错误 |
| 系数解释准确 | 10 | **使用"优势比"语言**、**加上"在其他变量不变的情况下"**、解释完整 | 解释基本正确 | 解释有瑕疵 | 解释错误或缺失 |

**验证方式**：
- 检查 `linear_vs_logistic.md` 和 `logistic_coefficient_interpretation.md`
- 验证线性回归预测值范围识别
- 检查优势比计算和解释
- 确认是否使用"优势比"语言（而非"概率变化"）

**常见错误**：
- ❌ 说"合同期每增加 1 月，流失概率降低 5.5%"（错误，应该说"优势降低 5.4%"）
- ❌ 忘记"在其他变量不变的情况下"
- ❌ 混淆"对数优势比"与"概率差"
- ❌ 未识别线性回归预测值超出 [0,1] 的问题

---

### 2. 分类评估指标（30 分）

| 评分项 | 分值 | 优秀（A） | 良好（B） | 合格（C） | 不合格（F） |
|--------|------|-----------|-----------|-----------|-------------|
| 混淆矩阵计算正确 | 8 | TN/FP/FN/TP 提取准确、业务含义解释清晰 | 混淆矩阵基本正确 | 混淆矩阵有瑕疵 | 混淆矩阵错误 |
| 四个评估指标正确 | 10 | 准确率、精确率、召回率、F1 全部正确（**每项 2.5 分**） | 指标基本正确 | 部分指标错误 | 多个指标错误 |
| 与基线对比完整 | 7 | 基线拟合正确、对比充分、识别模型价值 | 对比基本完整 | 对比有瑕疵 | 未对比或对比错误 |
| 业务解释合理 | 5 | 假阳性/假阴性成本分析清晰、阈值建议合理 | 业务解释基本合理 | 解释有瑕疵 | 解释缺失或错误 |

**验证方式**：
- 检查 `classification_evaluation_report.md`
- 验证混淆矩阵和四个评估指标
- 检查基线对比的完整性
- 评估业务解释的合理性

**常见错误**：
- ❌ 只报告准确率，完全忽略精确率/召回率/F1（准确率陷阱）
- ❌ 未与基线模型对比（无法判断模型价值）
- ❌ 混淆精确率（TP/(TP+FP)）与召回率（TP/(TP+FN)）
- ❌ 未讨论假阳性/假阴性成本（业务价值缺失）

---

### 3. ROC-AUC 与阈值分析（20 分）

| 评分项 | 分值 | 优秀（A） | 良好（B） | 合格（C） | 不合格（F） |
|--------|------|-----------|-----------|-----------|-------------|
| ROC 曲线正确绘制 | 5 | FPR/TPR 计算正确、图表清晰、AUC 标注完整 | ROC 曲线基本正确 | ROC 曲线有瑕疵 | ROC 曲线错误 |
| AUC 解释准确 | 7 | **使用"随机样本对"解释**、阈值无关性理解深入 | AUC 解释基本正确 | 解释有瑕疵 | 解释错误 |
| 阈值对比完整 | 5 | 至少 3 个阈值对比、权衡分析清晰 | 阈值对比基本完整 | 对比有瑕疵 | 对比缺失 |
| 阈值选择建议合理 | 3 | 基于业务目标的建议充分 | 建议基本合理 | 建议有瑕疵 | 建议缺失或错误 |

**验证方式**：
- 检查 `roc_auc_analysis.md`
- 验证 ROC 曲线和 AUC 计算
- 检查"随机样本对"解释
- 评估阈值选择的业务依据

**常见错误**：
- ❌ 说"AUC = 0.75 是模型 75% 正确"（错误理解）
- ❌ 未解释 AUC 的阈值无关性
- ❌ 只讨论一个阈值（默认 0.5）
- ❌ 阈值选择无业务依据

---

### 4. Pipeline 与数据泄漏（20 分）

| 评分项 | 分值 | 优秀（A） | 良好（B） | 合格（C） | 不合格（F） |
|--------|------|-----------|-----------|-----------|-------------|
| 数据泄漏解释准确 | 6 | 准确识别全局预处理的问题、后果分析清晰 | 解释基本正确 | 解释有瑕疵 | 解释错误 |
| Pipeline 代码正确 | 8 | Pipeline + ColumnTransformer 结构正确、预处理在折内执行 | Pipeline 基本正确 | Pipeline 有瑕疵 | Pipeline 错误 |
| 对比分析合理 | 4 | 错误方法 vs 正确方法对比充分、得分差异解释清晰 | 对比基本合理 | 对比有瑕疵 | 对比缺失 |
| StratifiedKFold 使用 | 2 | 使用 StratifiedKFold 保持类别比例 | 使用普通 KFold | CV 错误 | 未使用 CV |

**验证方式**：
- 检查 `pipeline_data_leakage.md` 和 `stratified_cv_analysis.md`
- 验证 Pipeline + ColumnTransformer 代码
- 检查数据泄漏解释
- 确认是否使用 StratifiedKFold

**常见错误**：
- ❌ 全局 StandardScaler 后再做交叉验证（数据泄漏）
- ❌ 未使用 ColumnTransformer 处理不同类型列
- ❌ 使用普通 KFold 而非 StratifiedKFold
- ❌ 不理解为什么 Pipeline 能防止泄漏

---

## AI 协作练习评分（10 分）

| 评分项 | 分值 | 优秀（A） | 良好（B） | 合格（C） | 不合格（F） |
|--------|------|-----------|-----------|-----------|-------------|
| 审查全面性 | 5 | 识别出所有主要缺失项、分类清晰（高/中/低） | 识别出大部分问题 | 识别出部分问题 | 仅识别少量问题 |
| 修订版结论准确 | 3 | 修订结论统计上正确、解释合理 | 修订结论基本正确 | 修订结论有瑕疵 | 修订结论不准确 |
| 反思深入 | 2 | 深入反思 AI 的优势和局限 | 反思基本合理 | 反思有瑕疵 | 反思缺失 |

**验证方式**：
- 检查 `ai_classification_review.md`
- 验证审查清单的完整性
- 评估修订版结论的准确性

**常见错误**：
- ❌ 未检查 AI 是否混淆优势比与概率
- ❌ 未检查数据泄漏问题（AI 容易遗漏）
- ❌ 未检查基线对比（AI 容易忽略）
- ❌ 直接接受 AI 结论，未进行审查

---

## 加分/扣分项

### 加分项

| 项目 | 加分 | 说明 |
|------|------|------|
| StatLab 集成完整 | +5% | 将分类评估结果正确整合到 StatLab 报告中 |
| 代码质量优秀 | +3% | 代码注释清晰、结构良好、可复现（固定随机种子） |
| 超额完成挑战作业 | +5% | 完成完整分类流水线且质量优秀 |
| 深入反思 AI 协作 | +2% | AI 审查报告包含深入反思 |

### 扣分项

| 项目 | 扣分 | 说明 |
|------|------|------|
| 优势比解释错误 | -10% | 多次将优势比说成"概率变化" |
| 只报告准确率 | -15% | 忽略混淆矩阵和精确率/召回率/F1 |
| 数据泄漏未识别 | -15% | 全局预处理后做交叉验证 |
| 未与基线对比 | -10% | 无法判断模型是否优于"总是预测多数类" |
| 阈值选择无依据 | -5% | 未讨论业务目标对阈值的影响 |

---

## 成绩等级标准

| 等级 | 总分范围 | 对应 GPA | 说明 |
|------|----------|----------|------|
| A | 90-100 | 4.0 | 优秀 |
| B | 80-89 | 3.0-3.7 | 良好 |
| C | 70-79 | 2.0-2.7 | 合格 |
| F | 0-69 | 0.0-1.7 | 不合格 |

---

## 学习目标对照

| 学习目标 | 对应任务 | 评分标准 |
|---------|---------|----------|
| 理解为什么不能用线性回归做分类 | 任务 1 | 识别线性回归问题、Sigmoid 函数作用 |
| 正确解释逻辑回归系数（优势比） | 任务 2 | 优势比计算准确、使用"优势比"语言 |
| 从准确率升级到混淆矩阵 | 任务 3 | 混淆矩阵计算正确、四个评估指标完整 |
| 与基线模型对比 | 任务 3 | 基线对比完整、识别模型价值 |
| 掌握 ROC-AUC 的直觉 | 任务 4 | AUC 解释准确（随机样本对）、阈值无关性 |
| 正确使用 Pipeline 防止数据泄漏 | 任务 5、6 | Pipeline + ColumnTransformer 正确 |
| 在 StatLab 报告中添加分类评估 | 挑战任务 | 分类评估章节完整、包含所有必要元素 |
| 审查 AI 生成的分类报告 | AI 协作 | 识别缺失项、修订版结论准确 |

---

## 提交检查清单

- [ ] 所有必做任务已完成
- [ ] 逻辑回归系数解释使用"优势比"语言
- [ ] 混淆矩阵和四个评估指标（准确率、精确率、召回率、F1）已报告
- [ ] 与基线模型（多数类分类器）已对比
- [ ] ROC-AUC 分析包含阈值对比
- [ ] Pipeline + ColumnTransformer 代码正确
- [ ] 使用 StratifiedKFold 而非普通 KFold
- [ ] StatLab 报告已更新（包含分类评估章节）
- [ ] AI 协作练习包含审查清单和反思
- [ ] 代码文件可复现（固定随机种子）

---

## 评分流程建议

1. **先看基础作业**：
   - 任务 1：检查线性回归 vs 逻辑回归对比
   - 任务 2：检查优势比解释（关键！）
   - 任务 3：检查混淆矩阵和基线对比
   - 任务 4：检查 ROC-AUC 解释

2. **再看进阶作业**（如有）：
   - 任务 5：检查 Pipeline 代码和数据泄漏解释
   - 任务 6：检查 StratifiedKFold 使用

3. **最后看挑战和 AI 练习**（如有）：
   - 任务 7：检查 StatLab 集成完整性
   - 任务 8：检查 AI 审查全面性

4. **扣分/加分项**：
   - 检查常见错误（如优势比解释错误、数据泄漏）
   - 检查加分项（StatLab 集成、代码质量）
