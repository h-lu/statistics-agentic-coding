# Week 10 研究缓存
生成日期：2026-02-17

## 时代脉搏素材
### 搜索词: "AI classification evaluation 2026"
- 2026 年，AI 工具可以一键训练分类器，输出"准确率 95%"
- 类别不平衡时准确率会误导决策
- Andrew Ng 名言："在分类问题中，选择正确的评估指标比选择复杂的模型更重要"

## AI 小专栏 #1: AI 时代的分类评估——为什么准确率不够用
### 搜索词: "imbalanced classification precision recall accuracy machine learning"
- 数据点 1: 在现实应用中，如欺诈检测场景，类别不平衡比例可能达到 1:1000 到 1:5000。这意味着如果模型简单预测"所有交易都正常"，准确率可以达到 99.9% 以上，但完全无法识别真正的欺诈行为。这正是"准确率悖论"(Accuracy Paradox) 的核心问题。(来源: https://machinelearningmastery.com/what-is-imbalanced-classification/)
- 数据点 2: 大多数分类算法的学习过程会偏向多数类样本。当数据集存在严重不平衡时，模型的决策函数会显著向多数类倾斜，导致对少数类的预测能力极差。(来源: https://imbalanced-learn.org/stable/introduction.html)
- 数据点 3: 在不平衡分类问题中，少数类（如欺诈、疾病阳性、客户流失）往往是我们更关心的目标。传统评估指标如准确率无法反映模型对这些关键类别的识别能力，因此需要使用 Precision（精确率）、Recall（召回率）、F1 Score 等指标。(来源: https://machinelearningmastery.com/what-is-imbalanced-classification/)

### 行业实践
- 医疗 AI：癌症筛查、罕见病诊断中，F1 分数和召回率比准确率更重要——漏诊的代价远大于误诊
- 风控系统：欺诈检测中，精确率很重要——误判正常用户为欺诈会导致客户流失
- 推荐系统：点击率预测中，AUC 是标准指标——它衡量"排序能力"，不是单一阈值的准确率

## AI 小专栏 #2: 数据泄漏——AI 模型的隐形杀手
### 搜索词: "data leakage machine learning prevention sklearn pipeline"
- 数据点 1: scikit-learn 官方文档展示了一个经典的数据泄漏案例：如果在划分训练/测试集之前进行特征选择（如 SelectKBest），从 10,000 个随机特征中选 25 个，会得到约 0.76 的虚高准确率；而正确做法是先划分数据再进行特征选择，准确率会降到约 0.5（接近随机猜测的真实水平）。(来源: https://scikit-learn.org/stable/common_pitfalls.html)
- 数据点 2: 防止数据泄漏的黄金法则："永远不要在测试数据上调用 fit()"。scikit-learn 的 Pipeline 机制可以自动确保数据变换只基于训练数据学习参数，然后正确地应用到测试数据。(来源: https://scikit-learn.org/stable/common_pitfalls.html)
- 数据点 3: 数据泄漏有多种形式：最常见的包括 train-test contamination（训练测试集污染）和 target leakage（目标泄漏）。Target leakage 指特征与目标变量存在异常强的相关性，例如一个"患者是否已服药"的特征预测"患者是否患病"，这在模型部署后会导致灾难性后果。(来源: https://scikit-learn.org/stable/common_pitfalls.html)

### 行业最佳实践
- Kaggle 竞赛中，数据泄漏是最常见的争议原因之一
- Google、Microsoft 等公司的 AI 开发指南强调"数据泄漏审计"是模型开发的标准流程
- Pipeline + 交叉验证成为防止数据泄漏的标准工程实践

## 可用参考链接汇总
- https://scikit-learn.org/stable/common_pitfalls.html (scikit-learn 官方：常见陷阱)
- https://machinelearningmastery.com/what-is-imbalanced-classification/ (Machine Learning Mastery: 不平衡分类)
- https://imbalanced-learn.org/stable/introduction.html (imbalanced-learn 官方文档)
- https://scikit-learn.org/stable/auto_examples/model_selection/plot_precision_recall.html (scikit-learn: 精确率-召回率曲线)
