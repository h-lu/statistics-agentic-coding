# Week 14 锚点（知识锚点 + 验证方法）
#
# 每个锚点包含：
#   - id: 本周唯一的锚点标识符
#   - claim: 知识声称（一句话）
#   - evidence: 证据位置（章节引用）
#   - verification: 如何验证（代码/公式/引用）

- id: week_14_frequentist_bayesian_difference
  claim: 频率学派与贝叶斯学派的核心差异在于：频率学派假设参数固定、数据随机；贝叶斯学派假设参数随机、数据给定。
  evidence: "CHAPTER.md 第 1 节：从'p 值游戏'到'信念更新'"
  verification: 频率学派输出 p 值和置信区间，贝叶斯学派输出后验分布和可信区间。

- id: week_14_ci_vs_credible_interval
  claim: 95% 置信区间（CI）不是"参数有 95% 的概率在区间内"，而是"重复抽样 100 次，95 个区间会覆盖真值"的方法可靠性；95% 可信区间（credible interval）才是"参数有 95% 的概率在区间内"。
  evidence: "CHAPTER.md 第 1 节：小北的困惑"
  verification: 置信区间关于方法的可靠性（参数固定，区间随机）；可信区间关于参数的概率（参数随机，区间固定）。

- id: week_14_prior_types
  claim: 先验有三种类型：无信息先验（让数据自己说话）、弱信息先验（编码基本常识，推荐）、强信息先验（基于历史数据）。
  evidence: "CHAPTER.md 第 2 节：先验的三个层次"
  verification: 示例代码展示了 Beta(1,1) 均匀分布、Beta(5,100) 弱信息、Beta(50,1000) 强信息三种先验对后验的影响。

- id: week_14_bayes_theorem_upgrade
  claim: 从 Week 05 的贝叶斯定理 P(A|B) 到贝叶斯推断 P(θ|data)，核心是从离散概率升级到概率分布——从"有没有病"到"效应有多大、多确定"。
  evidence: "CHAPTER.md 第 1 节：从 Week 05 的'贝叶斯定理'到贝叶斯推断"
  verification: Week 05 计算单个概率值（如 P(患病|阳性)），Week 14 计算后验分布（如转化率的 Beta 分布）。

- id: week_14_mcmc_convergence
  claim: MCMC 收敛诊断标准：R-hat < 1.01（优秀）或 < 1.05（可接受）；ESS（有效样本量）> 400；trace plot 应像"毛毛虫"（平稳、混合良好）。
  evidence: "CHAPTER.md 第 4 节：MCMC 收敛诊断"
  verification: 使用 ArviZ 的 az.rhat() 和 az.ess() 计算，用 az.plot_trace() 可视化。

- id: week_14_hierarchical_shrinkage
  claim: 层次模型的 shrinkage 效应：小样本组的估计向全球平均收缩，大样本组的估计保持不变——信息从大样本流向小样本。
  evidence: "CHAPTER.md 第 5 节：层次模型的直觉"
  verification: 示例代码显示德国（样本 200）的后验均值从 0.065 收缩到 0.055，美国（样本 10000）保持 0.058。

- id: week_14_posterior_decision_friendly
  claim: 后验分布是"决策金矿"——能回答任意概率问题：P(θ > 0)、P(θ > 20)、预期损失是多少等。
  evidence: "CHAPTER.md 第 3 节：阿码的追问"
  verification: 从后验采样后，可以用 (samples > 0).mean() 计算 P(θ > 0)，用 samples[samples < 0].mean() 计算预期损失。

- id: week_14_mcmc_skip_normalization
  claim: MCMC 的妙处在于不需要计算归一化常数（边际似然 P(data)），直接采样后验分布 P(θ|data) ∝ P(data|θ) × P(θ)。
  evidence: "CHAPTER.md 第 4 节：为什么需要 MCMC？"
  verification: 高维积分 P(data) = ∫ P(data|θ) × P(θ) dθ 在参数多时不可计算，MCMC 通过马尔可夫链直接采样绕过此问题。

- id: week_14_prior_sensitivity
  claim: 先验敏感性分析是必需的——如果不同先验下结论差异大，说明结论不稳定；如果接近，说明结论稳健（robust）。
  evidence: "CHAPTER.md 第 2 节：先验敏感性分析"
  verification: 示例代码测试无信息、弱信息、强信息三种先验，对比后验均值和 95% CI 是否接近。

- id: week_14_hierarchical_vs_regularization
  claim: 层次模型和 L2 正则化在数学上等价，但解释不同：L2 说"系数不要偏离 0 太远"（防止过拟合），层次模型说"系数来自共同分布"（信息共享）；更重要的是 L2 的 λ 固定，层次模型的 σ² 从数据中学习。
  evidence: "CHAPTER.md 第 5 节：从 Week 11 的'正则化'到层次模型"
  verification: L2 正则化在损失函数中加 λΣβ²，层次模型在先验中设 β ~ N(0, σ²) 并对 σ² 设置超先验。
