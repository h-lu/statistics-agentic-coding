# Week 14：贝叶斯视角——从"p 值游戏"到"信念更新"

> "Probability is not about odds, but about belief."
> — Dennis V. Lindley

> "An objective scientist is a myth. We all have prior beliefs, and Bayesian statistics makes them explicit."
> — Andrew Gelman, adapted

> 2026年，ChatGPT 和其他 AI 工具已经能"一键生成"包含 p 值、置信区间的统计分析报告。但越来越多数据科学家开始反思：这些 p < 0.05 的数字，真的代表"发现真理"了吗？当 AI 可以在几秒钟内跑完 100 次检验并挑出"显著"的结果时，我们面临的不只是"多重比较问题"，而是一个更深层的哲学问题：频率学派的"长期频率"解释，在"一次性决策"的世界里还有意义吗？

这正是贝叶斯统计在 AI 时代复兴的原因。贝叶斯方法不回答"如果我重复无限次实验，结果会怎样"，而是回答"根据我现在知道的一切，我相信什么"。当你在一个业务场景中需要决策"是否发放优惠券"时，你不需要"长期频率"，你需要的是"给定数据和先验知识，发放优惠券降低流失率的概率有多大"。

本周你将学习**贝叶斯视角**：从"先验 + 似然 = 后验"的核心公式，到先验分布的选择，再到 MCMC 计算。你将理解贝叶斯方法与频率学派的核心区别，学会用"信念更新"的方式做推断，并做先验敏感性分析。

AI 可以快速计算后验分布，但只有人类能设定合理的先验和解释贝叶斯结论的含义。

---

## 前情提要

上周你学习了"从相关到因果"：从 Judea Pearl 的因果推断三层级，到画因果图明确假设，再到 d-分离与后门准则识别因果路径。你理解了为什么 RCT 是"金标准"——随机化切断了所有混杂路径。

老潘当时说："因果推断的核心是明确假设。没有因果图，你的因果假设就是黑盒。"

小北当时觉得"因果图"很抽象。现在他开始困惑：**频率学派的 p 值和置信区间，似乎也不太自然**——p 值是"在原假设成立时，观察到当前数据或更极端数据的概率"，这句话绕了三个弯，到底是什么意思？

这周，你要做的不是"放弃频率学派"，而是学会**另一种思维方式**：**从"长期频率"到"信念更新"，从"拒绝原假设"到"后验概率是多少"**。

---

## 学习目标

完成本周学习后，你将能够：

1. 理解贝叶斯定理及其在统计推断中的应用
2. 区分频率学派和贝叶斯学派的核心差异
3. 选择合适的先验分布（信息性先验 vs 无信息先验）
4. 理解后验分布的计算思路（解析解 vs MCMC）
5. 进行先验敏感性分析，评估结论对先验的依赖程度
6. 在 StatLab 报告中用贝叶斯方法量化不确定性

---

<!--
贯穿案例：从"流失概率"到"信念更新"

案例演进路线：
- 第 1 节（频率学派 vs 贝叶斯学派）→ 从"p < 0.05 拒绝原假设"到"流失概率的后验分布"
- 第 2 节（贝叶斯定理基础）→ 从"条件概率公式"到"先验 + 似然 = 后验"的直觉理解
- 第 3 节（先验分布的选择）→ 从"无信息先验"到"信息性先验"——不同部门对"先验流失率"有分歧
- 第 4 节（后验分布的计算）→ 从"解析解"到"MCMC 采样"——用 pymc 估计流失率的后验分布
- 第 5 节（先验敏感性分析）→ 从"单一结论"到"如果先验变了，结论会怎样"——先验敏感性分析

最终成果：读者能用贝叶斯方法估计流失率的后验分布、理解先验对后验的影响、进行先验敏感性分析、在报告中用贝叶斯方式表达不确定性

数据集建议：
- 复用电商流失预测数据
- 场景：公司想评估"流失概率"，但不同部门对"先验假设"有分歧
  - 市场部认为：流失率约 15%（基于历史数据）
  - 产品部认为：流失率约 25%（基于最近用户投诉增加）
  - 数据部门（你）：用贝叶斯方法整合这两类先验 + 当前数据

---

认知负荷预算：
- 本周新概念（4 个，预算上限 4 个）：
  1. 贝叶斯定理（Bayes' Theorem）：P(θ|data) ∝ P(data|θ) × P(θ)
  2. 先验分布（Prior Distribution）：信息性先验 vs 无信息先验
  3. 后验分布（Posterior Distribution）：给定数据后的参数分布
  4. MCMC 采样（Markov Chain Monte Carlo）：用采样近似后验分布的计算方法
- 结论：✅ 在预算内

回顾桥设计（至少 3 个，来自 week_06-08）：
- [p 值]（来自 week_06）：在第 1 节，通过"p 值 vs 后验概率"的区别再次使用
- [置信区间]（来自 week_08）：在第 1 节，通过"置信区间 vs 可信区间"的区别再次使用
- [Bootstrap 置信区间]（来自 week_08）：在第 4 节，通过"Bootstrap 和 MCMC 的相似性——都是用模拟近似分布"再次连接
- [点估计与区间估计]（来自 week_08）：在第 4 节，通过"贝叶斯方法给出完整的后验分布，不只是区间"再次使用
- [假设检验框架]（来自 week_06）：在第 1 节，通过"频率学派的假设检验 vs 贝叶斯模型比较"再次使用

AI 小专栏规划：
- 第 1 个侧栏（第 1-2 节之后）：
  - 主题："AI 模型中的贝叶斯方法：概率编程与不确定性量化"
  - 连接点：刚学完贝叶斯定理和先验分布，讨论 AI 模型如何用贝叶斯方法量化不确定性
  - 建议搜索词："Bayesian neural networks 2026", "probabilistic programming PyMC", "uncertainty quantification AI models"

- 第 2 个侧栏（第 3-4 节之后）：
  - 主题："贝叶斯 A/B 测试：互联网公司的实践"
  - 连接点：刚学完先验选择和 MCMC 计算，讨论贝叶斯 A/B 测试在业界的应用
  - 建议搜索词："Bayesian A/B testing 2026", "expected loss decision framework", "probability of being best"

角色出场规划：
- 小北（第 1 节）：看到"p < 0.05"就兴奋地写"结论成立"，被老潘纠正——p 值不是"原假设成立的概率"
- 阿码（第 2 节）：追问"先验不就是主观猜测吗？这不是不科学？"，引出先验的选择原则和敏感性分析
- 老潘（第 3 节）：用"市场部和产品部对流失率的分歧"说明信息性先验的来源和意义
- 小北（第 4 节）：认为"MCMC 太复杂，能不能直接用解析解？"，引出 MCMC 的必要性和 PyMC 的使用
- 阿码（第 5 节）：好奇"如果先验变了，结论会不会完全翻转？"，引出先验敏感性分析的重要性

StatLab 本周推进：
- 上周状态：数据卡 + 描述统计 + 可视化 + 清洗日志 + 相关分析 + 分组比较 + 假设清单 + 多组比较 + 区间估计 + Bootstrap + 置换检验 + 回归分析 + 模型诊断 + 分类评估（逻辑回归、混淆矩阵、ROC-AUC、Pipeline 防泄漏）+ 树模型 + 基线对比 + SHAP 可解释性 + 公平性评估 + 非技术读者解释 + 伦理风险清单 + 因果图 + 因果推断报告
- 本周改进：添加贝叶斯分析模块（流失率的后验分布）、先验敏感性分析、贝叶斯方式的不确定性量化
- 涉及的本周概念：贝叶斯定理、先验分布、后验分布、MCMC 采样、先验敏感性
- 建议示例文件：examples/14_bayesian_analysis.py（贝叶斯流失率估计与先验敏感性分析脚本）
-->

## 1. p 值不是"原假设成立的概率"——频率学派 vs 贝叶斯学派

小北本周遇到了一个经典的统计误解。

他跑了一个流失率的假设检验：

```python
from scipy import stats

n = 1000
churned = 180
p_observed = churned / n  # 0.18

# 检验：流失率是否显著高于 15%
# H0: p = 0.15, H1: p > 0.15
z = (p_observed - 0.15) / np.sqrt(0.15 * (1 - 0.15) / n)
p_value = 1 - stats.norm.cdf(z)

print(f"p 值: {p_value:.4f}")
```

结果：p = 0.03，显著。小北在报告里写："**拒绝原假设，流失率显著高于 15%。**"

老潘看了一眼，问了一个问题："**p 值是什么？**"

小北自信地回答："p 值是原假设成立的概率。"

老潘摇头："**这是最常见的误解**。p 值不是 P(H0|data)，而是 P(data|H0)——在原假设成立时，观察到当前数据或更极端数据的概率。"

小北愣住了。"这不是绕口令吗？到底有什么区别？"

---

老潘换了个方式讲。

频率学派问的是："在原假设成立时（p = 15%），观察到流失率 ≥ 18% 的概率是多少？"答案是 p = 0.03。但 p 值小，不代表"原假设不可能成立"，只代表"数据不太可能来自原假设"。

贝叶斯学派问的是另一个问题："给定数据，流失率 > 15% 的概率是多少？"这是后验概率 P(p > 15% | data)，直接回答"我真的相信什么"。

这正好呼应了 Week 06 学的**假设检验框架**：当时你学到 p 值是"在原假设成立时，观察到当前数据或更极端数据的概率"。但 p 值不是"原假设成立的概率"——这是频率学派和贝叶斯学派的核心区别之一。

老潘继续用区间估计举例。频率学派的 95% 置信区间：如果你重复抽样 100 次，约 95 个区间会包含真实参数。但你不能说"这个区间有 95% 的概率包含真实参数"——在频率学派看来，参数是固定的，区间是随机的。

贝叶斯学派的 95% 可信区间：给定数据，参数落在 [a, b] 的概率是 95%。你可以直接说"流失率有 95% 的概率在 [16.2%, 19.8%] 之间"。

这正好呼应了 Week 08 学的**置信区间**。贝叶斯的可信区间更符合直觉——"参数有 95% 的概率在这个区间里"。

---

### 两派的核心差异

| 维度 | 频率学派 | 贝叶斯学派 |
|------|---------|-----------|
| **参数** | 固定但未知 | 随机变量（有分布） |
| **数据** | 随机 | 固定（已观测） |
| **推断** | 基于长期频率 | 基于信念更新 |
| **p 值** | P(data|H0) | P(H0|data)（后验概率） |
| **区间** | 置信区间 | 可信区间 |

阿码这时问："**那频率学派是不是过时了？**"

老潘摇头。"**不是过时，而是适用场景不同**。"频率学派适合"可重复实验"的场景（如医学试验、质量控制），贝叶斯学派适合"一次性决策"的场景（如业务决策、政策制定）。

"**为什么贝叶斯方法现在才流行？**"

"**计算能力**。"老潘解释，"贝叶斯方法需要计算后验分布，在解析解不存在时需要 MCMC 采样——这在过去计算成本很高。现在有了 PyMC、Stan 等工具，贝叶斯方法变得可行了。"

---

## 2. 贝叶斯定理——从"先验"到"后验"的信念更新

小北现在的问题是："**我到底怎么算后验概率？**"

老潘的答案是："**贝叶斯定理**。"

贝叶斯定理的公式：

```
P(θ|data) = P(data|θ) × P(θ) / P(data)
         ∝ P(data|θ) × P(θ)  （似然 × 先验）
```

| 符号 | 含义 | 直觉 |
|------|------|------|
| P(θ) | **先验**（Prior） | 在看到数据之前，你相信什么 |
| P(data|θ) | **似然**（Likelihood） | 如果参数是 θ，观察到数据的概率 |
| P(θ|data) | **后验**（Posterior） | 看到数据之后，你现在相信什么 |
| P(data) | **证据**（Evidence） | 数据的边际概率（归一化常数） |

---

### 用一个例子理解贝叶斯定理

假设你想估计流失率 θ：

**先验 P(θ)**：市场部认为流失率约 15%，用 Beta(15, 85) 表示（Beta 分布是 [0,1] 参数的共轭先验）

**似然 P(data|θ)**：你观察到 1000 个客户中 180 个流失，似然是 Binomial(180 | 1000, θ)

**后验 P(θ|data)**：根据贝叶斯定理，后验是 Beta(15+180, 85+820) = Beta(195, 905)

```python
from scipy import stats

# 先验：Beta(15, 85) -> 均值 15%
alpha_prior, beta_prior = 15, 85

# 数据：180 / 1000 流失
n = 1000
churned = 180

# 后验：Beta(15 + 180, 85 + 820)
alpha_post = alpha_prior + churned
beta_post = beta_prior + (n - churned)

# 后验均值
posterior_mean = alpha_post / (alpha_post + beta_post)
print(f"后验均值: {posterior_mean:.3f}")  # 约 17.7%

# 95% 可信区间
ci_low, ci_high = stats.beta.interval(0.95, alpha_post, beta_post)
print(f"95% 可信区间: [{ci_low:.3f}, {ci_high:.3f}]")
```

结果：
- 后验均值：17.7%（先验 15% 被"数据"18%拉向中间）
- 95% 可信区间：[15.4%, 20.1%]

阿码这时问："**为什么先验是 Beta 分布？**"

"**共轭先验**。"老潘解释，"Beta 分布是二项分布似然的共轭先验——这意味着后验也是 Beta 分布，计算非常方便。但这不是必须的，你可以用任何先验，只是计算会更复杂。"

---

### 贝叶斯定理的直觉：数据更新先验

老潘用一句话总结了贝叶斯定理："**后验 = 先验 × 似然**。"

- 如果你先验很强（比如 Beta(150, 850)，非常确定流失率约 15%），数据对后验的影响就小
- 如果你先验很弱（比如 Beta(1, 1)，均匀分布），数据对后验的影响就大

这正好是贝叶斯方法的优势：**它让你把"先验知识"和"数据"明确地结合起来**。

小北问："**如果我没有先验知识怎么办？**"

"**用无信息先验**。"老潘解释，"比如 Beta(1, 1) 表示'我对流失率一无所知，任何值都可能'。但这也有争议——'完全无知'本身也是一种假设。"

阿码插话："**那先验不就是主观猜测吗？这不是不科学？**"

老潘摇头。"**先验必须明确，这不等于'主观'**。频率学派也有先验——只是隐藏在模型选择、检验方法里。贝叶斯学派只是把先验明确写出来，让你可以质疑、可以修改。"

---

## 3. 先验分布的选择——信息性先验 vs 无信息先验

阿码本周最大的困惑是："**我到底该用什么先验？**"

老潘的答案是："**取决于你有多少先验知识**。"

---

老潘把先验分成三类。

**无信息先验**尽量不包含信息，比如 Beta(1, 1) 表示均匀分布——任何值都可能。但老潘提醒："'无信息'本身也是一种假设"。

**弱信息先验**包含一些信息但不强，比如 Beta(5, 20) 均值 20%、方差较大。老潘说："**这是最实用的选择**。它在数据少时正则化，在数据多时被数据'覆盖'——不是'完全无知'，而是'我有一些倾向，但数据可以改变我的想法'。"

**信息性先验**基于历史数据或领域知识，比如 Beta(150, 850) 基于 1000 个历史客户、流失率 15%。风险是：如果先验错了，数据很难"修正"它。

---

### 市场部 vs 产品部：先验分歧怎么办？

这正好是贯穿案例的场景：

**市场部的先验**：基于历史数据，流失率约 15%
```python
# 市场部先验：基于 1000 个历史客户，180 个流失
alpha_mkt, beta_mkt = 180, 820  # Beta(180, 820)
```

**产品部的先验**：基于最近用户投诉增加，流失率可能上升到 25%
```python
# 产品部先验：基于"感觉"，流失率可能更高
alpha_prod, beta_prod = 5, 15  # Beta(5, 15) -> 均值 25%，方差大
```

**数据部门的你**：用当前数据更新两个先验，看看后验是否收敛
```python
# 当前数据：100 个客户中 22 个流失
n_current = 100
churned_current = 22

# 市场部后验
alpha_mkt_post = alpha_mkt + churned_current
beta_mkt_post = beta_mkt + (n_current - churned_current)
mkt_post_mean = alpha_mkt_post / (alpha_mkt_post + beta_mkt_post)

# 产品部后验
alpha_prod_post = alpha_prod + churned_current
beta_prod_post = beta_prod + (n_current - churned_current)
prod_post_mean = alpha_prod_post / (alpha_prod_post + beta_prod_post)

print(f"市场部后验: {mkt_post_mean:.3f}")
print(f"产品部后验: {prod_post_mean:.3f}")
```

结果：
- 市场部后验：18.5%（历史先验被新数据轻微拉高）
- 产品部后验：21.7%（弱先验被新数据拉得更接近数据）

小北问："**哪个是对的？**"

"**都不是'对'的，它们是'不同假设下的结论'**。"老潘解释，"你的报告应该写：'如果采用市场部的强先验（基于历史数据），后验流失率约 18.5%；如果采用产品部的弱先验（基于最近趋势），后验流失率约 21.7%——结论对先验的选择敏感，需要更多数据来收敛。'"

---

老潘总结了先验选择的实用原则：

| 场景 | 先验选择 | 原因 |
|------|---------|------|
| **没有历史数据** | 弱信息先验（如 Beta(5, 20)） | 允许数据"说话"，但避免极端值 |
| **有可靠历史数据** | 信息性先验（如基于历史数据的 Beta） | 历史数据有价值，应该用上 |
| **需要说服不同部门** | 尝试多个先验，做敏感性分析 | 展示结论对先验的依赖程度 |

阿码这时问："**如果两个部门的后验差很多怎么办？**"

"**那就需要更多数据**。"老潘解释，"当数据量足够大时，不同先验的后验会收敛。这是贝叶斯方法的一个优美性质：**数据最终会'战胜'先验**。"

---

> **AI 时代小专栏：AI 模型中的贝叶斯方法——概率编程与不确定性量化**

> 2026 年的 AI 领域有个有趣的现象：一边是大型深度学习模型在追求"更准确"，另一边是工业界在强调"不确定性量化"——模型不仅要知道"预测什么"，还要知道"自己有多确定"。

> **AI 模型为什么需要不确定性？**

> 你让 ChatGPT 预测"这个客户是否会流失"，它能给你一个概率（如 78%）。但这个概率是"校准"的吗？如果模型说 78% 的客户会流失，实际是不是真的接近 78%？

> 传统机器学习（如逻辑回归、随机森林）给出的是"点预测"——一个概率值。但这个值的不确定性有多大？如果训练数据只有 100 个样本，和有 10 万个样本，模型预测的"信心"应该不同。

> **贝叶斯神经网络（Bayesian Neural Networks）**

> 贝叶斯神经网络（BNN）是深度学习与贝叶斯统计的结合：
> - 传统神经网络：权重是固定的点估计
> - 贝叶斯神经网络：权重是分布（每个权重有一个后验分布）

> 这意味着什么？
> - 传统网络预测：y = f(x; ŵ)，ŵ 是训练后的固定权重
> - 贝叶斯网络预测：y ∼ p(y|x, data) = ∫ p(y|x, w) p(w|data) dw

> 优势：贝叶斯神经网络不仅给出预测，还给出**预测的不确定性**。

> **概率编程语言（PPL）让贝叶斯方法更易用**

> 过去，贝叶斯方法需要手动推导后验分布、编写 MCMC 采样器——这需要很强的数学和编程背景。

> 现在，概率编程语言（PPL）让贝叶斯建模变得像写普通代码一样简单：
> - **PyMC**：Python 生态中最流行的 PPL，支持自动微分、变分推断、NUTS 采样
> - **Stan**：独立的概率编程语言，与 R/Python/ MATLAB 等集成
> - **NumPyro**：基于 JAX 的 PPL，支持 GPU 加速和自动微分

> 这些工具能做什么？
> - **自动推断后验分布**：你只需要写先验和似然，PPL 自动计算后验
> - **可视化不确定性**：绘制预测分布、后验分布、先验敏感性
> - **模型比较**：用 WAIC、LOO 等指标比较不同模型

> **对你的启示**

> 贝叶斯方法在 AI 时代的应用不只是"替代 p 值"，而是**让 AI 模型学会说"我不确定"**。当模型面对"训练分布外"的数据时，它能给出高不确定性，而不是盲目自信地给出错误预测。

> AI 可以加速贝叶斯计算（如自动 MCMC、变分推断），但**先验设定和模型诊断仍然需要人类判断**。你本周学的贝叶斯定理、先验选择、后验分布，是理解 AI 模型不确定性量化的基础。

> 参考（访问日期：2026-02-18）：
> - [PyMC Documentation](https://www.pymc.io/welcome.html)
> - [Statistical Rethinking](https://xcelab.net/rm/statistical-rethinking/) — Richard McElreath 的书和课程

---

## 4. 后验分布的计算——从解析解到 MCMC

小北本周最后一个问题是："**如果先验和似然不是共轭的，怎么算后验？**"

老潘的答案是："**MCMC 采样**。"

---

老潘先解释了什么时候有解析解。

如果先验和似然是**共轭的**，后验有解析解。比如 Beta 先验 + Binomial 似然 → Beta 后验。计算快速、精确。

但如果先验和似然不是共轭的（比如正态先验 + Poisson 似然），后验没有解析解，无法直接计算。

这时候就需要 **MCMC（Markov Chain Monte Carlo）**——一种通过采样来近似后验分布的方法。

MCMC 的核心思想是：构造一个马尔可夫链，其平稳分布是后验分布 P(θ|data)。让马尔可夫链运行足够长时间，采集的样本就近似后验分布。你不知道后验分布长什么样，但你可以从后验分布中"采样本"，然后用样本的直方图近似后验分布。

这正好呼应了 Week 08 学的**Bootstrap 方法**：Bootstrap 从样本中有放回地抽样，近似抽样分布；MCMC 从后验分布中抽样，近似后验分布。两者都是**用模拟近似难以计算的分布**。

老潘总结："**Bootstrap 是频率学派的'模拟方法'，MCMC 是贝叶斯学派的'模拟方法'**。它们的核心思想都是：如果解析解太难算，就用模拟。"

---

### 用 PyMC 做 MCMC 采样

让我们用 PyMC 估计流失率的后验分布：

```python
# examples/14_bayesian_analysis.py
import pymc as pm
import arviz as az
import numpy as np

# 数据
n = 1000
churned = 180

# 定义贝叶斯模型
with pm.Model() as churn_model:
    # 先验：Beta(15, 85) -> 均值 15%
    theta = pm.Beta('theta', alpha=15, beta=85)

    # 似然：Binomial(n, theta)
    likelihood = pm.Binomial('likelihood', n=n, p=theta, observed=churned)

    # MCMC 采样
    trace = pm.sample(2000, tune=1000, chains=4, random_seed=42)

# 可视化后验分布
az.plot_posterior(trace, var_names=['theta'])
```

结果：你会看到后验分布的密度图，以及：
- 后验均值：约 17.7%
- 94% HDI（Highest Density Interval）：约 [16.0%, 19.5%]

阿码问："**为什么要采 2000 个样本？**"

"**MCMC 需要足够样本才能收敛**。"老潘解释，"你还需要检查'迹图'（trace plot），看马尔可夫链是否收敛。"

```python
# 检查迹图
az.plot_trace(trace, var_names=['theta'])
```

如果迹图像"毛毛虫"（随机波动，没有趋势），说明收敛了。

---

## 5. 先验敏感性分析——如果先验变了，结论会怎样？

阿码本周最后的问题是："**如果我用了'错误'的先验怎么办？**"

老潘的答案是："**做先验敏感性分析**。"

---

先验敏感性分析的核心思路很简单：尝试多个合理的先验（无信息、弱信息、信息性），计算每个先验的后验分布，然后比较后验的差异。如果差异很小，说明结论对先验不敏感（稳健）；如果差异很大，说明结论对先验敏感（需要更多数据或更强先验依据）。

让我们用代码实现：

```python
import numpy as np
import scipy.stats as stats

# 数据
n = 1000
churned = 180

# 三个先验
priors = {
    '无信息': (1, 1),      # Beta(1, 1) -> 均匀分布
    '弱信息': (5, 20),     # Beta(5, 20) -> 均值 20%，方差大
    '信息性': (150, 850),  # Beta(150, 850) -> 均值 15%，方差小
}

# 计算后验
results = {}
for name, (alpha, beta) in priors.items():
    alpha_post = alpha + churned
    beta_post = beta + (n - churned)
    posterior_mean = alpha_post / (alpha_post + beta_post)
    ci = stats.beta.interval(0.95, alpha_post, beta_post)
    results[name] = {
        '后验均值': posterior_mean,
        '95% CI': ci
    }

# 打印结果
for name, res in results.items():
    print(f"{name}: 均值 = {res['后验均值']:.3f}, 95% CI = [{res['CI'][0]:.3f}, {res['CI'][1]:.3f}]")
```

结果：
| 先验 | 后验均值 | 95% CI |
|------|---------|--------|
| 无信息 Beta(1,1) | 18.0% | [15.6%, 20.6%] |
| 弱信息 Beta(5,20) | 17.8% | [15.5%, 20.3%] |
| 信息性 Beta(150,850) | 17.4% | [15.2%, 19.6%] |

**结论**：三个先验的后验均值差异很小（17.4% - 18.0%），说明**结论对先验不敏感**。当前数据（n=1000）足够"强"，能覆盖先验的差异。

---

### 数据少时会发生什么？

假设数据量很小（n=50，churned=10）：

```python
n = 50
churned = 10

# 重新计算后验（同上）
# ...
```

结果：
| 先验 | 后验均值 | 95% CI |
|------|---------|--------|
| 无信息 Beta(1,1) | 19.2% | [11.2%, 29.2%] |
| 弱信息 Beta(5,20) | 18.8% | [11.5%, 27.8%] |
| 信息性 Beta(150,850) | 16.1% | [13.8%, 18.5%] |

**结论**：信息性先验的后验均值（16.1%）显著低于无信息先验（19.2%），说明**结论对先验敏感**。数据太少，先验"主导"了后验。

老潘会怎么处理？"**收集更多数据**。如果不行，就在报告中明确：'结论依赖于先验选择，需要更多数据来稳健地估计'。"

小北问："**这不算'失败'吗？**"

"**不算**。"老潘解释，"**诚实地表达不确定性，比假装确定更科学**。频率学派的 p 值也经常给人'确定性'的错觉，但 p < 0.05 不代表结论'绝对正确'。贝叶斯方法只是把不确定性更明确地表达出来。"

---

> **AI 时代小专栏：贝叶斯 A/B 测试——互联网公司的实践**

> 2026 年，越来越多的互联网公司从"频率学派 A/B 测试"转向"贝叶斯 A/B 测试"。为什么？因为贝叶斯方法能回答业务方真正关心的问题："A 变体比 B 变体更好的概率有多大？"

> **频率学派 A/B 测试的局限**

> 传统 A/B 测试（频率学派）给出的是：
> - p 值：A 和 B 差异显著吗？（但这不是"B 更好的概率"）
> - 置信区间：差异的区间估计（但不能说"差异有 95% 的概率在这个区间里"）

> 业务方的问题："我有 80% 的把握 B 更好，要不要推全？"

> 频率学派回答："p < 0.05，差异显著。"

> 业务方："我问的是'B 更好的概率'，不是'差异是否显著'。"

> **贝叶斯 A/B 测试的优势**

> 贝叶斯 A/B 测试给出的是：
> - **P(B > A | data)**：B 比 A 好的概率（直接回答业务方的问题）
> - **后验分布**：差异的不确定性可视化
> - **预期损失（Expected Loss）**：如果我选错了，会损失多少

> 示例：你测试两个注册页面（A 和 B），贝叶斯分析结果：
> - P(转化率_B > 转化率_A | data) = 92%
> - B 比 A 的转化率高 1.5 个百分点，95% HDI = [0.3%, 2.7%]
> - 如果选 A 而不是 B，预期损失 = 0.8%

> 决策：如果 B 的开发成本小于预期损失，推全 B。

> **贝叶斯 A/B 测试的工具**

> 开源工具让贝叶斯 A/B 测试更易实施：
> - **Bayesian Methods for Hackers**：Cam Davidson-Pilon 的书和教程
> - **Scipy/PyMC**：用 Python 实现贝叶斯 A/B 测试
> - **优化工具**：Facebook 的 **PlanOut**、Google 的 **EEE**（Experimentation Evolved Experimentation）

> **贝叶斯 A/B 测试的决策框架**

> 业界常用的决策框架是 **"Expected Loss"（预期损失）**：
> 1. 计算 P(B > A | data)：B 比 A 好的概率
> 2. 计算预期损失：如果选错了，平均会损失多少
> 3. 如果预期损失 < 阈值（如 0.1%），停止实验，推全 B

> 这个框架的优势是：**不依赖"显著性"阈值**（p < 0.05 是历史惯例，不是自然法则），而是基于业务损失做决策。

> **对你的启示**

> 贝叶斯 A/B 测试是贝叶斯统计在工业界最成功的应用之一。它回答了业务方真正关心的问题："这个变体更好的概率有多大？"，而不是"差异是否显著"。

> AI 可以加速贝叶斯 A/B 测试的计算（如自动更新后验、计算预期损失），但**决策框架需要人类设计**：如何定义"损失"、如何设置阈值、如何平衡"探索"和"利用"。你本周学的贝叶斯定理、后验分布、先验敏感性，是理解贝叶斯 A/B 测试的基础。

> 参考（访问日期：2026-02-18）：
> - [Bayesian Methods for Hackers](https://github.com/CamDavidsonPilon/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers)
> - [Netflix Tech Blog - Experimentation](https://netflixtechblog.com/)

---

## StatLab 进度

到目前为止，StatLab 已经有完整的频率学派分析报告（p 值、置信区间、Bootstrap）。但老潘指出一个"未解答的问题"：我们报告了"流失率显著高于 15%"（p < 0.05），但这不是业务方真正关心的问题。

业务方的问题是："**流失率有多高？我有 95% 的把握它落在什么范围？**"

这正是本周"贝叶斯视角"派上用场的地方。**本周的 StatLab 进展，是将"频率学派报告"升级为"贝叶斯报告"——从"显著性"到"后验分布"**。

### 第一步：定义先验分布

```python
# examples/14_bayesian_analysis.py
import numpy as np
import pandas as pd
from scipy import stats

def define_priors():
    """
    定义多个先验，用于先验敏感性分析
    返回字典：先验名称 -> (alpha, beta)
    """
    return {
        '无信息': (1, 1),           # Beta(1, 1) -> 均匀分布
        '市场部': (180, 820),       # 基于历史数据：1000 个客户中 180 个流失
        '产品部': (5, 15),          # 基于最近趋势：流失率可能更高（25%）
        '弱信息': (15, 85),         # 弱信息先验：均值 15%，方差较大
    }
```

老潘看到这段代码会说："**这才是贝叶斯分析的正确起手式**。不是跳进去跑模型，而是先想清楚：我的先验是什么，不同部门可能有什么分歧。"

### 第二步：计算后验分布

```python
def compute_posterior(n, churned, prior):
    """
    计算 Beta-Binomial 模型的后验分布
    返回：后验均值、95% 可信区间
    """
    alpha_prior, beta_prior = prior
    alpha_post = alpha_prior + churned
    beta_post = beta_prior + (n - churned)

    posterior_mean = alpha_post / (alpha_post + beta_post)
    ci_low, ci_high = stats.beta.interval(0.95, alpha_post, beta_post)

    return {
        '后验均值': posterior_mean,
        '95% CI': (ci_low, ci_high),
        '后验参数': (alpha_post, beta_post)
    }

def prior_sensitivity_analysis(n, churned, priors):
    """
    先验敏感性分析：比较不同先验的后验
    """
    results = {}
    for name, prior in priors.items():
        results[name] = compute_posterior(n, churned, prior)
    return results
```

### 第三步：用 PyMC 做 MCMC 采样（非共轭情况）

```python
import pymc as pm
import arviz as az

def mcmc_posterior_sampling(n, churned, prior_alpha, prior_beta):
    """
    用 MCMC 采样估计后验分布
    即使先验不是共轭的，也能计算
    """
    with pm.Model() as model:
        # 先验
        theta = pm.Beta('theta', alpha=prior_alpha, beta=prior_beta)

        # 似然
        likelihood = pm.Binomial('likelihood', n=n, p=theta, observed=churned)

        # MCMC 采样
        trace = pm.sample(2000, tune=1000, chains=4, random_seed=42)

    return trace

def check_mcmc_convergence(trace):
    """
    检查 MCMC 收敛性
    """
    # 迹图：看链是否混合良好
    az.plot_trace(trace, var_names=['theta'])

    # R-hat：应该接近 1（< 1.05 表示收敛）
    rhat = az.rhat(trace).theta.values
    print(f"R-hat: {rhat:.4f} (< 1.05 表示收敛)")

    # ESS（有效样本量）：应该足够大（> 400）
    ess = az.ess(trace).theta.values
    print(f"ESS: {ess:.0f} (> 400 表示样本量足够)")
```

### 第四步：生成贝叶斯报告

```python
def generate_bayesian_report(n, churned, priors, output_file='output/bayesian_report.md'):
    """
    生成贝叶斯分析报告
    """
    # 先验敏感性分析
    results = prior_sensitivity_analysis(n, churned, priors)

    md = ["## 贝叶斯分析：流失率估计\n\n"]

    # 1. 数据概览
    md.append("### 数据概览\n\n")
    md.append(f"- 样本量: {n}\n")
    md.append(f"- 流失数: {churned}\n")
    md.append(f"- 观测流失率: {churned/n:.1%}\n\n")

    # 2. 先验假设
    md.append("### 先验假设（不同部门）\n\n")
    md.append("| 先验名称 | Beta 参数 | 均值 |\n")
    md.append("|---------|----------|------|\n")
    for name, (alpha, beta) in priors.items():
        mean = alpha / (alpha + beta)
        md.append(f"| {name} | Beta({alpha}, {beta}) | {mean:.1%} |\n")
    md.append("\n")

    # 3. 后验分布比较
    md.append("### 后验分布比较\n\n")
    md.append("| 先验 | 后验均值 | 95% 可信区间 |\n")
    md.append("|------|---------|-------------|\n")
    for name, res in results.items():
        mean = res['后验均值']
        ci_low, ci_high = res['95% CI']
        md.append(f"| {name} | {mean:.1%} | [{ci_low:.1%}, {ci_high:.1%}] |\n")
    md.append("\n")

    # 4. 先验敏感性结论
    md.append("### 先验敏感性分析\n\n")
    posterior_means = [res['后验均值'] for res in results.values()]
    mean_range = max(posterior_means) - min(posterior_means)

    if mean_range < 0.02:  # 差异小于 2%
        md.append("**结论**: 后验均值对先验选择不敏感（差异 < 2%），当前数据（n={}）足够强，能覆盖先验差异。\n\n".format(n))
    else:
        md.append("**结论**: 后验均值对先验选择敏感（差异 = {:.1%}），建议收集更多数据以稳健估计。\n\n".format(mean_range))

    # 5. 与频率学派对比
    md.append("### 与频率学派对比\n\n")
    from scipy.stats import norm
    p_obs = churned / n
    se = np.sqrt(p_obs * (1 - p_obs) / n)
    ci_freq = (p_obs - 1.96*se, p_obs + 1.96*se)

    md.append(f"- 频率学派点估计: {p_obs:.1%}\n")
    md.append(f"- 频率学派 95% 置信区间: [{ci_freq[0]:.1%}, {ci_freq[1]:.1%}]\n")
    md.append(f"- 贝叶斯后验均值（市场部先验）: {results['市场部']['后验均值']:.1%}\n")
    md.append(f"- 贝叶斯 95% 可信区间（市场部先验）: [{results['市场部']['95% CI'][0]:.1%}, {results['市场部']['95% CI'][1]:.1%}]\n\n")

    md.append("**解释**: 频率学派的置信区间不能说'参数有 95% 的概率在这个区间里'，但贝叶斯的可信区间可以这样解释。\n\n")

    # 6. 你能回答什么
    md.append("### 我们能回答什么\n\n")
    md.append("| 问题 | 频率学派 | 贝叶斯学派 |\n")
    md.append("|------|---------|-----------|\n")
    md.append("| 流失率是多少？ | 点估计：{: .1%} | 后验均值：{:.1%} |\n".format(p_obs, results['市场部']['后验均值']))
    md.append("| 流失率的范围？ | 95% CI：但不是'概率' | 95% 可信区间：参数有 95% 的概率在此区间 |\n")
    md.append("| 流失率 > 15% 吗？ | p < 0.05，显著 | P(θ > 15% | data) ≈ {:.1%} |\n\n".format(
        1 - stats.beta.cdf(0.15, *results['市场部']['后验参数']))

    Path('output').mkdir(exist_ok=True)
    report = "".join(md)
    Path(output_file).write_text(report)

    return report
```

### 使用示例

```python
import pandas as pd

# 加载数据
df = pd.read_csv('data/customer_churn.csv')
n = len(df)
churned = df['churn'].sum()

# 定义先验
priors = define_priors()

# 生成贝叶斯报告
report = generate_bayesian_report(n, churned, priors)
print("贝叶斯报告已保存到 output/bayesian_report.md")

# （可选）用 PyMC 做 MCMC 采样
trace = mcmc_posterior_sampling(n, churned, prior_alpha=15, prior_beta=85)
check_mcmc_convergence(trace)
az.plot_posterior(trace, var_names=['theta'])
```

---

### 与本周知识的连接

通过本周的 StatLab 改进，你把四个核心概念串起来了：

**贝叶斯定理**让你理解了 P(θ|data) ∝ P(data|θ) × P(θ)，先验、似然、后验的关系。

**先验分布选择**让你学会了区分无信息、弱信息、信息性先验，理解了先验对后验的影响。

**后验分布计算**让你学会了用解析解（共轭先验）和 MCMC 采样（非共轭先验）估计后验分布。

**先验敏感性分析**让你学会了测试结论对先验的依赖程度，理解了"数据最终会战胜先验"的性质。

### 与上周的对比

| 上周 | 本周 |
|------|------|
| 因果推断（因果图、RCT） | 贝叶斯视角（先验、后验） |
| "如果做了/没做会怎样" | "我相信什么，有多确定" |
| 因果假设明确化 | 先验假设明确化 |
| 相关性 vs 因果性 | 频率学派 vs 贝叶斯学派 |

老潘看到这段改动会说什么？"**这才是完整的分析报告**。你不仅告诉了读者'流失率是多少'，还解释了'我们有多确定'、'结论对假设的依赖程度'、'频率学派和贝叶斯学派的区别'。"

小北问："**我什么时候该用频率学派，什么时候该用贝叶斯？**"

老潘的答案："**取决于你想回答什么问题**。如果你要回答'差异显著吗'，频率学派够用。如果你要回答'参数有多大概率大于某个阈值'，贝叶斯更直接。两者不是对立的，而是互补的。"

---

## Git 本周要点

本周必会命令：
- `git status`（查看新增的贝叶斯分析模块）
- `git diff`（对比上周的频率学派报告和本周的贝叶斯报告）
- `git add -A`（添加所有变更）
- `git commit -m "feat: add bayesian analysis and prior sensitivity"`（提交贝叶斯模块）

常见坑：
- 把 p 值误解释为"原假设成立的概率"
- 把置信区间误解释为"参数有 95% 的概率在这个区间里"
- 用了强先验但不做敏感性分析
- 忘记检查 MCMC 收敛性（R-hat、ESS）
- 不区分"无信息先验"和"弱信息先验"——"完全无知"也是一种假设

老潘的建议：**贝叶斯方法的核心是"明确假设"——先验必须明确写下来，敏感性分析必须做，这样读者才能判断结论的稳健性**。

---

## Definition of Done（学生自测清单）

本周结束后，你应该能够：

- [ ] 理解贝叶斯定理：P(θ|data) ∝ P(data|θ) × P(θ)
- [ ] 区分频率学派和贝叶斯学派的核心差异
- [ ] 正确解释 p 值和后验概率的区别
- [ ] 区分置信区间和可信区间
- [ ] 选择合适的先验分布（无信息、弱信息、信息性）
- [ ] 计算后验分布（解析解或 MCMC 采样）
- [ ] 进行先验敏感性分析
- [ ] 检查 MCMC 收敛性（R-hat、ESS）
- [ ] 在 StatLab 报告中用贝叶斯方法量化不确定性

---

## 本周小结（供下周参考）

老潘最后给了一个总结："**贝叶斯方法不是'频率学派的替代品'，而是'另一种思维方式'**。"

这周你学会了**从频率学派到贝叶斯学派**：从 p 值和置信区间，到后验分布和可信区间。你理解了贝叶斯定理的核心："后验 = 先验 × 似然"——数据更新先验，形成后验。

你掌握了**先验分布的选择**：无信息先验、弱信息先验、信息性先验。你知道先验必须明确，这"不等于主观"，而是让假设透明化、可质疑、可修改。

你理解了**后验分布的计算**：解析解（共轭先验）和 MCMC 采样（非共轭先验）。你知道 MCMC 和 Bootstrap 的相似性——都是用模拟近似难以计算的分布。

最重要的是，你学会了**先验敏感性分析**：测试结论对先验的依赖程度，理解了"数据最终会战胜先验"的性质。你知道贝叶斯方法的优势是"诚实地表达不确定性"——不假装确定，而是明确"我们有多确定"。

老潘的总结很简洁："**频率学派回答'差异显著吗'，贝叶斯学派回答'我相信什么'。两者都是工具，取决于你想回答什么问题**。"

下周，我们将进入**计算专题**（Week 15）：当数据太多、太快、太复杂时，如何用降维、聚类、A/B 测试等方法做统计分析。
