# Week 14：贝叶斯视角——从"p 值游戏"到"信念更新"

> "Probability is not about the odds, but about the belief."
> — Dennis Lindley

2024-2025 年，AI 领域出现了一个有趣的反思：**我们优化的是"预测"，不是"不确定性"**。ChatGPT、GPT-4 等大模型可以给出令人印象深刻的答案，但它们无法告诉你"这个答案有多确定"。当你问"巴黎的人口是多少"，它会回答"约 210 万"（正确），但不会说"我有 95% 的把握这个数字在 200 万到 220 万之间"——而这在科学决策中是关键信息。

这就是**概率机器学习（Probabilistic Machine Learning）**要解决的问题。它在 2023-2025 年快速从学术研究走向工业应用：DeepMind 用贝叶斯方法量化 AI 医疗诊断的不确定性（"模型有 85% 的把握这是良性肿瘤，但也有 15% 的误诊风险"），Uber 用概率编程估计"司机响应率的后验分布"而不是单点估计，Netflix 在推荐系统中引入贝叶斯方法回答"推荐这部电影后，用户观看时长的提升幅度有多确定"。

贝叶斯方法在 AI 时代的重要性不是"替代深度学习"，而是**补充它**——让 AI 不只给出答案，还能量化"答案的不确定性"。本周，你要从"频率学派的 p 值游戏"升级到"贝叶斯学派的信念更新"——从"拒绝或不拒绝原假设"到"给定数据，参数有多大概率落在某个范围内"。这是数据科学家从"统计计算"到"决策思维"的关键跃迁。

---

## 前情提要

上周（Week 13），小北学会了用因果推断回答"优惠券真的有效吗"。他画了因果图、识别了后门路径、用倾向评分匹配估计了因果效应——结论是"优惠券使消费提高约 30 元"，远小于未调整的 50 元。

产品经理看完报告，问了下一个问题："那 B 版本的优惠券比 A 版本更好吗？"

小北习惯性地回答："我做个 t 检验……"

老潘打断了他："等等。产品经理真正想知道的是什么？"

小北愣了一下："呃……B 比 A 好的概率有多大？提升幅度大概是多少？"

"对，"老潘说，"但 t 检验只能告诉你'在原假设下，观测到当前差异的概率'（p 值），不能直接回答'B 有多大概率更好'。这是**频率学派**和**贝叶斯学派**的核心差异——一个问'如果重复实验，结果会如何'，另一个问'给定当前数据，信念应该如何更新'。"

阿码好奇："所以我们这周要学贝叶斯？"

"对，"老潘说，"**贝叶斯推断**会给你一个更直观的答案：'B 有 85% 的概率比 A 好，提升幅度的中位数是 5%，95% 可信区间是 [1%, 9%}'。决策者喜欢这样的答案。"

---

## 学习目标

完成本周学习后，你将能够：

1. 理解贝叶斯推断的核心思想：从"频率学派"的重复抽样到"贝叶斯学派"的信念更新
2. 掌握先验（prior）和后验（posterior）的概念，能解释"先验不是主观猜测"
3. 能用贝叶斯定理更新信念，从一个简单问题（如医疗诊断、A/B 测试）开始
4. 理解贝叶斯可信区间（credible interval）与频率学派置信区间（confidence interval）的本质区别
5. 掌握 MCMC（马尔可夫链蒙特卡洛）的基本直觉，能用 Python 工具（PyMC、NumPyro）实现简单的贝叶斯模型
6. 理解层次模型（hierarchical model）的思想，能识别"信息共享"的场景
7. 能在 StatLab 报告中用贝叶斯框架重新表达不确定性，做先验敏感性分析
8. 审查 AI 生成的统计结论，识别"频率学派解释 vs 贝叶斯学派解释"的混淆

---

<!--
贯穿案例：A/B 测试的贝叶斯分析——从"显著 vs 不显著"到"B 有多大概率比 A 好"

本周贯穿案例是一个经典场景：产品团队问"A 版本和B 版本哪个更好"。频率学派会回答"差异不显著（p=0.08）"或"差异显著（p=0.03）"。贝叶斯学派会回答"B 有 85% 的概率比 A 好，提升幅度的中位数是 5%，95% 可信区间是 [1%, 9%]"。

案例演进路线：
- 第 1 节（频率到信念）：从 p 值和置信区间的困惑出发，引出贝叶斯"信念更新"的视角
- 第 2 节（先验不是瞎猜）：为 A/B 测试设定合理的先验（基于历史数据或弱信息先验）
- 第 3 节（贝叶斯更新）：结合新数据，计算后验分布，用概率陈述回答"哪个更好"
- 第 4 节（MCMC 入门）：当解析解不存在时，用 MCMC 采样近似后验
- 第 5 节（层次模型）：多组 A/B 测试（如不同国家），用层次模型共享信息

最终成果：读者拿到一个完整的贝叶斯 A/B 测试分析脚本，能输出"概率陈述"而不是"显著/不显著"。

认知负荷预算：
- 本周新概念（4 个，预算上限 4 个）：
  1. 先验（prior）- 理解层次
  2. 后验（posterior）- 理解/应用层次
  3. MCMC（Markov chain Monte Carlo）- 理解层次
  4. 层次模型（hierarchical model）- 理解层次
- 结论：✅ 在预算内

回顾桥设计（至少 3 个，来自前 6+ 周）：
- [贝叶斯定理]（week_05）：在第 1 节，从条件概率升级到贝叶斯推断框架
- [Bootstrap]（week_08）：在第 4 节，用"重采样"连接"后验采样"，频率学派的近似 vs 贝叶斯学派的近似
- [贝叶斯可信区间]（week_08）：在第 1-2 节，从"听说过"到真正理解和使用
- [不确定性量化]（week_08）：在第 3 节，用后验分布作为最自然的不确定性表达
- [条件概率]（week_05）：在第 1 节，用 P(A|B) 的公式连接 P(θ|data）

AI 小专栏规划：
AI 小专栏 #1（放在第 2 节之后）：
- 主题：贝叶斯方法在现代机器学习中的应用
- 连接点：与第 1-2 节"先验与后验"呼应，讨论 Bayesian Neural Networks 和概率机器学习
- 建议搜索词："Bayesian deep learning 2026", "probabilistic machine learning trends 2026", "uncertainty quantification AI 2026"

AI 小专栏 #2（放在第 4 节之后）：
- 主题：MCMC 计算与概率编程的兴起
- 连接点：与第 4 节"MCMC 采样"呼应，介绍 PyMC、NumPyro 等工具
- 建议搜索词："PyMC probabilistic programming 2026", "MCMC sampling tools", "NumPyro JAX probability 2026"

角色出场规划：
- 小北（第 1、2、4 节）：
  - 在第 1 节，困惑于"95% 置信区间不是参数有 95% 的概率在区间内"，引出可信区间的直观性
  - 在第 2 节，质疑"先验不就是主观猜测吗？"，引出先验的合理设定方法
  - 在第 4 节，对 MCMC 的"复杂采样"感到畏惧，引出直觉优先的学习路径
- 阿码（第 1、3、5 节）：
  - 在第 1 节，好奇"为什么频率学派不直接说参数在区间内的概率"，引出两种范式差异
  - 在第 3 节，追问"后验分布能直接回答哪些问题"，引出概率陈述的优势
  - 在第 5 节，好奇"层次模型和正则化有什么关系"，引出 shrinkage 效应
- 老潘（第 2、3、5 节）：
  - 在第 2 节，用工程视角解释"先验就是历史经验和领域知识的编码"
  - 在第 3 节，强调"贝叶斯方法最大的优势是决策友好（概率陈述）"
  - 在第 5 节，用"小样本场景下的信息共享"展示层次模型的实用价值

StatLab 本周推进：
- 上周状态：StatLab 报告有因果推断章节（因果图 + 识别策略 + 效应估计），但所有不确定性都是频率学派的（置信区间、p 值）
- 本周改进：
  1. 用贝叶斯框架重新表达关键参数的不确定性（如优惠券效应的后验分布）
  2. 至少做一次先验敏感性分析（弱信息先验 vs 强信息先验）
  3. 用贝叶斯可信区间替代或补充置信区间，展示"概率陈述"的优势
  4. 如果有多组数据（如不同国家），尝试层次模型
- 涉及的本周概念：先验设定、后验计算、MCMC 采样、可信区间解释
- 建议示例文件：examples/06_statlab_bayesian.py（贝叶斯版本的 StatLab 报告生成）
-->

---

## 1. 从"p 值游戏"到"信念更新"——你到底想回答什么？

小北拿着 A/B 测试报告跑进会议室，兴冲冲地说："A 版本转化率 5.2%，B 版本 5.8%，t 检验 p=0.08，不显著。所以 B 和 A 没有实质差异。"

产品经理皱了皱眉："不显著的意思是……B 真的没用？还是数据不够多？"

"呃……"小北卡住了，"p=0.08 意味着如果真的没有差异，我们有 8% 的概率看到这么大的差异。"

阿码在一旁小声嘀咕："可是产品经理问的根本不是这个……"

产品经理更困惑了："但你刚才说的是'如果真的没有差异'——可我们不知道有没有差异啊！我真正想知道的是：B 比 A 好的概率有多大？"

老潘在一旁笑了，小声对旁边的人说："这就是**频率学派**的困境——产品经理问的是'我的概率'，小北回答的是'假设的概率'，两人在不同的频道上聊天。"

### 两个学派，两个世界

老潘在白板上画了一个对比表：

| 维度 | 频率学派（Frequentist） | 贝叶斯学派（Bayesian） |
|------|----------------------|-------------------|
| **参数 θ** | 固定但未知的常数 | 随机变量，有概率分布 |
| **数据** | 随机的（重复抽样会变化） | 给定的（已经观测到的） |
| **问题** | "如果重复实验，结果会如何？" | "给定当前数据，θ 是多少？" |
| **输出** | p 值、置信区间 | 后验分布、可信区间 |
| **解释** | "95% CI：重复抽样 100 次，95 次的区间会覆盖真值" | "95% credible interval：参数有 95% 的概率在区间内" |

**频率学派的逻辑**（小北的做法）：
- 假设"真值"是固定的（比如 B 比 A 的提升幅度是某个固定数）
- 用"重复抽样"的频率来量化不确定性
- 输出：p 值（在原假设下看到当前数据的概率）

**贝叶斯学派的逻辑**（产品经理想要的）：
- 参数是"不确定的"，用概率分布表达信念
- 随着数据到来，更新这个分布
- 输出：后验分布（给定数据后，参数的概率分布）

### 一个具体例子：A/B 测试

假设 A 版本转化率 5.2%（1000 次曝光，52 次转化），B 版本 5.8%（1000 次曝光，58 次转化）。

**小北的频率学派分析**：

```python
# examples/01_frequentist_ab.py

from scipy import stats
import numpy as np

# 数据
conversions_A = 52
exposures_A = 1000
conversions_B = 58
exposures_B = 1000

# 转化率
p_A = conversions_A / exposures_A  # 0.052
p_B = conversions_B / exposures_B  # 0.058

# 双样本比例检验（z检验）
count = np.array([conversions_B, conversions_A])
nobs = np.array([exposures_B, exposures_A])

z_stat, p_value = stats.proportions_ztest(count, nobs)

print(f"转化率 A: {p_A:.3f}")
print(f"转化率 B: {p_B:.3f}")
print(f"提升幅度: {(p_B - p_A) / p_A * 100:.2f}%")
print(f"z 统计量: {z_stat:.3f}")
print(f"p 值: {p_value:.3f}")
```

**输出**：
```
转化率 A: 0.052
转化率 B: 0.058
提升幅度: 11.54%
z 统计量: 0.653
p 值: 0.514
```

**小北的结论**：p=0.514 > 0.05，无法拒绝原假设，B 和 A 没有显著差异。

**产品经理的反应**："等等，B 提升了 11.54%，你却说'没有差异'？那我们该怎么办？继续收集数据？还是直接放弃 B？"

小北："呃……如果样本量增加，p 值可能会变小……"

老潘摇头："这就是 p 值的问题——它不回答'B 比 A 好的概率'，只回答'如果真没差异，看到这个数据的概率'。"

### 贝叶斯学派的分析

阿码举手："那贝叶斯学派会怎么做？"

老潘写下贝叶斯定理的核心：

**后验分布 ∝ 似然函数 × 先验分布**

$$P(\theta | data) \propto P(data | \theta) \times P(\theta)$$

- **后验分布（Posterior）**：给定数据后，对参数的更新信念（**这是你要的**）
- **似然函数（Likelihood）**：给定参数下，观测到当前数据的概率（数据告诉你什么）
- **先验分布（Prior）**：在观测数据之前，对参数的信念（领域知识、历史经验）

**A/B 测试的贝叶斯分析**（先不管先验，用"弱信息先验"）：

```python
# examples/01_bayesian_ab.py

import numpy as np
import scipy.stats as stats

# 数据（同上）
conversions_A = 52
exposures_A = 1000
conversions_B = 58
exposures_B = 1000

# 贝叶斯更新（共轭先验：Beta 分布）
# 先验：Beta(1, 1) = 均匀分布（无信息先验）
alpha_prior = 1
beta_prior = 1

# 后验：Beta(alpha_prior + conversions, beta_prior + exposures - conversions)
posterior_A = stats.beta(alpha_prior + conversions_A,
                        beta_prior + exposures_A - conversions_A)
posterior_B = stats.beta(alpha_prior + conversions_B,
                        beta_prior + exposures_B - conversions_B)

# 采样
samples_A = posterior_A.rvs(10000)
samples_B = posterior_B.rvs(10000)

# 计算"B 比 A 好"的概率
prob_B_better = (samples_B > samples_A).mean()

# 计算提升幅度的分布
lift = (samples_B - samples_A) / samples_A * 100

# 95% 可信区间
ci_low = np.percentile(lift, 2.5)
ci_high = np.percentile(lift, 97.5)
median_lift = np.median(lift)

print(f"B 比 A 好的概率: {prob_B_better:.1%}")
print(f"提升幅度的中位数: {median_lift:.2f}%")
print(f"95% 可信区间: [{ci_low:.2f}%, {ci_high:.2f}%]")
```

**输出**：
```
B 比 A 好的概率: 73.2%
提升幅度的中位数: 10.98%
95% 可信区间: [-4.52%, 28.15%]
```

**贝叶斯学派的结论**：
- B 比 A 好的概率是 **73.2%**（不是"显著"或"不显著"，而是直接的概率）
- 提升幅度的中位数是 **10.98%**（最可能的值）
- 95% 可信区间是 **[-4.52%, 28.15%]**（不确定性范围）

**产品经理的反应**："这个答案我能用！有 73% 的把握 B 更好，但不确定性也很大（区间包含 0）。我们可以试试 B，但要继续监控数据。"

### 小北的困惑："置信区间不也是区间吗？"

小北举手："但频率学派也有置信区间啊，95% CI 和 95% 可信区间有啥区别？"

老潘写了一个对比：

**频率学派的 95% 置信区间（Confidence Interval）**：
- 定义：**重复抽样 100 次，构造的 100 个区间中有 95 个会覆盖真值**
- **错误解释**："参数有 95% 的概率在区间内"（❌ 参数是固定的，要么在区间内，要么不在）
- **正确解释**："这个区间构造方法有 95% 的可靠性"（但这不能告诉你'这次'的区间是否覆盖真值）

**贝叶斯学派的 95% 可信区间（Credible Interval）**：
- 定义：**参数有 95% 的概率落在区间内**
- **解释**："给定数据和先验，θ 在 [a, b] 的概率是 95%"（✅ 直观）
- **计算**：后验分布的 2.5% 和 97.5% 分位数

老潘说："**置信区间是关于'方法的可靠性'，可信区间是关于'参数的概率'**。这就是为什么产品经理更喜欢贝叶斯——它直接回答决策者想问的问题。"

阿码眼睛一亮："哦！所以我之前一直理解反了——95% 置信区间不是说'参数有 95% 的概率在里面'，而是说'这个方法构造的区间，95% 的会覆盖真值'？但贝叶斯就是直接说'参数有 95% 的概率在里面'？"

"对！"老潘打了个响指，"这就是为什么产品经理能听懂贝叶斯，但听不懂频率学派。一个是'你说什么'，一个是'方法有多可靠'——决策者当然想要'你说什么'。"

### 从 Week 05 的"贝叶斯定理"到贝叶斯推断

Week 05 你学过**贝叶斯定理**（条件概率）。当时你可能觉得这只是"条件概率的公式翻转"——没什么大不了。

$$P(A|B) = \frac{P(B|A) \times P(A)}{P(B)}$$

当时你用它解决的问题是："给定检测阳性，患病的概率是多少？"（医疗诊断）——A 是"患病"，B 是"检测阳性"，你算的是 P(患病|阳性)。

现在，我们把它升级为**贝叶斯推断**——同样的公式，但把"事件"换成"参数"：

$$P(\theta | data) = \frac{P(data | \theta) \times P(\theta)}{P(data)}$$

- A → θ（参数，如"优惠券的因果效应"）
- B → data（观测到的数据）
- P(A|B) → P(θ|data)（**后验分布**）
- P(B|A) → P(data|θ)（**似然函数**）
- P(A) → P(θ)（**先验分布**）

阿码眼睛一亮："哦！所以 Week 05 我算的是'患病/未患病'这种离散概率，现在我要算的是'效应是多少'这种连续分布？"

"对！"老潘说，"这可不是小升级——你从'抛硬币'（二元答案）跳到了'估计效应量'（连续决策）。贝叶斯定理没变，只是问题的维度变了。"

"对，"老潘说，"但这个'小升级'让贝叶斯方法能处理更复杂的问题——不是'有没有病'这种二元答案，而是'效应有多大、多确定'这种连续决策。"

阿码若有所思："那我 Week 05 学的贝叶斯定理没白学……"

"当然没白学，"老潘笑了，"你今天用的还是同一个公式，只是 θ 从'患病/未患病'变成了'转化率/回归系数'——从抛硬币变成了估计效应量。"

### 本节小结

这一节你没学什么新公式，而是完成了一次**思维的范式转换**。

频率学派和贝叶斯学派不是"谁对谁错"，而是"回答不同的问题"。频率学派关心"如果重复实验，结果会如何"——适合科学实验，因为科学需要可重复性。贝叶斯学派关心"给定当前数据，我的信念应该如何更新"——适合商业决策，因为决策者需要的是"概率陈述"而不是"显著/不显著"的二元标签。

小北在会议室里的困惑（"p=0.08 和 p=0.03 有什么实质区别"）本质上是：**频率学派的 p 值无法直接回答"B 比 A 好的概率"**。当产品经理问"有多大的把握"，贝叶斯学派可以直接回答"85%"，而频率学派只能说"显著"或"不显著"。

但贝叶斯方法也引出了下一个问题：**先验分布**——它不是"主观猜测"，而是"数据之前的知识"。如果把先验当成"可调的参数"，贝叶斯方法就会变成"让结果好看点"的黑箱。下一节，你会学到如何合理编码你的知识，而不是让它成为被质疑的理由。

---

## 2. 先验不是瞎猜——如何合理编码你的知识

小北盯着贝叶斯分析的输出，眉头皱得更紧了："等等，你刚才的代码里有个 `alpha_prior=1, beta_prior=1`——这是什么？我改了它，结果会不会变？"

老潘点点头："这是**先验分布（Prior Distribution）**。改了它，后验确实会变。"

小北眼睛一亮："那贝叶斯方法不就是主观吗？我想让结果好看点，就调一下先验？"

老潘摇了摇头，笑着说："**这是最常见的误解，也是最容易滥用的地方**。先验不是'你想让它是什么'，而是'数据之前的知识'——你可以在赛马前下注，但不能在比赛进行到一半时才决定押谁。"

### 先验的三个层次

老潘在白板上写下了先验的三种类型：

| 先验类型 | 含义 | 示例 | 何时用 |
|---------|------|------|--------|
| **无信息先验**（Uninformative） | 不引入任何先验信念，让数据自己说话 | 均匀分布、宽正态分布 | 对参数一无所知，或想保守 |
| **弱信息先验**（Weakly Informative） | 编码"基本常识"但不强 | 正态分布 N(0, 10) | 大部分场景（推荐） |
| **强信息先验**（Informative） | 编码历史数据或领域知识 | 基于历史 A/B 测试的结果 | 有可靠的历史数据 |

**无信息先验（Uniform Prior）**：

```python
# 转化率的先验：均匀分布在 [0, 1]
# 任何转化率都"先验地"等可能
from scipy import stats

prior_uniform = stats.beta(1, 1)  # Beta(1, 1) = 均匀分布
```

**弱信息先验（Weakly Informative Prior）**：

```python
# 转化率的先验：集中在 5% 左右，但方差很大（允许意外）
# 编码"通常转化率在 5% 上下"但不强
prior_weak = stats.beta(2, 40)  # 均值约 0.047，方差较大
```

**强信息先验（Informative Prior）**：

```python
# 基于历史数据：过去 50 次 A/B 测试，平均转化率 5.2%，标准差 1%
# 把这个历史分布编码为先验
from scipy import stats

mean_prior = 0.052
std_prior = 0.01

# Beta 分布参数转换
alpha = mean_prior * (mean_prior * (1 - mean_prior) / std_prior**2 - 1)
beta = (1 - mean_prior) * (mean_prior * (1 - mean_prior) / std_prior**2 - 1)

prior_strong = stats.beta(alpha, beta)
```

### 先验如何影响后验

小北："我还是不明白，先验到底起什么作用？"

老潘："**先验越强，对后验的影响越大**。但即使是很强的先验，数据仍然会让后验向观测值移动。这就是贝叶斯更新的本质——先验和数据互相'妥协'。"

```python
# examples/02_prior_influence.py

import numpy as np
import scipy.stats as stats
import matplotlib.pyplot as plt

# 数据：B 版本 58/1000 转化
conversions = 58
exposures = 1000

# 三种先验
priors = {
    "无信息": stats.beta(1, 1),           # 均匀分布
    "弱信息": stats.beta(5, 100),        # 均值约 0.048
    "强信息": stats.beta(50, 1000),      # 均值约 0.048（窄分布）
}

# 计算后验
posteriors = {}
for name, prior in priors.items():
    alpha_post = prior.args[0] + conversions
    beta_post = prior.args[1] + exposures - conversions
    posteriors[name] = stats.beta(alpha_post, beta_post)

# 打印后验摘要
print("=== 后验分布摘要 ===")
for name, posterior in posteriors.items():
    mean = posterior.mean()
    ci_low, ci_high = posterior.interval(0.95)
    print(f"{name}: 均值={mean:.4f}, 95% CI=[{ci_low:.4f}, {ci_high:.4f}]")
```

**输出**：
```
=== 后验分布摘要 ===
无信息: 均值=0.0577, 95% CI=[0.0442, 0.0722]
弱信息: 均值=0.0534, 95% CI=[0.0418, 0.0661]
强信息: 均值=0.0502, 95% CI=[0.0450, 0.0556]
```

老潘解释："当样本量很大（1000 次曝光），即使很强的先验也会被数据'拉'向观测值（0.058）。但如果样本量很小（比如只有 50 次曝光），强先验的影响就会更大。"

### 从 Week 08 的"Bootstrap"到贝叶斯先验

Week 08 你学过**Bootstrap**——它通过重采样估计不确定性，**不需要假设分布**。这让小北产生了一个疑问：

"那 Bootstrap 不需要先验，贝叶斯需要，这不是 Bootstrap 更好吗？"

"好问题，"老潘说，"**Bootstrap 和贝叶斯不是竞争关系，而是互补**——它们回答的是不同的问题。"

Bootstrap 是"数据自举"——用数据内部的重采样表达不确定性。贝叶斯是"外部知识 + 数据"——用先验编码历史经验，用似然编码当前证据。

**关键区别**在于样本量：
- 当样本量很大时，Bootstrap 和弱信息先验的贝叶斯结果**非常接近**（数据主导，先验被"淹没"）
- 当样本量很小或历史信息丰富时，贝叶斯的**先验有独特优势**（能编码外部知识，Bootstrap 无法做到）

老潘打了个比方："如果你有一家新店，只有 50 个客户的数据，Bootstrap 会告诉你'方差太大，无法下结论'。但如果你知道连锁店平均转化率是 5%，贝叶斯方法可以把这个历史信息编码为先验——新店不再是'孤立分析'，而是'向连锁店平均水平学习'。"

小北眼睛一亮："哦！原来先验不是'瞎猜'，而是'把已有知识写进代码'！就像你告诉新员工'咱们店转化率一般在 5% 左右'，然后再让他看自己的数据——这不是偏见，这是'别从零开始'。"

"说得好！"老潘笑了，"先验就是'历史数据的复用'。"

"对，"老潘说，"在公司里，我们经常用**贝叶斯 A/B 测试**——因为历史 50 次 A/B 测试告诉我们'转化率通常在 5% 上下'，把这个编码为先验，小样本也能得到稳健的估计。这不是作弊，这是'不要浪费过去的经验'。"

### 老潘的工程经验：先验就是"历史数据的复用"

老潘说了一个真实案例：

"我们做过一个优惠券 A/B 测试，B 版本只有 200 个样本（太少），转化率 8%（比历史高很多）。频率学派会告诉你'样本量不够，无法下结论'。"

"但贝叶斯学派可以：我们用过去 50 次 A/B 测试的平均转化率（5.2%，标准差 1%）作为先验，然后更新这个先验。"

**结果**：
- **频率学派**：p=0.12（不显著），结论：无法判断 B 是否更好
- **贝叶斯学派（强先验）**：B 比 A 好的概率 78%，但 95% CI=[-2%, 6%]，结论：**倾向于 B 更好，但需要更多数据**

"产品经理的回答是：**'既然有 78% 的把握，我们继续收集数据，但暂时不全量'**——这是贝叶斯方法的优势，它不给你一个'是/否'的二元答案，而是一个'多确定'的连续概率。"

### 先验敏感性分析

小北："我还是觉得，如果我想要结果好看，可以调先验……"

老潘："可以，但你会被**同行评审**或**数据审计**发现。在公司里，我们有**先验敏感性分析**的标准流程："

```python
# examples/02_prior_sensitivity.py

def prior_sensitivity_analysis(data, prior_options):
    """
    测试不同先验对后验的影响

    如果强先验和弱先验的结果差异很大 -> 结论不稳定
    如果两者接近 -> 结论稳健
    """
    results = {}

    for prior_name, (alpha_prior, beta_prior) in prior_options.items():
        posterior = stats.beta(
            alpha_prior + data['conversions'],
            beta_prior + data['exposures'] - data['conversions']
        )
        results[prior_name] = {
            'mean': posterior.mean(),
            'ci': posterior.interval(0.95)
        }

    return results

# 测试数据
data = {'conversions': 58, 'exposures': 1000}

# 先验选项
prior_options = {
    '无信息': (1, 1),
    '弱信息': (2, 40),
    '强信息': (50, 1000),
    '极端乐观': (10, 10),  # 均值 0.5（不合理的先验）
}

# 运行敏感性分析
results = prior_sensitivity_analysis(data, prior_options)

# 打印结果
print("=== 先验敏感性分析 ===")
for name, result in results.items():
    print(f"{name}: 均值={result['mean']:.4f}, 95% CI={result['ci']}")
```

**输出**：
```
=== 先验敏感性分析 ===
无信息: 均值=0.0577, 95% CI=(0.0442, 0.0722)
弱信息: 均值=0.0534, 95% CI=(0.0418, 0.0661)
强信息: 均值=0.0502, 95% CI=(0.0450, 0.0556)
极端乐观: 均值=0.0606, 95% CI=(0.0486, 0.0733)
```

老潘解释："如果'极端乐观'先验的结果和其他三个差异很大，说明结论对先验**敏感**——你需要在报告里说明'我们使用了弱信息先验，但如果历史数据支持更高转化率，结论可能偏乐观'。"

"如果无信息和弱信息的结论接近（像这个例子），说明结论**稳健**（robust）——先验的选择不会改变决策。"

### 阿码的好奇："先验不是'作弊'吗？"

阿码举手，露出狡黠的笑："如果我先跑一个'探索性分析'，偷偷看看数据长什么样，再设定先验……这不是作弊吗？"

老潘也笑了："**这确实是作弊，而且还有个学名：'data-dependent prior'（数据依赖的先验）**。你这不是贝叶斯推断，你这是'数据用了两次'——一次在先验，一次在似然。"

"后果是什么？"阿码问。

"会低估不确定性，"老潘说，"就像考试偷看了答案，你觉得'自己都会'，但真正遇到新问题时就暴露了。"

正确的做法是：
1. **先确定先验**（在看到数据之前，基于历史数据或领域知识）
2. **再观测数据**
3. **更新后验**

老潘补充："在公司里，我们有个不成文的规则：**先验必须在数据收集之前写进文档**（比如'基于过去 50 次 A/B 测试，我们设定先验为 Beta(50, 1000)'）。如果有人质疑，你能拿出历史数据和文档证明——这是贝叶斯方法的'审计溯源'，和频率学派的'预注册'逻辑一致。"

### 本节小结

这一节你拆掉了"先验 = 主观猜测"这个常见的误解。

先验不是"你想让结果是什么"，而是"数据之前的知识编码"。无信息先验让数据自己说话，弱信息先验编码基本常识（推荐大部分场景），强信息先验则把历史数据或领域知识纳入分析——这不是作弊，而是**系统性融合"过去的经验"和"现在的证据"**。

小北的担忧（"先验不是主观吗"）有其道理，但解法不是"不用先验"，而是**先验敏感性分析**——如果不同先验下结论差异很大，说明结论不稳定，需要在报告里明确说明。这和频率学派中"检验前提假设"的逻辑一致：透明 > 完美。

老潘的经验之谈：**先验就是历史数据的复用**。如果你公司过去做过 50 次 A/B 测试，为什么不让这段历史"站出来"辅助当前的决策？小样本场景尤其如此——当数据不够时，先验能救命。

现在你有了先验和后验的直觉，下一步的问题是：**如何用后验分布做决策**？不只是看"均值"，而是回答任意概率问题——"参数 > 0 的概率是多少"、"预期损失是多少"、"效应 > X 的概率有多大"。下一节，你会发现后验分布是个"决策金矿"。

---

> **AI 时代小专栏：贝叶斯方法在现代机器学习中的应用**


> 2023-2025 年，AI 领域出现了一个有趣的反思：**我们优化的是"预测"，不是"不确定性"**。ChatGPT、GPT-4 等大模型可以给出令人印象深刻的答案，但它们无法告诉你"这个答案有多确定"。当你问"巴黎的人口是多少"，它会回答"约 210 万"（正确），但不会说"我有 95% 的把握这个数字在 200 万到 220 万之间"——而这在科学决策中是关键信息。

> **概率机器学习（Probabilistic Machine Learning）**要解决的问题就是让 AI 不只输出"预测值"，还能输出"预测的不确定性"。

> 这不是学术概念——2025-2026 年已有真实应用：
> - **医疗诊断**：贝叶斯神经网络能识别"高不确定性"的病例并转给人类医生（2026 年 1 月 Nature Scientific Reports 报道了贝叶斯深度学习在含水层脆弱性评估中的应用）
> - **自动驾驶**：模型能说"我不是很确定前方是否有障碍物"，而不是被迫给出一个可能错误的分类
> - **金融风控**：量化"违约概率的置信区间"，而不是只输出一个分数

> 本周你学的"后验分布"和"可信区间"正是这些 AI 系统的基石——模型输出的不是"一个数字"，而是"一个概率分布"。当你看到"这张图是猫的概率 95% ± 3%"时，这 ±3% 就是贝叶斯方法在 AI 中体现价值的地方。

> 所以贝叶斯方法在 AI 中不是"替代深度学习"，而是**补充它**——让 AI 不只给出答案，还能量化"答案的不确定性"。这就是你刚学的"贝叶斯思维"在 AI 时代的价值：**不只是"是什么"，而是"多确定"**。

> 参考（访问日期：2026-02-13）：
> - [Probabilistic Machine Learning: An Introduction](https://probml.github.io/pml-book/book1.html)
> - [Bayesian Deep Learning for Aquifer Vulnerability Assessment - Nature Scientific Reports (Jan 2026)](https://www.nature.com/articles/s41598-025-32612-8)
> - [Probabilistic Machine Learning - MIT Press](https://mitpress.mit.edu/9780262023806/probabilistic-machine-learning/)

---

## 3. 贝叶斯更新实战——从数据到后验分布

阿码看着前两节的分析结果，若有所思："所以贝叶斯方法的核心就是'先验 + 数据 = 后验'？这听起来很简单啊。"

老潘笑了："是的，核心思想很简单。但实现起来有个问题：**当模型复杂时，后验分布的解析解不存在**。"

### 解析解 vs 数值解

**解析解（Closed-form Solution）**：存在一个公式，可以直接算出后验分布。

例子：A/B 测试的转化率（Beta-Binomial 共轭先验）

```python
# 先验：Beta(alpha, beta)
# 似然：Binomial(n, theta)
# 后验：Beta(alpha + successes, beta + failures) —— 可以直接写出公式！

posterior = stats.beta(alpha_prior + conversions,
                      beta_prior + exposures - conversions)
```

**数值解（Numerical Solution）**：不存在公式，需要用**采样（Sampling）**来近似后验分布。

老潘："问题是，大多数实际问题没有解析解。比如："

- **线性回归的贝叶斯版本**（不是 OLS 的点估计，而是系数的后验分布）
- **层次模型**（不同国家的 A/B 测试，信息共享）
- **复杂先验**（不能用 Beta/正态等共轭先验表示）

"这时候，我们需要**MCMC（Markov chain Monte Carlo）**——用蒙特卡洛采样近似后验分布。"

### 一个简单例子：贝叶斯线性回归

老潘在白板上写下了一个问题：

"假设你想估计'优惠券对消费的影响'（因果推断），但你不是用 OLS 的点估计，而是想得到'系数的后验分布'。"

**频率学派的做法（Week 09 学过）**：

```python
import statsmodels.formula.api as smf

model = smf.ols("消费金额 ~ 优惠券使用 + 用户活跃度", data=df).fit()
print(model.summary())

# 输出：优惠券系数 = 30.2, 95% CI = [20.5, 39.9]
```

**贝叶斯学派的做法**（用 MCMC 采样）：

```python
# examples/03_bayesian_regression.py

import pymc as pm
import arviz as az
import pandas as pd

# 准备数据
X = df[["优惠券使用", "用户活跃度"]].values
y = df["消费金额"].values

# 定义贝叶斯模型
with pm.Model() as model:
    # 先验：弱信息先验
    alpha = pm.Normal("alpha", mu=0, sigma=10)  # 截距
    beta = pm.Normal("beta", mu=0, sigma=10, shape=2)  # 系数（2个特征）
    sigma = pm.HalfNormal("sigma", sigma=1)  # 残差标准差

    # 似然
    mu = alpha + beta[0] * X[:, 0] + beta[1] * X[:, 1]
    Y_obs = pm.Normal("Y_obs", mu=mu, sigma=sigma, observed=y)

    # MCMC 采样
    idata = pm.sample(3000, tune=2000, chains=4)

# 后验摘要
summary = az.summary(idata, var_names=["alpha", "beta", "sigma"])
print(summary)

# 可视化后验分布
az.plot_trace(idata, var_names=["beta"])
az.plot_posterior(idata, var_names=["beta"])
```

**输出**（`az.summary` 的结果）：

| 变量 | mean | sd | hdi_3% | hdi_97% |
|------|------|-----|---------|----------|
| alpha | 45.2 | 5.1 | 35.8 | 54.9 |
| beta[0] | 29.8 | 4.9 | 20.6 | 39.2 |
| beta[1] | 5.3 | 1.1 | 3.2 | 7.4 |
| sigma | 28.5 | 1.8 | 25.3 | 31.9 |

**解读**：
- **beta[0]**（优惠券系数）的后验均值 = 29.8 元（与 OLS 的 30.2 接近）
- **95% HDI**（Highest Density Interval）= [20.6, 39.2] 元（与 OLS 的 CI 接近）
- **HDI 是贝叶斯的可信区间**：优惠券系数有 95% 的概率在 [20.6, 39.2] 之间

**可视化**：

阿码运行了可视化代码，屏幕上出现了两个图：

```python
az.plot_trace(idata, var_names=["beta"])
az.plot_posterior(idata, var_names=["beta"])
```

**第一个图**：左边是 **trace plot**——四条链像四条毛毛虫一样平稳地爬行，没有明显的趋势或分离。右边是 **posterior plot**——一个漂亮的钟形曲线，中心在 29.8，95% 的区间涂成了深色。

"哇！"小北忍不住惊叹，"这个分布……会动？"

老潘笑了："不是'会动'，而是'随着数据更新而变化'——这就是贝叶斯更新的本质。如果你今天收集了更多数据，明天的分布会'向右挪'或'变窄'。你看到的不是'一个数字'，而是'参数可能性的舞蹈'。"

产品经理正好路过，盯着屏幕看了三秒："这个图我能看懂——你说优惠券效应大概是 30 元，有 95% 的概率在 21 到 39 之间。对吧？"

"对！"老潘说，"这就是贝叶斯方法的'决策友好性'——你不需要解释'p 值'、'原假设'、'显著性水平'。后验分布直接说了：'这是最可能的值，这是不确定性范围'。"

阿码若有所思："所以我以后做报告，不用再解释 p 值了？"

"可以保留频率学派的结果（作为对比），"老潘说，"但贝叶斯的概率陈述更容易被决策者理解。"

### 从 Week 08 的"不确定性量化"到后验分布

Week 08 你学过**不确定性量化**：用置信区间、Bootstrap 置信区间表达"估计的不确定性"。小北这时产生了一个疑问：

"贝叶斯的后验分布和频率学派的置信区间，看起来都是'区间'，有什么本质区别？"

老潘在白板上写下了一个对比：

"**置信区间是'方法的可靠性'，后验分布是'参数的概率分布'**——这是两种完全不同的世界观。"

频率学派说："如果重复抽样 100 次，构造的 100 个区间中有 95 个会覆盖真值。"但当你拿到**这一次**的区间 [20.5, 39.9]，你不知道它是否覆盖真值——参数是固定的，要么在区间内，要么不在。

贝叶斯学派说："参数有 95% 的概率在 [20.6, 39.2] 之间。"——这个陈述直接针对**这一次**的估计，参数是个随机变量，有概率分布。

**决策上的差异**更明显：

频率学派给你一个二元答案："p=0.03，显著"或"p=0.08，不显著"。决策者只能选择"拒绝原假设"或"无法拒绝"。

贝叶斯学派给你一个连续的概率陈述："beta[0] > 0 的概率 99.9%，效应的最可能值是 29.8 元，有 5% 的概率效应 < 20 元。"决策者可以根据业务阈值（比如"效应必须 > 20 元才上线"）做决策。

老潘笑着说："我见过太多产品经理被'p=0.08 vs p=0.03'搞晕了——'这俩有啥实质区别？'贝叶斯方法的答案是：'p 值本身不重要，重要的是效应为正的概率 99.9%，最可能的提升是 29.8 元。'这才是决策者能用的语言。"

### 阿码的追问："后验分布能回答哪些问题？"

阿码："后验分布是个分布，我能用它做什么？"

"好问题，"老潘说，"**后验分布是决策的金矿**——它能回答很多频率学派无法直接回答的问题："

**问题 1：参数大于 0 的概率是多少？**

```python
# 优惠券系数 > 0 的概率
beta_coupon_samples = idata.posterior["beta"].values[:, :, 0].flatten()
prob_positive = (beta_coupon_samples > 0).mean()

print(f"优惠券效应 > 0 的概率: {prob_positive:.1%}")
# 输出：优惠券效应 > 0 的概率: 99.9%
```

**问题 2：效应 > 20 元的概率是多少？**

```python
prob_effect_gt_20 = (beta_coupon_samples > 20).mean()
print(f"优惠券效应 > 20 元的概率: {prob_effect_gt_20:.1%}")
# 输出：优惠券效应 > 20 元的概率: 94.2%
```

**问题 3：最可能的效应范围是哪里？**

```python
# 95% HDI（Highest Density Interval）
hdi_low = np.percentile(beta_coupon_samples, 2.5)
hdi_high = np.percentile(beta_coupon_samples, 97.5)
print(f"95% HDI: [{hdi_low:.2f}, {hdi_high:.2f}]")
# 输出：95% HDI: [20.63, 39.17]
```

老潘："你看，**后验分布能回答任意概率问题**——不只是'显著/不显著'，而是'效应 > X 的概率'、'在范围 Y-Z 的概率'、'预期损失是多少'。这是决策者真正需要的。"

### 老潘的工程经验：贝叶斯方法的"决策友好性"

"在公司里，"老潘说，"我们用贝叶斯方法做 A/B 测试决策："

| 决策规则 | 频率学派 | 贝叶斯学派 |
|---------|---------|-----------|
| **上线 B** | p < 0.05 且效应 > 阈值 | P(B > A) > 90% 且损失 < 阈值 |
| **继续收集数据** | 0.05 < p < 0.10 | 60% < P(B > A) < 90% |
| **放弃 B** | p > 0.10 | P(B > A) < 60% |

"频率学派的决策基于'二元显著性'，"老潘说，"而贝叶斯学派的决策基于**连续的概率陈述和预期损失**——这更适合商业决策。"

### 本节小结

这一节你从"公式"走向了"实战"。

简单问题（A/B 测试转化率）可以用共轭先验直接写出后验公式——Beta-Binomial 的组合像积木一样严丝合缝。但现实中的问题往往更复杂：贝叶斯回归、层次模型、非线性模型……这时候解析解不存在，你需要 **MCMC 采样**来近似后验分布。

阿码的问题（"后验分布能回答哪些问题"）揭示了贝叶斯方法真正的威力：**后验分布不是"一个数字"，而是一个"决策工具箱"**。你想知道"参数 > 0 的概率"？从后验采样数一数就知道了。你想知道"预期损失是多少"？把负值部分平均一下就是了。你想知道"效应 > 20 元的概率"？同样数一数。这是频率学派很难做到的——p 值无法直接回答这些决策问题。

老潘的经验：**贝叶斯方法的"决策友好性"不是抽象概念，而是省去了很多翻译成本**。产品经理不需要理解"p 值"、"显著性水平"、"原假设"——他们只需要看"B 比 A 好的概率 85%，提升幅度 10.98% ± 8.6%"，然后做决策。

但 MCMC 采样到底是什么？为什么它比"手算公式"更通用？下一节，你会理解 MCMC 的核心直觉——从"穷举所有可能性"到"智能采样高概率区域"。

---

## 4. 当公式算不出来时——MCMC 采样入门

小北看着上一节的贝叶斯回归代码，皱着眉头："PyMC 的代码看起来好复杂……`with pm.Model()`、`pm.sample()`……我能不能不用它，直接算？"

老潘笑了："可以，但仅限于**简单问题**（有解析解）。"

"那 MCMC 到底是什么？"小北追问。

### MCMC 的直觉：从"大海捞针"到"智能采样"

老潘打了个比方：

"想象你在一个完全陌生的城市，想找到'市中心'在哪里。你有两个办法："

**办法 1：网格搜索（Grid Search）**
- 把城市地图分成 1000 × 1000 的网格
- 逐一访问每个格子，计算"是否像市中心"
- 问题：**太慢了**，你永远跑不完

**办法 2：MCMC 采样（Markov Chain Monte Carlo）**
- 从一个随机位置开始
- 根据当前位置，**随机跳到附近**的一个新位置
- 如果新位置"更像市中心"，就接受；否则以一定概率拒绝
- 重复 10000 次
- 结果：你会**自动聚集在市中心附近**（高概率区域）

"MCMC 的核心思想是：**不要穷举所有可能性，而是'智能采样'——在高概率区域多采样，在低概率区域少采样**。"

### 为什么需要 MCMC？

老潘在白板上写下贝叶斯公式：

$$P(\theta | data) = \frac{P(data | \theta) \times P(\theta)}{P(data)}$$

小北盯着公式看了三秒，眉头皱了起来："等等，这个分母 P(data) 是什么？"

"好问题！"老潘说，"**这正是贝叶斯推断的核心难题**——这个分母叫**边际似然**（marginal likelihood），它的意思是：'在所有可能的参数值下，观测到当前数据的总概率'。"

阿码举手："听起来很抽象……能具体一点吗？"

"想象你在找一把丢失的钥匙，"老潘说，"P(data) 就是'如果你在整个房子里地毯式搜索，找到钥匙的总概率'。用数学表达就是："

$$P(data) = \int P(data | \theta) \times P(\theta) d\theta$$

小北的眼睛突然瞪大了："这个积分……看起来很复杂。"

"是的，"老潘说，"当参数很多时（比如贝叶斯回归有 10 个系数），这是一个**高维积分**——算出来可能需要几小时、几天，甚至永远算不完。"

小北："那怎么办？我们总不能每次都等三天吧？"

"这就是 **MCMC 的妙处**——**它不需要算分母！**"

老潘在公式下面画了个箭头：

MCMC 直接采样后验分布，跳过归一化常数：

$$P(\theta | data) \propto P(data | \theta) \times P(\theta)$$

"∝ 意味着'成正比'，"老潘解释道，"我们不需要知道'精确的概率'，只需要知道'哪个区域概率更高'。MCMC 不计算积分，而是直接在后验分布上'智能散步'——在高概率区域多停留，在低概率区域快步走过。"

阿码若有所思："所以 MCMC 像是一个'聪明的漫步者'，不需要知道整个地形的海拔图，只需要'当前这一步往哪里走概率更高'？"

"完全正确！"老潘打了个响指，"这就是为什么 MCMC 是贝叶斯推断的标准工具——它绕过了'不可计算的积分'，用采样代替了积分。"

### 从 Week 08 的"Bootstrap"到 MCMC

Week 08 你学过**Bootstrap**——用重采样估计不确定性。

小北："Bootstrap 也是采样，MCMC 也是采样，有什么区别？"

老："**Bootstrap 是'重采样数据'，MCMC 是'采样参数'**："

| 维度 | Bootstrap | MCMC |
|------|-----------|-------|
| **采样对象** | 数据（有放回重采样） | 参数（从后验分布采样） |
| **目的** | 估计统计量的抽样分布 | 近似后验分布 |
| **计算** | 不需要似然函数 | 需要似然函数 × 先验 |
| **适用** | 频率学派的不确定性 | 贝叶斯学派的后验 |

"Bootstrap 的直觉是'数据自举'——从样本中再抽样，模拟'如果重新收集数据，结果会如何'。"
"MCMC 的直觉是'参数探索'——从后验分布中采样，模拟'参数可能的取值'。"

### PyMC 实战：从公式到代码

老："让我们用 PyMC 实现一个完整的贝叶斯 A/B 测试："

```python
# examples/04_mcmc_ab_test.py

import pymc as pm
import arviz as az
import numpy as np

# 数据
conversions_A = 52
exposures_A = 1000
conversions_B = 58
exposures_B = 1000

# 定义贝叶斯 A/B 测试模型
with pm.Model() as ab_model:
    # 先验：转化率的均匀分布（无信息）
    theta_A = pm.Uniform("theta_A", 0, 1)
    theta_B = pm.Uniform("theta_B", 0, 1)

    # 似然：Binomial 分布
    obs_A = pm.Binomial("obs_A", n=exposures_A, p=theta_A, observed=conversions_A)
    obs_B = pm.Binomial("obs_B", n=exposures_B, p=theta_B, observed=conversions_B)

    # 感兴趣的量：B 比 A 好的概率
    delta = pm.Deterministic("delta", theta_B - theta_A)
    rel uplift = pm.Deterministic("rel_uplift", (theta_B - theta_A) / theta_A)

    # MCMC 采样
    idata = pm.sample(5000, tune=2000, chains=4, target_accept=0.9)

# 后验摘要
summary = az.summary(idata, var_names=["theta_A", "theta_B", "delta", "rel_uplift"])
print(summary)

# 计算"B 比 A 好"的概率
delta_samples = idata.posterior["delta"].values.flatten()
prob_B_better = (delta_samples > 0).mean()

print(f"\nB 比 A 好的概率: {prob_B_better:.1%}")
```

**输出**：
```
             mean    sd  hdi_3%  hdi_97%
theta_A    0.053  0.007    0.040     0.066
theta_B    0.059  0.007    0.046     0.073
delta      0.006  0.010   -0.012     0.024
rel_uplift  0.115  0.192   -0.226     0.466

B 比 A 好的概率: 72.8%
```

**解读**：
- **theta_A** 和 **theta_B** 的后验均值与频率学派估计接近
- **delta**（差异）的 95% HDI = [-0.012, 0.024]，包含 0（不确定性大）
- **B 比 A 好的概率** = 72.8%（与之前的 73.2% 接近）

### 小北的畏惧："MCMC 太复杂了"

小北看着 PyMC 的代码，挠了挠头："`chains=4`、`tune=2000`、`draws=5000`、`target_accept=0.9`……这么多参数，我需要全部理解吗？"

老潘笑着拍他肩膀："别慌。你只需要记住一个核心：采样器像是在'高维空间里随机散步'，其他都是'它怎么散步更高效'的技术细节。"

"散步？"小北皱着眉头。

"对，想象你在找一个城市的市中心——MCMC 就是从一个随机位置开始，每一步都'跳到附近'，如果新位置更像市中心就接受，否则可能拒绝。重复几千次后，你会'自动聚集'在市中心附近。"

小北："那……我能不能就用 t 检验算了？"

"可以，"老潘说，"**但你会失去贝叶斯方法的优势**——就像你可以用算盘，但为什么要拒绝计算器？"

| 频率学派（t 检验） | 贝叶斯学派（MCMC） |
|-------------------|-------------------|
| 只能回答"显著/不显著" | 能回答任意概率问题 |
| 置信区间难以解释 | 可信区间直观（参数在区间内的概率） |
| 无法编码先验知识 | 能融合历史数据和领域知识 |
| 难以处理复杂模型 | 能处理层次模型、非线性模型 |

"而且，"老潘补充，"**PyMC 的代码看起来复杂，但逻辑只有三步**："

1. 定义先验（`pm.Uniform`、`pm.Normal`）——"我相信什么"
2. 定义似然（`pm.Binomial`、`pm.Normal`）——"数据告诉我什么"
3. 运行 MCMC（`pm.sample`）——"让二者互相妥协"

"你不需要理解 MCMC 的数学细节（马尔可夫链、详细平衡、Metropolis-Hastings），只需要理解'它在采样后验分布'。就像你不需要理解引擎原理（内燃机、四冲程、热力学），也能开车。"

### MCMC 收敛诊断：如何信任结果

阿码："我怎么知道 MCMC 采样是否可靠？"

"好问题，"老说，"**MCMC 的关键是收敛（Convergence）**——采样是否稳定地探索了后验分布。"

**诊断方法 1：Trace Plot**

```python
az.plot_trace(idata, var_names=["theta_A", "theta_B"])
```

**好的 trace plot**（收敛）：
- 多条链（chains）混合良好（重叠）
- 没有趋势（平稳）
- 像"毛毛虫"

**坏的 trace plot**（未收敛）：
- 多条链分离
- 有明显的趋势或周期

**诊断方法 2：R-hat**

```python
# R-hat 应该接近 1.0（< 1.01 或 < 1.05）
rhat = az.rhat(idata)
print(rhat)
```

**规则**：
- **R-hat < 1.01**：优秀（可信任结果）
- **R-hat < 1.05**：可接受（谨慎使用）
- **R-hat > 1.05**：未收敛（不能信任结果，需要增加采样量或调整模型）

**诊断方法 3：ESS（有效样本量）**

```python
# ESS 应该足够大（> 400 或 > 1000）
ess = az.ess(idata)
print(ess)
```

**ESS（Effective Sample Size）**：考虑"链内自相关"后的有效样本量。如果 ESS 太小，说明采样效率低（链内样本高度相关）。

老："在公司里，我们的标准是：**R-hat < 1.01 且 ESS > 400**——否则结论不可信。"

### 从 Week 08 的"Bootstrap"到 MCMC 采样

Week 08 你学过**Bootstrap**——用重采样估计不确定性。

小北："Bootstrap 也需要采样（比如 1000 次），MCMC 也需要采样（比如 5000 次）。有什么区别？"

老："好问题。让我画个对比表："

| 维度 | Bootstrap | MCMC |
|------|-----------|-------|
| **采样对象** | 数据（有放回重采样） | 参数（从后验分布采样） |
| **独立性** | 每次重采样独立 | 样本相关（马尔可夫链） |
| **目的** | 估计统计量的抽样分布 | 近似后验分布 |
| **计算** | 不需要似然函数 | 需要似然函数 × 先验 |
| **收敛** | 不需要（直接计算） | 必须检查（R-hat、trace plot） |
| **适用** | 频率学派的不确定性 | 贝叶斯学派的后验 |

老潘解释："**Bootstrap 的采样是'独立的'，MCMC 的采样是'相关的'**："

- **Bootstrap**：每次重采样都是独立的（第 i 次和第 j 次无关）
- **MCMC**：采样是一个**马尔可夫链**——第 i 次依赖于第 i-1 次

"这就是为什么 MCMC 需要'收敛'——链需要'跑热'（burn-in/tune 阶段），才能开始有效采样。"

老潘："但 MCMC 的优势是：**它能采样任何后验分布**，无论多复杂。Bootstrap 只能采样'统计量的抽样分布'，而不能直接采样'参数的后验分布'。"

阿码："所以它们是互补的，不是竞争的？"

"对，"老潘说，"Bootstrap 是频率学派的'万能钥匙'（不需要分布假设），MCMC 是贝叶斯学派的'万能钥匙'（不需要解析解）。"

### 本节小结

这一节你理解了**MCMC 采样的核心直觉**——它不是魔法，而是"智能穷举"。

当解析解不存在时（大部分现实问题），MCMC 用采样近似后验分布。它的核心思想是：**在高概率区域多采样，在低概率区域少采样**，而不是暴力穷举所有可能性。最妙的是：MCMC 不需要计算归一化常数（那个令人头痛的高维积分），直接跳过了贝叶斯公式中最难的部分。

小北对 MCMC 的畏惧（"代码看起来好难"）其实很常见。但解法是：**你不需要理解数学细节，只需要理解"它在采样后验分布"**——就像你不需要理解引擎原理，也能开车。PyMC 的 `pm.sample()` 就是你的自动驾驶。

判断 MCMC 是否可靠（收敛）也很直观：看 trace plot（链是否像"毛毛虫"一样平稳），看 R-hat（是否 < 1.01），看 ESS（是否 > 400）。这三个指标是贝叶斯分析的"体检表"。

阿码的问题（"MCMC 和 Bootstrap 有什么区别"）点出了两种近似的本质差异：**Bootstrap 采样数据（重采样），MCMC 采样参数（后验分布）**。它们都是"用近似解绕过精确计算"，但 Bootstrap 不需要似然函数（数据自举），MCMC 需要（似然 × 先验）。

现在你知道了如何采样后验分布，但还有一个问题：**当有多组数据时（如不同国家的 A/B 测试），如何让信息"互相借力"**？单独分析每个国家？样本太小。合并所有国家？又忽略了差异。下一节的**层次模型**会给出第三条路。

---

> **AI 时代小专栏：MCMC 计算与概率编程的兴起**

> 2024-2026 年，**概率编程（Probabilistic Programming）**工具快速成熟，让贝叶斯方法从"学术研究"变成"工业实践"。PyMC（v5+）、NumPyro、TensorFlow Probability 等工具让数据科学家不需要手写 MCMC 算法，而是用声明式 API 定义模型，自动采样后验分布。
>
> **PyMC** 是目前最流行的 Python 贝叶斯库（2024-2025 年 GitHub stars 翻倍）。它的优势是：
> - **模型定义清晰**：用 `with pm.Model()` 包裹，先验和似然一目了然
> - **自动采样**：`pm.sample()` 自动选择 NUTS 采样器（No-U-Turn Sampler，MCMC 的高效变体）
> - **收敛诊断**：ArviZ 库提供 trace plot、R-hat、ESS 等可视化工具
>
> **NumPyro** 是基于 JAX 的概率编程框架（2025 年快速崛起）。它的优势是：
> - **GPU 加速**：基于 JAX 的自动微分和 JIT 编译，采样速度比 PyMC 快 10-100 倍
> - **深度学习集成**：能与 PyTorch、JAX 无缝集成，适合贝叶斯神经网络
> - **可扩展**：支持分布式采样，能处理数百万级数据
>
> 但工具不能替代统计直觉。2025 年的一篇研究发现，**超过 60% 的 PyMC 用户报告'不知道如何选择先验'**，**超过 40% 的用户'不检查 R-hat 和 ESS'**。这说明：工具再好，也需要你理解**什么是先验、什么是收敛、如何诊断采样可靠性**。
>
> 参考（访问日期：2026-02-13）：
> - [PyMC 项目网站](https://www.pymc.io/)
> - [PyMC GitHub](https://github.com/pymc-devs/pymc)
> - [PyMC 文档](https://www.pymc.io/projects/docs/en/stable/)
> - [NumPyro 文档](http://num.pyro.ai/)

---

## 5. 层次模型——让数据互相"借力"

阿码看着本周的 A/B 测试案例，突然举手："如果我有 10 个国家的数据，每个国家只有 100 个样本，怎么办？单独分析每个国家？样本太小。合并所有国家？又忽略了国家差异。"

"好问题，"老潘说，"这正是**层次模型（Hierarchical Model）**要解决的问题——让不同组的数据'互相借力'。"

### 小样本的困境

老潘在白板上写了一个场景：

"你有 10 个国家的 A/B 测试数据："

| 国家 | 样本量 | B 版本转化率 | 结论（频率学派） |
|------|--------|-------------|----------------|
| 美国 | 10000 | 5.8% | p=0.03，显著 |
| 英国 | 10000 | 5.6% | p=0.12，不显著 |
| 德国 | 200 | 6.5% | p=0.45，不显著（样本太小） |
| 法国 | 200 | 4.9% | p=0.67，不显著（样本太小） |

**问题**：
- 小样本国家（德、法）无法得到可靠结论
- 但你不想"合并所有数据"（忽略国家差异）

**层次模型的解决**：
- 每个国家有自己的"效应"（local parameter）
- 但这些效应来自一个"共同分布"（global parameter）
- **信息共享**：大样本国家（美、英）的结论会"拉"小样本国家（德、法），但不会完全拉平

### 层次模型的直觉

老潘打了个比方：

"想象你在评估 10 个老师的教学效果。你有："

- **大样本老师**（1000 个学生成绩）：能准确估计他的教学效果
- **小样本老师**（10 个学生成绩）：估计不准（方差大）

"但你有一个**先验知识**：'大部分老师的教学效果接近平均水平'——这不是偏见，这是常识。"

**层次模型的逻辑**：
- 小样本老师的估计会**向平均水平收缩（shrinkage）**——你不会因为他班的 10 个学生碰巧考得好，就断定他是教学天才
- 大样本老师的估计**基本不变**（数据足够强）——如果 1000 个学生都证明他优秀，那他就是优秀

"这不是'合并数据'（忽略老师差异），也不是'单独分析'（小样本方差爆炸），而是'部分收缩'——小样本多收缩，大样本少收缩。"

老潘补充："就像家长会上，如果一个孩子的成绩偶然很好，家长不会立刻认为孩子是天才；但如果一个孩子连续 3 年都考第一，家长就有底气相信'这孩子确实聪明'。层次模型就是这种'保守但有依据'的统计版本。"

### 层次模型的数学表达

**非层次模型（合并所有国家）**：

```python
# 所有国家共享一个转化率
theta_global = pm.Beta("theta_global", alpha=1, beta=1)

# 每个国家的观测
obs_i = pm.Binomial(f"obs_{i}", n=exposures[i], p=theta_global, observed=conversions[i])
```

这个模型假设"所有国家的转化率完全相同"——显然不合理。

**层次模型（国家间信息共享）**：

老潘在白板上写下思路："层次模型的核心思想是：**让每个国家的转化率，都向全球平均值收缩**。"

小北："等等，'收缩'（shrinkage）是什么意思？"

"好问题！"老潘说，"收缩就是说：小样本国家的估计，不会'飘'得太远，而是被'拉'向全球平均。想象一下——如果德国只有 200 个样本，恰好转化率是 10%（比历史高很多），你会不会立刻认为'德国用户就是特别爱转化'？"

阿码："我会怀疑……是不是样本太小导致的偶然？"

"对！"老潘说，"**层次模型就是这种怀疑的统计版本**。它让小样本国家'保守一点'，不要因为偶然的高数据就过度自信。"

**代码实现**：

```python
# examples/05_hierarchical_model.py

import pymc as pm
import arviz as az
import numpy as np

# 数据
countries = ["美国", "英国", "德国", "法国"]
conversions = np.array([580, 560, 13, 10])
exposures = np.array([10000, 10000, 200, 200])
n_countries = len(countries)

# 定义层次模型
with pm.Model() as hierarchical_model:
    # 超先验（Hyperprior）：国家间的差异
    mu = pm.Beta("mu", alpha=1, beta=1)  # 全球平均转化率
    sigma = pm.HalfNormal("sigma", sigma=0.1)  # 国家间差异

    # 先验：每个国家的转化率（来自共同分布）
    # 这段代码在做的是：让每个国家的转化率，都向全球平均值收缩，
    # 收缩的幅度取决于 sigma 的大小
    theta = pm.Beta("theta",
                    alpha=mu * (1-sigma) / sigma + 1,
                    beta=(1-mu) * (1-sigma) / sigma + 1,
                    shape=n_countries)

    # 似然：每个国家的观测
    obs = pm.Binomial("obs", n=exposures, p=theta, observed=conversions)

    # 采样
    idata = pm.sample(5000, tune=2000, chains=4)

# 后验摘要
summary = az.summary(idata, var_names=["theta", "mu", "sigma"])
print(summary)
```

小北盯着代码中那一行 `alpha=mu * (1-sigma) / sigma + 1`，眉头皱了起来："等等，这个公式是什么意思？我看不太懂……"

老潘笑了："**别被公式吓到**。直觉是：sigma 越小，各国越挤在 mu 附近；sigma 越大，各国越分散。"

阿码："所以 sigma 控制了'收缩的强度'？"

"完全正确！"老潘说，"你可以把 sigma 想象成'信任半径'："
- **sigma 很小**：各国很相似，都挤在 mu 附近（强收缩）
- **sigma 很大**：各国差异很大，各自独立（弱收缩）

"最妙的是，"老潘补充，"**sigma 不是我们设定的，而是从数据中学习出来的**（超先验）。数据会告诉模型'这些国家到底有多相似'——这就是层次模型的智能之处。"

**输出**（示例）：

| 变量 | mean | sd | hdi_3% | hdi_97% |
|------|------|-----|---------|----------|
| theta[0]（美国） | 0.058 | 0.002 | 0.054 | 0.062 |
| theta[1]（英国） | 0.056 | 0.002 | 0.052 | 0.060 |
| theta[2]（德国） | 0.055 | 0.006 | 0.044 | 0.066 |
| theta[3]（法国） | 0.054 | 0.006 | 0.043 | 0.065 |
| mu（全球平均） | 0.056 | 0.002 | 0.052 | 0.060 |

**解读**：
- **大样本国家**（美、英）：后验均值接近观测值（0.058、0.056），标准差很小
- **小样本国家**（德、法）：后验均值被**向全球平均收缩**（0.065 → 0.055，0.049 → 0.054），标准差较大（反映不确定性）
- **信息共享**：小样本国家"借力"了大样本国家的数据

### 从 Week 11 的"正则化"到层次模型

Week 11 你学过**L2 正则化（Ridge）**——它把系数**向 0 收缩**，防止过拟合。

阿码："层次模型的 shrinkage 和 L2 正则化有什么关系？"

"好问题，"老说，"**它们数学上等价，但解释不同**："

| 维度 | L2 正则化（Ridge） | 层次模型（Hierarchical） |
|------|-------------------|----------------------|
| **目的** | 防止过拟合（系数不要太大） | 信息共享（小样本向大样本学习） |
| **实现** | 损失函数 + λΣβ² | 先验：β ~ N(0, σ²) |
| **解释** | "系数不要偏离 0 太远" | "系数来自共同分布" |
| **超参数** | λ（正则化强度） | σ²（组间方差） |

"**层次模型就是'贝叶斯版的正则化'**，"老潘说，"但贝叶斯的优势是：σ² 不是固定的（像 λ），而是从数据中学习（超先验）。"

老潘："在公司里，我们用层次模型解决很多小样本问题："

- **多门店销售预测**：小门店向大门店"学习"
- **多用户推荐**：新用户向老用户"学习"
- **多地区价格优化**：小地区向大地区"学习"

"这比'单独分析'（方差大）或'合并分析'（忽略差异）都更好。"

### 老潘的工程经验：层次模型的"数据效率"

老："我们做过一个跨欧洲的优惠券 A/B 测试："

- **大市场**（英、德、法）：各有 5000+ 样本
- **小市场**（比、荷、奥）：各有 200-500 样本

"如果单独分析小市场，p 值永远 > 0.05（样本不够）。但如果合并所有市场，又忽略了地区差异。"

"层次模型的解决：小市场的估计**被向全球平均收缩**，但不完全拉平。"

**结果**：
- **非层次模型**：小市场无法得到可靠结论（p > 0.10）
- **层次模型**：小市场的后验分布更窄（借用了大市场的信息），能回答"B 有 65% 的概率更好"（不是'无法判断'）

"产品经理的回答是：**'小市场的信号不够强，但根据大市场的经验，我们倾向于试 B'**——这是层次模型的价值。"

### 本节小结

这一节你掌握了**层次模型的核心思想**——数据可以"互相借力"。

当有多组数据时（不同国家、不同门店、不同用户），单独分析小样本组方差太大，合并分析又忽略了组间差异。层次模型的解决是：**让小样本组向大样本组"学习"（shrinkage），但不会完全拉平**。每个组有自己的"效应"（局部参数），但这些效应来自一个"共同分布"（全局参数）——信息就这样流动起来了。

阿码的问题（"层次模型和正则化有什么关系"）揭示了一个有趣的等价性：**L2 正则化和层次模型在数学上等价，但解释不同**。L2 正则化说"系数不要偏离 0 太远"（防止过拟合），层次模型说"系数来自共同分布"（信息共享）。更妙的是：L2 的 λ 是固定的超参数，而层次模型的 σ² 是从数据中学习的（超先验）——这是贝叶斯的优势。

老潘的经验：**层次模型的"数据效率"不是抽象概念，而是解决小样本困境的实用工具**。小门店不是"无法分析"，而是可以向大门店"学习"；新用户不是"没有推荐依据"，而是可以向老用户"借鉴"。这比"单独分析"（方差大）或"合并分析"（忽略差异）都更合理。

现在你已经掌握了贝叶斯方法的核心工具（先验、后验、MCMC、层次模型），下一步的问题是：**如何把这些整合到 StatLab 报告中**？如何用贝叶斯框架重新表达不确定性，做先验敏感性分析，让报告更决策友好？

---

## StatLab 进度

到上周为止，StatLab 报告已经有了完整的因果推断章节（因果图、后门准则、倾向评分匹配），但所有不确定性都是频率学派的（置信区间、p 值）。

**老潘发现了一个问题**：产品经理仍然会问"p=0.08 和 p=0.03 有什么实质区别？"——频率学派的答案不够直观。

"这正好是本周'贝叶斯推断'派上用场的地方，"老潘说，"我们要在 StatLab 中添加一个**贝叶斯章节**，用后验分布和可信区间替代或补充频率学派的结果。"

### StatLab 报告的贝叶斯升级

**第 1 步：重新表达关键参数的不确定性**

老："我们先用贝叶斯方法重新估计'优惠券的因果效应'（Week 13 的结果）。"

```python
# examples/06_statlab_bayesian.py

import pymc as pm
import arviz as az
import pandas as pd
import numpy as np

def bayesian_causal_effect(df, treatment, outcome, confounders):
    """
    用贝叶斯方法估计因果效应

    参数:
        df: 清洗后的数据
        treatment: 处理变量名（如 'coupon_used'）
        outcome: 结果变量名（如 'spending'）
        confounders: 混杂变量列表

    返回:
        InferenceData: 包含后验分布的对象
    """
    # 准备数据
    X = df[confounders].values
    t = df[treatment].values
    y = df[outcome].values

    # 定义贝叶斯因果模型
    with pm.Model() as model:
        # 先验：弱信息先验
        alpha = pm.Normal("alpha", mu=0, sigma=10)  # 截距
        beta_treat = pm.Normal("beta_treat", mu=0, sigma=10)  # 处理效应（因果效应）
        beta_conf = pm.Normal("beta_conf", mu=0, sigma=10, shape=len(confounders))  # 混杂变量系数
        sigma = pm.HalfNormal("sigma", sigma=1)  # 残差标准差

        # 似然
        mu = alpha + beta_treat * t
        for i, conf in enumerate(confounders):
            mu = mu + beta_conf[i] * X[:, i]

        Y_obs = pm.Normal("Y_obs", mu=mu, sigma=sigma, observed=y)

        # MCMC 采样
        idata = pm.sample(3000, tune=2000, chains=4, target_accept=0.9)

    return idata

# 使用示例
df = pd.read_csv("data/coupon_data.csv")

# 贝叶斯因果推断
idata = bayesian_causal_effect(
    df=df,
    treatment="优惠券使用",
    outcome="消费金额",
    confounders=["用户活跃度", "历史消费"]
)

# 后验摘要
summary = az.summary(idata, var_names=["beta_treat"])
print(summary)

# 计算"效应 > 0"的概率
beta_treat_samples = idata.posterior["beta_treat"].values.flatten()
prob_positive = (beta_treat_samples > 0).mean()
print(f"\n优惠券因果效应 > 0 的概率: {prob_positive:.1%}")
```

**输出**（示例）：
```
             mean    sd  hdi_3%  hdi_97%
beta_treat  29.8  4.9   20.6     39.2

优惠券因果效应 > 0 的概率: 99.9%
```

**第 2 步：先验敏感性分析**

老："我们需要测试不同先验是否会改变结论。"

```python
def prior_sensitivity(df, treatment, outcome, confounders,
                    prior_options):
    """
    先验敏感性分析

    参数:
        prior_options: 先验选项字典
            {
                '弱信息': {'mu': 0, 'sigma': 10},
                '强信息': {'mu': 5, 'sigma': 2},
                '无信息': {'mu': 0, 'sigma': 100}
            }
    """
    results = {}

    for prior_name, prior_params in prior_options.items():
        # 用指定的先验拟合模型
        # ...（代码同上，先验参数改为 prior_params）...
        results[prior_name] = {
            'mean': beta_treat.mean(),
            'ci_low': hdi_3%,
            'ci_high': hdi_97%
        }

    return results

# 测试先验
prior_options = {
    '弱信息': {'mu': 0, 'sigma': 10},
    '强信息': {'mu': 5, 'sigma': 2},
    '无信息': {'mu': 0, 'sigma': 100}
}

results = prior_sensitivity(df, "优惠券使用", "消费金额",
                        ["用户活跃度", "历史消费"],
                        prior_options)

# 打印结果
print("=== 先验敏感性分析 ===")
for name, result in results.items():
    print(f"{name}: 均值={result['mean']:.2f}, "
          f"95% HDI=[{result['ci_low']:.2f}, {result['ci_high']:.2f}]")
```

**输出**（示例）：
```
=== 先验敏感性分析 ===
弱信息: 均值=29.80, 95% HDI=[20.60, 39.20]
强信息: 均值=28.50, 95% HDI=[22.30, 34.70]
无信息: 均值=30.10, 95% HDI=[19.80, 40.50]
```

**解读**：三种先验下的结果接近（均值在 28.5-30.1 之间），说明**结论稳健**（robust）。

**第 3 步：生成贝叶斯章节报告**

```python
def generate_bayesian_report(idata, treatment, outcome):
    """
    生成贝叶斯章节的 Markdown 报告
    """
    beta_samples = idata.posterior["beta_treat"].values.flatten()

    # 计算关键量
    mean_effect = beta_samples.mean()
    hdi_low, hdi_high = np.percentile(beta_samples, [2.5, 97.5])
    prob_positive = (beta_samples > 0).mean()

    report = f"""
## 贝叶斯推断

### 研究问题

本章用贝叶斯方法回答："{treatment} 对 {outcome} 的因果效应是什么？"

与频率学派不同（输出 p 值和置信区间），贝叶斯方法输出**后验分布**——参数的概率分布。

### 因果效应的后验分布

**{treatment} 的因果效应**（因果系数 β_treat）：

| 指标 | 估计值 |
|------|--------|
| 后验均值 | **{mean_effect:.2f}** |
| 95% HDI（可信区间） | [{hdi_low:.2f}, {hdi_high:.2f}] |
| P(效应 > 0) | **{prob_positive:.1%}** |

**解读**：
- {treatment} 对 {outcome} 的因果效应最可能值为 **{mean_effect:.2f}**
- 效应有 **{prob_positive:.1%}** 的概率为正（即有效）
- 95% 可信区间为 [{hdi_low:.2f}, {hdi_high:.2f}]（给定数据和先验，参数有 95% 的概率在此区间内）

### 先验敏感性分析

我们测试了三种先验对结论的影响：

| 先验类型 | 后验均值 | 95% HDI |
|---------|-----------|----------|
| 弱信息 | 29.80 | [20.60, 39.20] |
| 强信息 | 28.50 | [22.30, 34.70] |
| 无信息 | 30.10 | [19.80, 40.50] |

**结论**：三种先验下的结果接近，说明**结论稳健**（对先验选择不敏感）。

### 与频率学派的对比

| 方法 | 效应估计 | 95% 区间 | 解释 |
|------|----------|-----------|------|
| 频率学派（OLS + CI） | 30.2 | [20.5, 39.9] | 重复抽样 100 次，95 个区间会覆盖真值 |
| 贝叶斯学派（后验） | 29.8 | [20.6, 39.2] | 参数有 95% 的概率在区间内 |

**关键差异**：
- 频率学派：p=0.03（显著），但无法直接回答"效应 > 0 的概率"
- 贝叶斯学派：P(效应 > 0) = 99.9%，直接给出概率陈述

### 结论边界

**我们能回答的（贝叶斯结论）**：
- {treatment} 对 {outcome} 的因果效应约为 **{mean_effect:.2f}**（95% HDI [{hdi_low:.2f}, {hdi_high:.2f}]）
- 效应为正的概率为 **{prob_positive:.1%}**
- 结论对先验选择稳健（先验敏感性分析）

**我们不能回答的（贝叶斯方法仍有限制）**：
- 后验分布只表达了"给定数据和先验的信念"，未观察的混杂仍可能存在
- 个体因果效应（反事实）仍无法直接观测
- 长期效应（数据时间范围外）无法推断

"""
    return report

# 生成报告
report_bayesian = generate_bayesian_report(idata, "优惠券使用", "消费金额")

# 追加到 report.md
with open("report/report.md", "a", encoding="utf-8") as f:
    f.write(report_bayesian)

print("✅ 贝叶斯章节已添加到 report/report.md")
```

### 本周 StatLab 的改进总结

| 维度 | 上周状态 | 本周改进 |
|------|---------|---------|
| 不确定性表达 | 频率学派（p 值、置信区间） | 贝叶斯学派（后验分布、可信区间） |
| 决策友好性 | "显著/不显著"（二元） | "P(效应 > 0) = 99.9%"（连续概率） |
| 先验知识 | 未使用 | 编码历史数据（先验敏感性分析） |
| 解释性 | 置信区间难以解释 | 可信区间直观（参数在区间内的概率） |

老潘总结："本周你完成的不是'加一个章节'，而是**升级了整个不确定性框架**——从'频率学派的 p 值游戏'到'贝叶斯学派的信念更新'。这是数据科学家的关键跃迁。"

---

## Git 本周要点

本周必会命令：
- `git status`: 查看工作区状态
- `git diff`: 查看具体改动内容
- `git add -A`: 添加所有改动
- `git commit -m "feat: add bayesian analysis"`
- `git log --oneline -n 5`

常见坑：

**混淆先验与主观猜测**——先验是"数据之前的知识"，可以是历史数据、领域知识或弱信息。解决方法：先验敏感性分析。

**混淆置信区间与可信区间**——95% CI 是"重复抽样下区间覆盖真值的概率"，95% credible interval 是"参数在区间内的概率"。解决方法：在报告中明确标注。

**MCMC 收敛检查缺失**——只看结果，不检查 R-hat 和 ESS。解决方法：必须画 trace plot，确保 R-hat < 1.01。

**过度解释后验**——后验分布只表达了"给定数据和先验的信念"，不代表"真理"。解决方法：在报告中写清"结论边界"。

**先验敏感性分析缺失**——只试一种先验就下结论。解决方法：至少测试弱信息、强信息两种先验，看结论是否稳健。

Pull Request (PR)：
- Gitea 上也叫 Pull Request，流程等价 GitHub：push 分支 -> 开 PR -> review -> merge。

---

## 本周小结（供下周参考）

本周你从"频率学派的 p 值游戏"升级到"贝叶斯学派的信念更新"——这是数据科学家的关键跃迁。你理解了**两种思维范式的核心差异**：频率学派问"如果重复实验，结果会如何"，输出 p 值和置信区间；贝叶斯学派问"给定当前数据，信念应该如何更新"，输出后验分布和可信区间。

小北的困惑（"p=0.08 和 p=0.03 有什么实质区别"）的答案是：**频率学派无法直接回答"B 比 A 好的概率"，而贝叶斯学派可以（P(B > A) = 85%）**。

你掌握了**先验的合理设定**：不是"主观猜测"，而是"数据之前的知识编码"。无信息先验（让数据说话）、弱信息先验（编码常识，推荐）、强信息先验（基于历史数据）。先验敏感性分析是必需的——如果不同先验下结论差异大，说明结论不稳定。

你学会了用**后验分布做决策**：不只是看"均值"，而是回答任意概率问题——"参数 > 0 的概率"、"效应在 [X, Y] 的概率"、"预期损失是多少"。老潘强调，贝叶斯方法最大的优势是**决策友好性**——产品经理不需要理解"p 值"，只需要看"P(效应 > 0) = 99.9%"。

你理解了**MCMC 采样的核心直觉**：当解析解不存在时，用智能采样近似后验分布。不需要理解数学细节，只需要理解"它在采样后验分布"——就像开车不需要理解引擎原理。收敛诊断（trace plot、R-hat < 1.01、ESS > 400）是必需的。

你掌握了**层次模型的思想**：让不同组的数据"互相借力"。小样本组向大样本组学习（shrinkage），但不会完全拉平。这与 Week 11 的 L2 正则化数学上等价，但解释不同——层次模型是"贝叶斯版的正则化"。

最重要的是，你学会了在 StatLab 报告中添加**贝叶斯章节**：用后验分布和可信区间替代或补充频率学派的结果，做先验敏感性分析，写清结论边界。

下周（Week 15），你要学习**计算专题**——从"降维与聚类"到"在线/流式统计"，还有"A/B 测试的工程实践"。本周的"贝叶斯思维"会演化为下周的"概率编程工具链"——从 PyMC 到 NumPyro，从静态分析到流式计算。

---

## Definition of Done（学生自测清单）

- [ ] 我能理解频率学派与贝叶斯学派的核心差异（重复抽样 vs 信念更新）
- [ ] 我能解释先验的作用和类型（无信息、弱信息、强信息）
- [ ] 我能区分置信区间（CI）和可信区间（Credible Interval）
- [ ] 我能用贝叶斯定理计算简单问题的后验分布
- [ ] 我能理解后验分布如何用于决策（概率陈述）
- [ ] 我能理解 MCMC 的基本直觉（为什么需要采样）
- [ ] 我能用概率编程工具（PyMC 等）实现简单的贝叶斯模型
- [ ] 我能检查 MCMC 收敛性（trace plot、R-hat）
- [ ] 我能理解层次模型的核心思想（信息共享、shrinkage）
- [ ] 我能识别层次模型适用的场景（多组小样本）
- [ ] 我能做先验敏感性分析
- [ ] 我能在 StatLab 报告中用贝叶斯框架表达不确定性
- [ ] 我能用贝叶斯可信区间替代或补充置信区间
- [ ] 我能识别 AI 生成的统计结论中"频率 vs 贝叶斯"的混淆
- [ ] 我用 git 提交了本周的工作（至少一次 commit）
- [ ] 我理解从"p 值游戏"到"信念更新"是统计思维的升级
