# Week 01 作业

> **提交前自查**：你的代码能运行吗？你的报告能重新生成吗？如果你现在把代码发给同学，他能得到完全相同的结果吗？

---

## 基础练习（必做，60 分）

### 练习 1：用"统计三问"识别分析目标（20 分）

选择一个你感兴趣的真实数据集（可以是教材示例数据、工作中的数据，或公开数据集如 Titanic、Housing Prices 等），回答以下问题：

1. **描述（Description）**：列出 3 个你想了解的"数据长什么样"的问题。例如：平均值是多少？分布如何？哪些变量有缺失？
2. **推断（Inference）**：列出 1 个你想回答的"从样本到总体"的问题。例如：两组之间的差异是真实存在的，还是抽样造成的偶然？
3. **预测（Prediction）**：列出 1 个你想做的"给定特征，猜目标"的问题。例如：给定某些特征，能不能预测某个结果？

**输入**：
- 任何结构化数据集（CSV、Excel、数据库导出等）

**输出**：
- 一个 Markdown 文件（`questions.md`），包含：
  - 数据集名称和来源
  - 3 个描述性问题
  - 1 个推断性问题
  - 1 个预测性问题

**评分点**：
- [ ] 描述性问题关注"数据本身的样子"（均值、分布、缺失等），不涉及推断到总体
- [ ] 推断性问题明确提到"样本与总体"或"差异是否真实"
- [ ] 预测性问题有明确的输入特征和输出目标
- [ ] 每个问题具体、可回答，不模糊

**常见错误**：
- ❌ 描述性问题写成"某因素是否影响某结果"（这是推断）
- ❌ 预测性问题没有明确输入输出（例如："预测数据"太宽泛）
- ❌ 三类问题混淆（例如把推断写成预测）

---

### 练习 2：数据类型判断（20 分）

对你选择的数据集，逐列判断数据类型。创建一个表格，包含以下列：

| 字段名 | pandas 推断类型 | 统计学类型 | 连续/离散 | 名义/有序 |
|--------|----------------|-----------|----------|----------|
| ...    | ...            | ...       | ...      | ...      |

**要求**：
- "pandas 推断类型"：运行 `df.dtypes` 得到的类型（如 `int64`、`object`、`float64`）
- "统计学类型"：数值型（numeric）或分类型（categorical）
- "连续/离散"：仅数值型需要填写
- "名义/有序"：仅分类型需要填写

**评分点**：
- [ ] 正确区分数值型和分类型（例如：邮政编码是分类型，不是数值型）
- [ ] 连续/离散判断准确（可测量的量是连续，计数是离散）
- [ ] 名义/有序判断准确（有顺序差异的是有序）

**常见错误**：
- ❌ 把"看起来像数字"的分类变量当成数值型（如 ID、邮编、电话号码）
- ❌ 忽略 pandas 的 `object` 类型通常是分类型
- ❌ 混淆"离散数值"和"名义分类"（孩子数量是离散数值，不是分类）

---

### 练习 3：用 pandas 读取数据并生成数据卡（20 分）

编写一个 Python 脚本，完成以下任务：

1. **读取数据**：使用 pandas 或 seaborn 读取数据集
2. **生成数据卡**：编写一个函数 `generate_data_card(df, metadata)`，生成包含以下内容的 Markdown 格式数据卡：
   - 数据来源（数据集名称、来源、描述、收集时间等）
   - 字段字典（字段名、数据类型、缺失率）
   - 规模概览（行数、列数）
   - 缺失概览（哪些字段有缺失、缺失数量和比例）

3. **写入文件**：将数据卡保存为 `data_card.md`

**输入示例**：
```python
import seaborn as sns

penguins = sns.load_dataset("penguins")
metadata = {
    "数据集名称": "Palmer Penguins",
    "来源": "seaborn 内置数据集",
    "描述": "南极 Palmer Station 的三种企鹅的形态测量数据"
}
```

**输出示例**（`data_card.md` 的内容片段）：
```markdown
# 数据卡（Data Card）

## 数据来源
- **数据集名称**：Palmer Penguins
- **来源**：seaborn 内置数据集
...

## 字段字典
| 字段名 | 数据类型 | 缺失率 |
|--------|---------|--------|
| species | object | 0.0% |
| bill_length_mm | float64 | 2.4% |
...
```

**评分点**：
- [ ] 代码能成功读取数据并打印 `shape` 和 `dtypes`
- [ ] `generate_data_card` 函数正确生成 Markdown 格式字符串
- [ ] 缺失率计算正确（`缺失数 / 总行数 * 100`）
- [ ] 生成的 `data_card.md` 文件内容完整、格式正确

**常见错误**：
- ❌ 路径写死（如 `pd.read_csv("C:/Users/xxx/data.csv")`）
- ❌ 缺失率计算错误（例如没乘 100 或没用 `round()`）
- ❌ 生成的 Markdown 格式错误（表格对齐问题、换行问题）
- ❌ 没有实际写入文件，只是 `print()` 到控制台

---

## 进阶练习（选做，30 分）

### 练习 4：完善的数据卡生成器（15 分）

在基础练习的数据卡基础上，增加以下功能：

1. **自动推断统计学类型**：编写一个函数，根据 pandas 类型和唯一值数量，自动判断每列是"数值型-连续"、"数值型-离散"、"分类型-名义"或"分类型-有序"

2. **基本描述统计**：对数值型字段，增加一列显示均值、中位数、标准差

3. **分类值概览**：对分类型字段，增加一列显示唯一值数量和最常见的 3 个值

**输出示例**：
```markdown
## 字段字典（增强版）
| 字段名 | 统计学类型 | 缺失率 | 均值±标准差 / 常见值 |
|--------|-----------|--------|---------------------|
| bill_length_mm | 数值型-连续 | 2.4% | 43.9 ± 5.5 |
| species | 分类型-名义 | 0.0% | Adelie(152), Gentoo(124), Chinstrap(68) |
```

**评分点**：
- [ ] 类型推断逻辑合理（例如：唯一值少于 10 且非数值型 → 分类型）
- [ ] 数值型字段的描述统计计算正确
- [ ] 分类型字段的最常见值统计正确
- [ ] 代码结构清晰，有适当的函数拆分

**提示**：
- 可以用 `df[col].nunique()` 判断唯一值数量
- 可以用 `pd.api.types.is_numeric_dtype(df[col])` 判断是否为数值型
- 分类型的"常见值"可以用 `value_counts().head(3)` 获取

---

### 练习 5：处理"有坑"的数据集（15 分）

找一个真实数据集，它可能包含以下问题之一：

1. **编码问题**：文件不是 UTF-8 编码，读取时报错
2. **类型推断错误**：pandas 自动推断的类型不符合统计学含义（如邮编被当成整数）
3. **日期问题**：日期列被当成字符串，需要解析

你的任务是：写一个脚本，正确读取数据并解决这些问题，生成数据卡。

**评分点**：
- [ ] 正确识别并解决编码问题（尝试 `encoding="gbk"`、`encoding="gb18030"` 等）
- [ ] 正确识别并修正类型推断错误（使用 `astype()` 或 `read_csv` 的 `dtype` 参数）
- [ ] 正确解析日期列（使用 `parse_dates` 参数）
- [ ] 在数据卡中记录"遇到的问题和解决方案"

**常见错误**：
- ❌ 遇到编码错误就换数据集，而不是尝试不同编码
- ❌ 类型转换错误（例如把分类型强制转成数值型）
- ❌ 日期解析失败但没处理，导致后续分析有问题

---

## 挑战练习（选做，10 分）

### 练习 6：自动化数据卡生成器（可扩展）

设计一个更通用的数据卡生成工具类 `DataCardGenerator`，支持以下功能：

1. **自定义元数据模板**：允许用户传入自定义的元数据字段（如许可证、用途、限制等）
2. **可配置的统计量**：允许用户选择要计算哪些统计量（如偏度、峰度、分位数等）
3. **自动检测并标记潜在问题**：
   - 缺失率超过 30% 的列标红
   - 唯一值等于行数的列（可能是 ID）标记
   - 数值型字段但方差接近 0 的列（可能是常量）标记

**输出**：
- 一个可复用的 Python 模块（`data_card_generator.py`）
- 一个使用示例脚本，演示如何用这个工具类生成数据卡

**评分点**：
- [ ] 代码结构合理，使用类（class）封装
- [ ] 配置灵活，易于扩展新功能
- [ ] 潜在问题检测逻辑合理
- [ ] 有适当的文档字符串和注释

**提示**：
- 可以用 `dataclasses` 或 `pydantic` 定义配置
- 可以考虑支持导出多种格式（Markdown、JSON、HTML）

---

## AI 协作练习（可选）

本周暂无 AI 协作练习。

从 Week 05 开始，我们会逐步引入 AI 审查练习，教你如何评估 AI 生成的统计分析结论是否可靠。在此之前，先建立自己的统计直觉。

---

## 提交要求

### 必交内容（基础练习）

1. **`questions.md`**：统计三问分析
2. **`data_types.md`**：数据类型判断表格
3. **`data_card.md`**：生成的数据卡
4. **`generate_data_card.py`**：生成数据卡的 Python 脚本

### 选交内容（进阶/挑战练习）

5. **`enhanced_data_card.py`**：完善的数据卡生成器（练习 4）
6. **`robust_reader.py`**：处理有坑数据集的脚本（练习 5）
7. **`data_card_generator.py`**：自动化工具类（练习 6）

### 代码质量要求

- [ ] 代码能从头到尾运行，不报错
- [ ] 有适当的注释，关键步骤有说明
- [ ] 变量命名清晰，不使用 `a`、`b`、`tmp` 这类无意义名称
- [ ] 没有硬编码的绝对路径（如 `/Users/xxx/Desktop/data.csv` 或 `C:\Users\xxx\Desktop\data.csv`）

### 可复现性要求

- [ ] 如果使用本地数据集，说明数据来源和获取方式
- [ ] 如果使用随机操作（如采样），设置随机种子（`np.random.seed(42)`）
- [ ] 附上一份 `README.md`，说明如何运行你的代码

---

## 需要帮助？

如果你遇到困难，可以参考 `starter_code/solution.py` 中的参考实现。但请先自己尝试，再去看答案——直接复制无法建立真正的理解。

常见问题：

**Q: 我应该选什么数据集？**
A: 建议先用教材示例数据（Palmer Penguins）练习，熟悉流程后再换自己的数据。可以从 seaborn 内置数据集开始：`sns.load_dataset("penguins")`、`sns.load_dataset("tips")`、`sns.load_dataset("titanic")`。

**Q: 我的代码运行报错，怎么办？**
A: 先检查：
1. 文件路径是否正确（用相对路径，不要写死绝对路径）
2. 编码是否正确（试试 `encoding="utf-8"`、`encoding="gbk"`）
3. 数据是否真的存在（打印 `os.path.exists("your_file.csv")` 检查）

**Q: 我需要做可视化吗？**
A: 本周重点不在可视化，先把数据卡做好。可视化是 Week 02 的内容。如果时间充裕，可以尝试画一两个简单的图（如 `df["column"].hist()`），但这不是必须的。

**Q: 我可以使用 AI 工具吗？**
A: 本周建议先自己动手。AI 可以帮你解释概念、调试代码，但不要直接让 AI 生成整个解决方案——你跳过了"挣扎"的过程，也就跳过了真正的学习。

---

## 评分说明

- **基础练习 60 分**：必须完成，每题 20 分
- **进阶练习 30 分**：选做，每题 15 分
- **挑战练习 10 分**：选做

总分不超过 100 分。完成基础练习即可获得 60 分，达到合格线。

详细评分标准见 `RUBRIC.md`。
