# Week 01 作业：给你的数据办一张"身份证"

> "先问问题，再找答案。" —— 这是统计思维的起点。

本周作业的核心是：**不要急着算均值、画图、跑模型，先停下来，把"这份数据是什么"搞清楚。**

你需要为自己选择的一个数据集创建一份完整的**数据卡**（Data Card）。这份数据卡会是你整个 StatLab 项目的起点——没有它，任何后续分析都缺乏"审计地基"。

---

## 基础层（必做，60 分）

### 任务 1：回答"统计三问"（15 分）

选择一个你感兴趣的数据集（可以是公开数据集、工作中的数据，或者教材示例数据），然后写一段 3-5 句话的回答：

**你用这份数据想回答什么类型的问题？**

- **描述（Description）**：说明数据本身的特点（如"这批用户的平均消费是多少"）
- **推断（Inference）**：从样本推断总体（如"基于这批用户，我们能否推断整体用户的消费水平"）
- **预测（Prediction）**：对未来或未见样本做判断（如"预测一个新用户是否会购买"）

**要求**：
1. 明确指出你的分析属于上述哪一类（或哪几类）
2. 用你自己的话解释为什么属于这一类
3. 给出 1-2 个具体的研究问题示例

**输入示例**：
```
数据集：电商用户行为数据
我的分析类型：描述（Description）
理由：我只想了解这批用户的基本特征，不打算推断到整体用户，也不做预测。
研究问题示例：
1. 这批用户的平均年龄是多少？年龄分布是什么样的？
2. 不同城市的用户消费水平有差异吗？
```

**输出**：
- 一段 3-5 句话的文字说明（Markdown 格式）
- 保存在你的项目目录下，命名为 `questions.md`

**评分点**：
- ✅ 准确识别分析类型（5 分）
- ✅ 理由清晰合理（5 分）
- ✅ 给出具体的研究问题示例（5 分）

---

### 任务 2：识别数据类型（15 分）

列出你选择的数据集中的所有列，并标注每一列的数据类型。

**要求**：
为每个列标注以下两类信息：

1. **统计类型**：
   - 数值型（Numeric）
   - 分类型（Categorical）

2. **细分类型**（如适用）：
   - 连续（Continuous）或 离散（Discrete）
   - 有序（Ordinal）或 无序（Nominal）

**输入示例**：

| 列名 | 统计类型 | 细分类型 | 为什么 |
|------|----------|----------|--------|
| age | 数值型 | 离散 | 年龄是整数，虽然可以有小数但通常按整数记录 |
| income | 数值型 | 连续 | 收入可以是任意小数值 |
| gender | 分类型 | 无序 | 男/女/未知，没有顺序关系 |
| rating | 分类型 | 有序 | 1-5 星评分，有明确的"大于/小于"关系 |

**输出**：
- 一个 Markdown 表格（如上所示）
- 保存在 `data_types.md`

**评分点**：
- ✅ 正确区分数值型 vs 分类型（6 分）
- ✅ 正确区分连续 vs 离散、有序 vs 无序（6 分）
- ✅ "为什么"一列的说明合理（3 分）

**常见错误**：
- ❌ 把邮政编码、ID 类列当成连续数值
- ❌ 把只有 1-2 个取值的离散数值（如孩子数量）当成连续型
- ❌ 忘记说明"为什么"

---

### 任务 3：用 pandas 加载和初步探索（30 分）

编写一个 Python 脚本，完成以下任务：

1. **加载数据**：用 pandas 读取你的数据集（CSV/Excel/JSON 均可）
2. **查看基本信息**：
   - 打印数据形状（`df.shape`）
   - 打印前 5 行（`df.head()`）
   - 打印各列数据类型（`df.dtypes`）
3. **基本统计摘要**：
   - 对数值列调用 `df.describe()`
   - 对分类列调用 `df.describe(include=['O'])` 或 `value_counts()`

**代码框架提示**（仅供参考，需要根据你的数据集修改）：

```python
import pandas as pd

# 1. 加载数据
df = pd.read_csv("your_data.csv")  # 替换成你的文件路径

# 2. 查看基本信息
print("数据形状：", df.shape)
print("\n前 5 行：")
print(df.head())
print("\n列名和数据类型：")
print(df.dtypes)

# 3. 基本统计摘要
print("\n数值列统计摘要：")
print(df.describe())

print("\n分类列统计摘要：")
for col in df.select_dtypes(include=['object']).columns:
    print(f"\n{col} 的值计数：")
    print(df[col].value_counts())
```

**输出**：
- 一个可运行的 Python 脚本 `explore.py`
- 运行脚本的输出结果保存在 `explore_output.txt`

**评分点**：
- ✅ 代码能成功加载你的数据集（10 分）
- ✅ 正确使用 pandas 方法查看基本信息（10 分）
- ✅ 对数值列和分类列分别做合适的探索（10 分）

**常见错误**：
- ❌ 文件路径错误（相对路径 vs 绝对路径）
- ❌ 编码问题（中文乱码）—— 尝试 `encoding='utf-8'` 或 `encoding='gbk'`
- ❌ 对分类列调用 `describe()` 后没有进一步用 `value_counts()` 查看具体分布

---

## 进阶层（可选，+30 分）

### 任务 4：创建完整的数据卡（30 分）

基于前面三个任务的成果，为你的数据集创建一份完整的数据卡（Data Card）。

你可以参考教材中的 `examples/04_data_card.py`，但**不要直接复制粘贴**——你需要根据自己数据集的特点调整内容。

**你的数据卡必须包含以下部分**：

1. **数据来源**：数据从哪来？采集时间是什么？
2. **数据描述**：这份数据是关于什么的？覆盖了哪些方面？
3. **统计三问**：你的分析类型是什么？为什么？
4. **样本规模**：行数、列数
5. **时间范围**：数据覆盖的时间段（如适用）
6. **字段字典**：每一列的
   - 数据类型
   - 业务含义
   - 缺失率
   - 示例值（可选）
7. **缺失概览**：哪些列缺失值多？分别缺失多少？
8. **基本统计**：数值列的均值、标准差、分位数等
9. **使用限制**：这份数据能回答什么问题？不能回答什么？

**输出**：
- 一个 Markdown 格式的数据卡文件 `data_card.md`
- （可选）生成数据卡的 Python 脚本 `generate_card.py`

**评分点**：
- ✅ 包含所有 9 个必需部分（9 分，每部分 1 分）
- ✅ 字段字典完整且准确（8 分）
- ✅ 缺失概览清晰准确（5 分）
- ✅ 使用限制部分思考深入（8 分）

**提示**：
- 如果在实现过程中遇到困难，可以参考 `starter_code/solution.py` 中的参考实现
- 但最终提交的数据卡必须根据你自己的数据集定制，不能只是示例数据的改个名字

---

## 挑战层（可选，+10 分）

### 任务 5：数据卡的自我审查（10 分）

假装你是三个月后的自己，或者一个需要审计你分析的同事。阅读你刚刚写的数据卡，回答以下问题：

1. **如果这份数据卡是别人写的，你能看懂这份数据吗？**
   - 列出至少 1 个可能让读者困惑的地方，并给出改进建议

2. **数据卡里有没有遗漏的关键信息？**
   - 列出至少 1 个应该补充但缺失的信息

3. **你的"使用限制"部分真的够详细吗？**
   - 设想一个错误的分析场景（有人误用这份数据得出了错误结论）
   - 解释为什么你的使用限制能防止这个错误

**输出**：
- 在 `data_card.md` 末尾添加一个"## 自我审查与改进"部分
- 或单独创建 `review.md` 记录你的审查结果

**评分点**：
- ✅ 找出至少 1 个潜在的困惑点（3 分）
- ✅ 找出至少 1 个遗漏的信息（3 分）
- ✅ 给出一个具体的错误分析场景和防御方案（4 分）

---

## StatLab 项目启动（必做，纳入平时成绩）

### 任务 6：初始化你的 StatLab 项目（不计分，但必须完成）

这是你 16 周项目的起点。请完成以下步骤：

1. **选择数据集**：
   - 可以是你工作中使用的数据
   - 可以是公开数据集（如 Kaggle、UCI、政府公开数据）
   - 要求：至少 5 列、至少 100 行

2. **创建项目目录**：
   ```
   statlab/
   ├── data/              # 原始数据（不要提交到 git）
   ├── notebooks/         # Jupyter notebooks（可选）
   ├── scripts/           # 分析脚本
   ├── report.md          # 分析报告（每周迭代）
   └── README.md          # 项目说明
   ```

3. **初始化 Git 仓库**：
   ```bash
   git init
   echo "*.csv" >> .gitignore  # 不提交原始数据
   git add .
   git commit -m "init: statlab project setup"
   ```

4. **生成第一版 report.md**：
   - 这就是你任务 4 中生成的数据卡
   - 复制到 `statlab/report.md`

5. **写一段 README**：
   - 项目简介
   - 数据来源
   - 当前进度（Week 01：数据卡完成）

**输出**：
- 一个可以运行的 Git 仓库（可以在 GitHub/Gitea 上创建）
- 至少一次 commit

---

## 提交清单

### 必交（基础层）
- [ ] `questions.md`：统计三问的回答
- [ ] `data_types.md`：数据类型标注表
- [ ] `explore.py`：pandas 探索脚本
- [ ] `explore_output.txt`：脚本运行输出

### 进阶层（如完成）
- [ ] `data_card.md`：完整的数据卡
- [ ] `generate_card.py`：（可选）生成数据卡的脚本

### 挑战层（如完成）
- [ ] 自我审查部分（在 `data_card.md` 中或独立的 `review.md`）

### StatLab 项目（必交）
- [ ] Git 仓库链接或截图
- [ ] `statlab/report.md`（第一版）
- [ ] `statlab/README.md`

---

## 常见问题与提示

### Q1：我没有合适的数据集怎么办？

**A**：可以使用以下公开数据集：
- **Kaggle**：搜索你感兴趣的主题（如"电商用户行为"、"房价预测"等）
- **UCI Machine Learning Repository**：经典的 Iris、Titanic 等
- **教材示例数据**：使用 `examples/04_data_card.py` 中的示例数据（但不建议长期使用，最好用自己的数据）

### Q2：我的数据集很大（几百万行），pandas 读取很慢怎么办？

**A**：本周作业不需要处理全量数据。你可以：
- 只读取前 10 万行：`pd.read_csv("file.csv", nrows=100000)`
- 或先用一个子集完成作业，后续再处理全量数据

### Q3：数据卡里的"使用限制"不知道写什么怎么办？

**A**：问自己以下几个问题：
- **样本代表性**：我的样本能代表我想研究的总体吗？（例如：只有活跃用户的数据不能代表所有用户）
- **时间限制**：我的数据有多新？能回答"当前情况"的问题吗？
- **缺失值**：哪些字段缺失很多？基于这些字段的分析结论可靠吗？
- **变量限制**：我有某个变量，但不等于我能做因果推断（例如：有"是否购买"和"广告曝光"的数据，不代表能说"广告导致了购买"）

### Q4：我可以用 AI 来帮我写代码吗？

**A**：本周是**观察期**，我们的重点是建立统计直觉。你可以：
- ✅ 用 AI 帮你查 pandas 的 API 用法
- ✅ 用 AI 解释报错信息
- ❌ 不建议直接让 AI 生成完整的数据卡代码——你需要自己理解每一行在做什么

从 Week 05 开始，我们会系统性地学习"如何审查 AI 生成的统计代码"。本周先把基础打牢。

---

## 评分说明

- **基础层（60 分）**：必须完成，达到基本要求即可及格
- **进阶层（30 分）**：有额外精力的话建议完成，能加深理解
- **挑战层（10 分）**：给想深入思考的同学设计的
- **StatLab 项目**：不计入本周作业分数，但会影响期末项目成绩

**截止日期**：下周上课前提交

**提交方式**：按照老师/助教的要求提交（可能通过 GitHub/Gitea、学习平台或邮件）

---

**记住：数据卡不是一次性的文档，而是你整个项目的"身份证"。每周你做新的分析时，记得回来更新它。**
