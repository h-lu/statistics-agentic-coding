# Week 09 作业：回归分析与模型诊断

> "没有诊断的回归不是分析，是自欺欺人。"
> — 老潘

---

## 作业说明

本周作业分为三层：**基础作业**（必须完成）、**进阶作业**（选做）、**挑战作业**（加分）。每层都有明确的输入输出格式、评分点和常见错误提示。

**提交格式**：将所有代码和结果整理到 `week09_assignment.ipynb` 或 `week09_assignment.py` 中，并在 `week09_report.md` 中回答文字题。

**数据集**：使用 `seaborn.load_dataset("penguins")`

---

## 基础作业（必须完成）

### 1. 简单线性回归拟合

**任务**：拟合 Adelie 企鹅的喙长度（`bill_length_mm`）对喙深度（`bill_depth_mm`）的简单线性回归模型，并解释回归系数。

**输入**：
- 数据：`penguins[penguins["species"] == "Adelie"].dropna()`
- 自变量（X）：喙长度（`bill_length_mm`）
- 因变量（y）：喙深度（`bill_depth_mm`）

**输出格式**：
```
=== 回归方程 ===
bill_depth = XX.XX + XX.XX * bill_length
            ↑      ↑
          截距    斜率

=== 系数解读 ===
截距：当喙长度为 0 mm 时，预测喙深度为 XX.XX mm
斜率：喙长度每增加 1 mm，喙深度平均增加 XX.XX mm

=== 模型拟合 ===
R² = X.XXXX
F 统计量 = XX.XX (p = X.XXXX)

=== 系数显著性 ===
截距：t = XX.XX, p = X.XXXX [XX.XX, XX.XX]
斜率：t = XX.XX, p = X.XXXX [XX.XX, XX.XX]
```

**提示**：
- 使用 `statsmodels.api.OLS()` 拟合模型
- 用 `sm.add_constant()` 添加截距项
- 调用 `model.summary()` 查看完整结果

**常见错误**：
- 忘记添加截距项（`sm.add_constant()`）
- 混淆自变量和因变量（X 和 y 的位置）
- 只报告 p 值，不报告置信区间
- 错误解读斜率（如把"每增加 1 单位"说成"每增加 1%"——只有当变量是百分比形式或取对数后才用百分比表述）

---

### 2. R² 和拟合优度解读

**任务**：计算并解读回归模型的 R²，理解"高 R² 不等于好模型"。

**要求**：
1. 计算三个不同简单回归模型的 R²：
   - 喙长度 → 喙深度
   - 翼展长度 → 喙深度
   - 体重 → 喙深度
2. 比较三个模型的 R²，找出"拟合最好"的模型
3. 回答：R² 最高的模型就是最好的吗？

**输出格式**：
```
=== 模型比较 ===
模型 1（喙长度 → 喙深度）：R² = X.XXXX
模型 2（翼展 → 喙深度）：R² = X.XXXX
模型 3（体重 → 喙深度）：R² = X.XXXX

R² 最高：模型 X（XXX → 喙深度）

=== 思考题 ===
Q: R² 最高的模型就是最好的吗？
A: [你的回答]
```

**提示**：
- R² 衡量的是模型解释的方差比例（0 到 1）
- R² 高不等于假设满足
- R² 高不等于因果关系

**常见错误**：
- 认为 R² 高就是好模型，忽略假设检查
- 混淆"相关"和"因果"
- 只比较 R² 数值，不看实际意义

---

### 3. 回归假设检查（LINE）

**任务**：对题目 1 的回归模型执行完整的假设检查，画诊断图，判断是否满足 LINE 假设。

**要求**：
1. **画残差 vs 拟合值图**（检查线性和等方差）
2. **画 QQ 图**（检查正态性）
3. **执行 Shapiro-Wilk 检验**（正态性检验）
4. **执行 Breusch-Pagan 检验**（等方差检验）
5. **计算 Durbin-Watson 统计量**（独立性）
6. 给出结论：哪些假设满足，哪些不满足？

**输出格式**：
```
=== 假设检查总结 ===

1. 线性（Linear）：
   残差图形状：[随机分布 / 有模式 / U型 / 漏斗型]
   结论：✅ 满足 / ⚠️ 不满足

2. 独立性（Independence）：
   Durbin-Watson 统计量：X.XX
   结论：✅ 接近 2 / ⚠️ 偏离 2

3. 正态性（Normal）：
   Shapiro-Wilk 检验：p = X.XXXX
   QQ 图：[点大致在对角线上 / 严重偏离]
   结论：✅ 满足 / ⚠️ 不满足

4. 等方差（Equal variance）：
   Breusch-Pagan 检验：p = X.XXXX
   残差图：[宽度恒定 / 漏斗型]
   结论：✅ 满足 / ⚠️ 不满足

=== 总体结论 ===
[给出你的结论：模型假设是否满足？是否可以使用？]
```

**提示**：
- 使用 `sns.residplot()` 画残差图（带 LOWESS 线）
- 使用 `scipy.stats.probplot()` 画 QQ 图
- 使用 `scipy.stats.shapiro()` 做正态性检验
- 使用 `statsmodels.stats.diagnostic.het_breuschpagan()` 做等方差检验
- Durbin-Watson 统计量在 `model.summary()` 中（接近 2 表示独立）

**常见错误**：
- 只画图，不做检验（或反之）
- 忘记解释图和检验结果的含义
- 混淆"p > 0.05 不能拒绝"和"证明假设成立"

---

### 4. 模型诊断：高影响点检测

**任务**：计算 Cook's 距离，识别高影响点，并决定如何处理。

**要求**：
1. 计算每个观测的 Cook's 距离
2. 画 Cook's 距离图，标注阈值（4/n）
3. 列出所有高影响点的索引
4. 删除高影响点后重新拟合模型，比较系数变化
5. 给出处理建议

**输出格式**：
```
=== Cook's 距离分析 ===
样本量：XXX
阈值（4/n）：X.XXXX

高影响点数量：X
高影响点索引：[X, X, X, ...]

=== 删除高影响点前后比较 ===
          原始模型    删除后模型    变化
截距      XX.XX      XX.XX       ±X.XX
斜率      XX.XX      XX.XX       ±X.XX
R²        X.XXXX     X.XXXX      ±X.XXXX

=== 处理建议 ===
[给出你的建议：保留 / 删除 / 稳健回归，并说明理由]
```

**提示**：
- 使用 `model.get_influence()` 获取影响统计量
- 使用 `influence.cooks_distance[0]` 获取 Cook's 距离
- 阈值公式：4/n（n 是样本量）
- 删除点前先检查是否为录入错误

**常见错误**：
- 看到高影响点就删除，不检查原因
- 混淆"异常值"和"高影响点"
- 为了提高 R² 而删除点（数据造假）
- 不报告删除前后的比较

---

## 进阶作业（选做）

### 5. 多元回归：控制其他变量后

**任务**：拟合多元回归模型，理解"控制其他变量后"的含义。

**要求**：
1. 拟合两个模型：
   - 简单回归：体重 → 喙深度
   - 多元回归：体重 + 喙长度 + 翼展 → 喙深度
2. 比较体重系数在两个模型中的变化
3. 解释：为什么系数会变化？

**输出格式**：
```
=== 简单回归（体重 → 喙深度） ===
体重系数：XX.XX (p = X.XXXX)
R² = X.XXXX

=== 多元回归（体重 + 喙长度 + 翼展 → 喙深度） ===
          系数      p 值      95% CI
截距      XX.XX    X.XXXX   [XX.XX, XX.XX]
体重      XX.XX    X.XXXX   [XX.XX, XX.XX]
喙长度    XX.XX    X.XXXX   [XX.XX, XX.XX]
翼展      XX.XX    X.XXXX   [XX.XX, XX.XX]

R² = X.XXXX, 调整 R² = X.XXXX

=== 系数变化解释 ===
简单回归中，体重系数 = XX.XX
多元回归中，体重系数 = XX.XX
变化 = ±X.XX

为什么变化？[你的解释]
```

**提示**：
- 在多元回归中，系数表示"控制其他变量后"的影响
- 如果自变量之间相关，简单回归的系数会"吸收"其他变量的影响
- 多元回归的系数是"纯粹"的影响

**常见错误**：
- 认为简单回归和多元回归的系数应该相同
- 不理解"控制其他变量后"的含义
- 只报告数字，不解释差异原因

---

### 6. 多重共线性检测（VIF）

**任务**：计算方差膨胀因子（VIF），检测多重共线性问题。

**要求**：
1. 计算多元回归中每个自变量的 VIF
2. 判断哪些变量存在多重共线性（VIF > 10）
3. 画相关矩阵热图，验证 VIF 结果
4. 如果存在多重共线性，给出处理建议

**输出格式**：
```
=== VIF 分析 ===
      VIF    诊断
截距   X.X   （跳过）
体重   XX.XX  ✅ / ⚠️ VIF > 10
喙长度 XX.XX  ✅ / ⚠️ VIF > 10
翼展   XX.XX  ✅ / ⚠️ VIF > 10

=== 相关矩阵 ===
        体重   喙长度   翼展
体重    1.00   X.XX    X.XX
喙长度  X.XX   1.00    X.XX
翼展    X.XX   X.XX    1.00

=== 处理建议 ===
[如果 VIF > 10：给出建议（删除哪个变量 / PCA / 正则化）]
[如果 VIF 都 < 10：说明多重共线性不是问题]
```

**提示**：
- 使用 `statsmodels.stats.outliers_influence.variance_inflation_factor()` 计算 VIF
- VIF > 10 表示严重多重共线性
- 相关矩阵热图可以用 `sns.heatmap()` 画

**常见错误**：
- 忘记加截距项（VIF 计算会出错）
- 混淆相关系数和 VIF（相关是成对的，VIF 是多变量）
- 看到 VIF 稍高（如 5-7）就恐慌（VIF > 10 才需处理）

---

## 挑战作业（加分）

### 7. 稳健回归 vs OLS

**任务**：当数据存在异常值时，比较 OLS 和稳健回归（RLM）的表现。

**要求**：
1. 生成含异常值的模拟数据
2. 分别拟合 OLS 和 RLM（Robust Linear Model）
3. 比较两种方法的系数、残差图
4. 解释：稳健回归的优势是什么？

**输出格式**：
```
=== OLS vs RLM 比较 ===

OLS 结果：
  截距：XX.XX [XX.XX, XX.XX]
  斜率：XX.XX [XX.XX, XX.XX]
  R²：X.XXXX

RLM 结果：
  截距：XX.XX [XX.XX, XX.XX]
  斜率：XX.XX [XX.XX, XX.XX]

=== 残差比较 ===
[画两张残差图，对比 OLS 和 RLM]

=== 结论 ===
稳健回归的优势：[你的解释]
什么时候用稳健回归？[你的建议]
```

**提示**：
- 使用 `statsmodels.api.RLM()` 拟合稳健回归
- 稳健回归使用 Huber's T 或其他损失函数，对异常值不敏感
- 可以手动在数据中加入 2-3 个极端点

**常见错误**：
- 直接用 penguins 数据做比较（异常值可能不够明显）
- 只比较系数，不画残差图
- 不解释稳健回归的原理

---

### 8. 异方差处理：稳健标准误（HC3）

**任务**：当数据存在异方差时，使用稳健标准误（HC3）修正置信区间。

**要求**：
1. 生成异方差数据（或用真实数据演示）
2. 执行 Breusch-Pagan 检验确认异方差
3. 比较 OLS 标准误和 HC3 稳健标准误
4. 解释：HC3 如何解决异方差问题？

**输出格式**：
```
=== 异方差检验 ===
Breusch-Pagan 检验：p = X.XXXX
结论：✅ 等方差 / ⚠️ 异方差

=== 标准误比较 ===
          OLS SE   HC3 SE   变化
截距      X.XX     X.XX     ±X%
斜率      X.XX     X.XX     ±X%

=== 系数置信区间比较 ===
OLS：  斜率 [XX.XX, XX.XX]
HC3：  斜率 [XX.XX, XX.XX]

=== 解释 ===
HC3 如何解决异方差问题？[你的解释]
```

**提示**：
- 使用 `model.get_robustcov_results(cov_type='HC3')` 获取稳健标准误
- HC3 标准误通常比 OLS 标准误更大（更保守）
- 异方差不会影响系数一致性，但会影响标准误

**常见错误**：
- 混淆 HC3 和 Bootstrap（HC3 是公式修正，Bootstrap 是重采样）
- 认为稳健标准误可以"修复"异方差（它只是修正标准误）
- 不画残差图，只依赖检验

---

## AI 协作练习（可选）

### 题目 9：审查 AI 生成的回归结论

假设你让 AI 分析"广告投入对销售额的影响"，它给你生成了下面这份结论。请审查它，找出其中的问题。

**AI 生成的结论**：

> "回归分析显示，广告投入对销售额有显著正向影响（β = 0.5, p < 0.001）。R² = 0.85，说明模型拟合非常好。建议增加广告投入以提高销售额。"

---

**审查清单**：

- [ ] **残差图**：AI 报告了残差图吗？
  - 没有残差图，无法判断假设是否满足
  - R² = 0.85 可能建立在违反假设的基础上
  - 风险：p 值和置信区间可能不可信

- [ ] **假设检查**：AI 检查了 LINE 假设吗？
  - 报告中没有提到线性、独立性、正态性、等方差检查
  - 没有诊断图（残差图、QQ 图）
  - 没有诊断检验（Shapiro-Wilk、Breusch-Pagan）

- [ ] **高影响点**：AI 识别了高影响点吗？
  - 报告中没有提到 Cook's 距离
  - 可能存在绑架模型的极端点
  - 删除一个点可能让结论完全改变

- [ ] **置信区间**：AI 报告了系数的置信区间吗？
  - 只报告了点估计（β = 0.5）和 p 值
  - 没有量化"影响有多确定"
  - 95% CI 可能是 [0.1, 0.9]（不精确）或 [0.45, 0.55]（精确）

- [ ] **因果推断**：AI 把"相关"说成"因果"了吗？
  - "建议增加广告投入" —— 这是因果建议
  - 但观察性研究不能证明因果关系
  - 可能存在混淆变量（如季节、竞争对手行为等）

**你的任务**：

1. 写一份审查报告（200-300 字），列出你发现的问题
2. 给出修订建议（应该补充什么诊断、如何改写结论）
3. （可选）用 Python 执行完整的回归分析（带诊断），验证你的结论

**提交物**：
- 审查报告（Markdown 格式）
- 你发现的 3-5 个问题列表
- 修订后的报告（可选，如果做了代码验证）

**提示**：
- 使用本周学到的知识：LINE 假设、残差诊断、Cook's 距离、VIF
- 参考正文第 3-4 节关于模型诊断的讨论
- 参考本周 StatLab 进度中的报告格式
- 如果你遇到困难，可以参考 `starter_code/solution.py`

**评分标准**（如果提交）：
- 识别问题的准确性（40%）
- 审查报告的说服力（30%）
- 修订建议的合理性（30%）

---

## 提交清单

**基础作业**（必须完成）：
- [ ] 题目 1：简单线性回归拟合（代码 + 输出 + 系数解读）
- [ ] 题目 2：R² 和拟合优度解读（代码 + 比较表格 + 思考题回答）
- [ ] 题目 3：回归假设检查（代码 + 诊断图 + 假设检验 + 结论）
- [ ] 题目 4：模型诊断（代码 + Cook's 距离图 + 处理建议）

**进阶作业**（选做）：
- [ ] 题目 5：多元回归（代码 + 系数比较 + 解释）
- [ ] 题目 6：多重共线性检测（代码 + VIF + 相关矩阵 + 处理建议）

**挑战作业**（加分）：
- [ ] 题目 7：稳健回归（代码 + OLS vs RLM 比较 + 解释）
- [ ] 题目 8：异方差处理（代码 + HC3 vs OLS + 解释）

**AI 协作练习**（可选）：
- [ ] 题目 9：AI 报告审查报告

---

## 参考资源

如果你遇到困难，可以参考：
- `starter_code/solution.py`（示例实现）
- 本周 CHAPTER.md 的第 1-5 节
- `statsmodels.api.OLS` 文档
- `statsmodels.api.RLM` 文档

---

祝你好运！记住：**残差图是底线。没有诊断的回归不是分析，是自欺欺人。**
