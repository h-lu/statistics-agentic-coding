# Week 11 锚点表
#
# 约定：
# - id: 周内唯一标识符，格式为 anchor_{序号}
# - claim: 知识声称（一句话，中文）
# - evidence: 证据位置（章节内的行号或代码块引用）
# - verification: 验证方法（代码示例/统计规则/逻辑推导）

# ─────────────────────────────────────────────────────────────

- id: anchor_11_01
  claim: 线性回归只能捕捉线性关系，当真实关系是非线性时（如房价的边际递减），残差图会显示U型或倒U型模式
  evidence: CHAPTER.md 第143-169行（"线性回归的局限"和"残差图在说话"）
  verification: 统计规则（残差诊断）+ 代码示例（可视化残差vs预测值）

- id: anchor_11_02
  claim: 决策树通过"如果-那么"规则划分特征空间，每个叶子节点给出预测值（回归为均值，分类为众数）
  evidence: CHAPTER.md 第197-306行（"决策树：用'如果-那么'规则预测"）
  verification: 代码示例（DecisionTreeRegressor + plot_tree）+ 可视化输出

- id: anchor_11_03
  claim: 决策树使用熵或Gini不纯度作为分裂标准，选择能最大化信息增益（或最大化不纯度降低）的特征和阈值
  evidence: CHAPTER.md 第281-306行（"决策树的分裂逻辑"）
  verification: 逻辑推导（信息增益公式）+ scikit-learn源码参考

- id: anchor_11_04
  claim: 决策树在训练集上表现完美（R²→1）但在测试集上很差，是过拟合的典型症状
  evidence: CHAPTER.md 第310-362行（"为什么决策树这么容易过拟合"和"控制树的生长"）
  verification: 代码示例（训练集vs测试集R²对比）+ 统计规则（泛化差距）

- id: anchor_11_05
  claim: 交叉验证（Week 10学过）可以用于估计决策树的最佳复杂度（max_depth），防止过拟合
  evidence: CHAPTER.md 第362-407行（"和Week 10的连接：用交叉验证找最佳复杂度"）
  verification: 代码示例（cross_val_score）+ validation_curve可视化

- id: anchor_11_06
  claim: 随机森林通过Bootstrap采样（Week 08学过）训练多棵决策树，并在预测时投票（分类）或平均（回归），降低单棵树的高方差
  evidence: CHAPTER.md 第420-439行（"和Week 08的连接：Bootstrap是Bagging的基础"）
  verification: 逻辑推导（方差降低公式）+ 代码示例（单树vs森林variance对比）

- id: anchor_11_07
  claim: 随机森林通过"特征随机性"（每次分裂只考虑部分特征）进一步增加树之间的多样性，提升集成效果
  evidence: CHAPTER.md 第431-439行（"随机森林的改进：特征随机性"）
  verification: 代码示例（max_features参数影响）+ 文献引用（Breiman 2001）

- id: anchor_11_08
  claim: 基于不纯度的特征重要性有陷阱：(1)高基数特征（如用户ID）会被误认为重要；(2)相关特征会"稀释"重要性
  evidence: CHAPTER.md 第520-570行（"基于不纯度的特征重要性"和两个陷阱）
  verification: 代码示例（高基数特征vs正常特征的重要性对比）+ 统计解释

- id: anchor_11_09
  claim: 置换重要性通过随机打乱某特征值后观察模型性能下降程度来衡量特征重要性，能避免高基数特征陷阱
  evidence: CHAPTER.md 第571-610行（"更可靠的方案：置换重要性"）
  verification: 代码示例（permutation_importance）+ scikit-learn文档引用

- id: anchor_11_10
  claim: 特征重要性≠因果性，重要特征只是"与预测相关的特征"，不能理解为"改变它能导致结果变化"
  evidence: CHAPTER.md 第610-620行（"特征重要性的正确解释"）
  verification: 逻辑推导（相关性≠因果性）+ 真实案例说明

- id: anchor_11_11
  claim: 网格搜索适合参数少（2-4个）、范围小、离散值的场景；随机搜索适合参数多（5+个）、连续值、参数重要性不均的场景
  evidence: CHAPTER.md 第649-715行（"网格搜索"和"随机搜索"）
  verification: 代码示例（GridSearchCV vs RandomizedSearchCV运行时间对比）+ 文献引用（Bergstra & Bergstra 2012）

- id: anchor_11_12
  claim: 嵌套交叉验证（外层CV评估泛化，内层CV选择超参数）能提供"更诚实"的性能估计，但计算成本更高
  evidence: CHAPTER.md 第715-729行（"嵌套交叉验证"代码示例）
  verification: 代码示例（cross_val_score with cv参数）+ 性能对比数据（0.824 vs 0.801）

- id: anchor_11_13
  claim: StatLab本周新增树模型评估功能，包括决策树可视化、随机森林建模、特征重要性图、超参数调优、模型对比表
  evidence: CHAPTER.md 第775-1032行（"StatLab进度"）
  verification: 代码实现（examples/11_statlab_trees.py）+ 输出示例（Markdown报告片段）

- id: anchor_11_14
  claim: 树模型在工业界（欺诈检测、推荐系统、信用评分）应用广泛，特征重要性在合规审计中有价值
  evidence: CHAPTER.md 第467-492行（AI时代小专栏"树模型在工业界"）
  verification: 行业报告引用（2024-2025）+ 实际应用案例
