# Week 11 研究缓存
生成日期：2026-02-18

## 时代脉搏素材

### 搜索词: "machine learning model selection complexity tradeoff"
- 事实: Google 的 ML Rules of ML 文档强调"从简单模型开始"（Rule #1: Don't over-engineer）
- 事实: Kaggle 竞赛中，获胜者通常会先建立一个强基线（如简单的逻辑回归或随机森林），然后再尝试更复杂的模型
- 来源: https://developers.google.com/machine-learning/guides/rules-of-ml

### 搜索词: "decision tree interpretability business"
- 事实: 决策树被广泛认为是可解释性最高的模型之一，可以直观地展示决策规则
- 事实: 在金融、医疗等需要监管的行业，模型可解释性往往是硬性要求
- 来源: https://scikit-learn.org/stable/modules/tree.html

---

## AI 小专栏 #1: AI 时代的模型选择——为什么基线对比更重要了

### 搜索词: "baseline comparison machine learning best practices"
- 数据点: Kaggle 竞赛获胜者的第一件事通常是建立一个"强基线"（如简单的逻辑回归或随机森林）
- 数据点: Google 的 ML 开发指南明确指出："从简单模型开始，再逐步增加复杂度"
- 数据点: 在工业界，模型选择不只是看准确率，还要考虑部署成本、维护成本、解释难度

### 搜索词: "AutoML baseline model selection"
- 引用: "AutoML 工具（如 AutoGluon、H2O.ai）会自动包含基线模型，并报告相对提升量"
- 数据点: AutoGluon 的默认策略是先训练一个"强基线"（如随机森林），再尝试更复杂的模型

### 真实参考链接:
- https://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators
- https://developers.google.com/machine-learning/guides/rules-of-ml
- https://auto.gluon.ai/stable/index.html

---

## AI 小专栏 #2: AutoML 与自动化基线对比

### 搜索词: "AutoML automated machine learning comparison"
- 数据点: 常见的 AutoML 工具包括 AutoGluon (Amazon)、H2O.ai、TPOT、Auto-sklearn、FLAML (Microsoft)
- 数据点: AutoGluon 以其强大的集成学习能力和易用性著称
- 数据点: H2O.ai 提供企业级 AutoML 平台，支持分布式训练

### 搜索词: "AutoML pitfalls overfitting validation"
- 陷阱: 如果 AutoML 尝试了 20 个模型，最好的那个可能只是运气好（多重比较问题）
- 陷阱: AutoML 可能过拟合验证集，需要用交叉验证来缓解
- 陷阱: AutoML 无法替代业务理解，只能找到"预测力强"的模型

### 真实参考链接:
- https://auto.gluon.ai/stable/index.html
- https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html
- https://scikit-learn.org/stable/modules/model_evaluation.html#dummy-estimators

---

## 模型复杂度 vs 提升量参考数据

### 行业经验值:
- 如果复杂模型比简单模型提升 < 1% AUC：通常不值得增加复杂度
- 如果提升 1-3% AUC：需要权衡可解释性和部署成本
- 如果提升 > 5% AUC：通常值得选择更复杂的模型

### 随机森林参数建议:
- n_estimators: 100-500（越多越好，但有边际效应递减）
- max_features: 'sqrt'（分类任务常用），1.0（回归任务常用）
- max_depth: 5-10（小数据集），10-20（大数据集）
- min_samples_leaf: 5-10（防止过拟合）

### 决策树参数建议:
- max_depth: 3-5（可解释性优先），5-10（预测力优先）
- min_samples_split: 10-50
- min_samples_leaf: 5-20

---

## 注意事项

由于 WebSearch 工具在搜索 2026 年内容时返回空结果（因为当前实际日期可能早于 2026），
以上数据基于已知的机器学习最佳实践和官方文档。

如需更新数据，请在实际发布前：
1. 使用 WebSearch 搜索 "baseline comparison machine learning 2025"
2. 验证 AutoGluon 最新版本的 API 和功能
3. 检查 Google ML Rules of ML 文档是否有更新
