# Week 11 作业：树模型与集成学习实战

> "The strength of a tree is in its branches; the strength of a forest is in its diversity."
> — Adapted from African proverb

本周作业要求你**完整走一遍树模型建模流程**：从线性模型的局限到决策树，从过拟合诊断到随机森林，从特征重要性到超参数调优。你不再只是"跑一个随机森林"，而是学会判断"什么时候需要树模型"、"如何防止过拟合"、"哪些特征真正驱动预测"、"如何与基线模型对比"。

---

## 作业结构

| 层级 | 内容 | 建议时间 |
|------|------|----------|
| 基础作业（必做） | 决策树建模、过拟合诊断、随机森林、特征重要性 | 4-5 小时 |
| 进阶作业（选做） | 超参数调优、模型对比分析 | 1-2 小时 |
| 挑战作业（可选） | StatLab 树模型完整流水线 | 2-3 小时 |
| AI 协作练习（可选） | 审查 AI 生成的树模型代码 | 1 小时 |

---

## 基础作业（必做）

### 任务 1：从线性回归到决策树——发现非线性关系（25 分）

**目标**：理解线性模型的局限性，掌握决策树的基本概念

**背景**：小北用 Week 09 学过的线性回归预测房价，R² = 0.65。他兴冲冲地对老潘说："模型很棒！"

老潘问："**你看过残差图吗？**"

小北愣住了："残差图？"

老潘叹了口气："**残差图会告诉你模型是否漏掉了非线性关系**。如果残差有模式（比如 U 型），线性模型就不够用了。"

**步骤**：

1. **拟合线性回归基线**：
   - 使用你的数据集（回归任务，如房价、销量、消费金额）
   - 拟合线性回归模型
   - 计算 R² 和 MSE

2. **绘制残差图**：
   - 横轴：预测值
   - 纵轴：残差
   - 观察残差是否有模式（U 型、漏斗形、周期性）

3. **拟合决策树**：
   - 使用 `DecisionTreeRegressor(max_depth=3, random_state=42)`
   - 计算训练集和测试集 R²
   - 对比线性回归和决策树的性能

4. **可视化决策树**：
   - 使用 `plot_tree()` 绘制树结构
   - 解释第一个分裂节点的规则（如 `area_sqm <= 85.5`）
   - 解释叶子节点的预测值含义

5. **提交** `linear_vs_tree.md`，包含：
   - 线性回归 R² 和 MSE
   - 残差图（文件或截图）
   - 决策树 R²（训练集/测试集）
   - 决策树可视化图
   - 对比分析（150-200 字）：线性模型 vs 决策树

**输入示例**：
```
特征: area_sqm, bedrooms, bathrooms, age_years, distance_km
目标: price（房价）
```

**输出示例**：
```
线性回归:
- 训练集 R²: 0.650
- 测试集 R²: 0.623
- MSE: 45000

残差图分析:
残差图呈现轻微的U型模式：预测值较低和较高时，残差偏大且呈对称状。
这说明线性模型漏掉了非线性关系。

决策树 (max_depth=3):
- 训练集 R²: 0.780
- 测试集 R²: 0.710
- MSE: 32000

对比分析:
决策树测试集R²(0.710)高于线性回归(0.623)，说明数据中存在非线性关系。
决策树通过"如果-那么"规则（如面积<85.5㎡预测200万）捕捉了这些模式，
而线性回归只能画一条直线。决策树的可解释性也更强——能看到每个分裂的
具体规则。
```

**评分标准**：
- 线性回归拟合正确（5 分）
- 残差图绘制和解释正确（7 分）
- 决策树拟合正确（5 分）
- 决策树可视化清晰（3 分）
- 对比分析合理（5 分）

---

### 任务 2：决策树过拟合诊断与正则化（30 分）

**目标**：识别决策树的过拟合问题，掌握正则化方法

**背景**：阿码很兴奋："我的决策树训练集 R² = 0.95，测试集 R² = 0.61！模型完美！"

老潘摇头："**你的模型过拟合了——它记住了训练数据，但不会泛化**。"

**步骤**：

1. **拟合无约束决策树**：
   - 使用 `DecisionTreeRegressor(random_state=42)`（不限制深度）
   - 计算训练集和测试集 R²
   - 观察树深度（`tree.get_depth()`）

2. **诊断过拟合**：
   - 写一段分析（100 字），回答：
     - 训练集 R² ≈ 1.0，测试集 R² 很低，说明什么？
     - 为什么决策树这么容易过拟合？
     - 树深度与过拟合有什么关系？

3. **应用正则化**：
   - 尝试不同的 `max_depth` 值（3, 5, 7, 10）
   - 尝试不同的 `min_samples_leaf` 值（1, 5, 10）
   - 使用 5-fold 交叉验证选择最佳超参数组合

4. **对比正则化效果**：
   - 绘制一张图：横轴是 max_depth，纵轴是 CV R²
   - 找到最佳深度
   - 解释为什么深度过大或过小都不好

5. **提交** `tree_overfitting.md`，包含：
   - 无约束决策树的性能（训练集/测试集）
   - 过拟合诊断分析
   - 正则化后的性能对比
   - CV 性能曲线图
   - 最佳超参数选择

**输出示例**：
```
无约束决策树:
- 训练集 R²: 0.998
- 测试集 R²: 0.610
- 树深度: 25

过拟合诊断:
训练集R²接近1.0，但测试集只有0.61，说明模型"背答案"了。决策树通过
无限生长，可以记住每一个训练样本，但这些规则在新数据上失效。树深度25
意味着平均每个叶子节点只有很少样本，模型过于复杂。

正则化实验:

max_depth | 训练集R² | 测试集R² | CV R²
---------|----------|----------|-------
3        | 0.780    | 0.710    | 0.695
5        | 0.850    | 0.745    | 0.732
7        | 0.910    | 0.720    | 0.728
10       | 0.950    | 0.680    | 0.705
None     | 0.998    | 0.610    | 0.650

最佳深度: max_depth=5 (CV R² = 0.732)

解释:
深度过小(3)时，模型太简单，欠拟合。深度过大(10或None)时，模型记住
噪声，过拟合。深度=5是平衡点，既捕捉了非线性，又不会过拟合。
```

**评分标准**：
- 无约束决策树拟合正确（5 分）
- 过拟合诊断准确（8 分）
- 正则化实验完整（10 分）
- CV 性能曲线清晰（4 分）
- 最佳超参数解释合理（3 分）

---

### 任务 3：随机森林与 Bagging 原理（35 分）

**目标**：理解随机森林的 Bagging 原理，掌握集成学习方法

**背景**：小北找到了最佳决策树（max_depth=5），测试集 R² = 0.745。阿码问："**随机森林会不会更好？**"

老潘说："**随机森林通过'多棵树投票'降低方差，通常比单棵树更稳健**。"

**步骤**：

1. **拟合随机森林**：
   - 使用 `RandomForestRegressor(n_estimators=100, max_depth=5, random_state=42, n_jobs=-1)`
   - 计算训练集和测试集 R²
   - 对比单棵决策树和随机森林

2. **理解 Bagging 原理**：
   - 写一段解释（150 字），回答：
     - 什么是 Bagging（Bootstrap Aggregating）？
     - 为什么多棵树投票比单棵树好？
     - 随机森林如何增加树的多样性？（两个随机性来源）

3. **连接 Week 08**：
   - Week 08 你学过 Bootstrap（自助法）
   - 解释 Bootstrap 和 Bagging 的关系
   - 为什么随机森林要用 Bootstrap 重采样？

4. **对比不同 n_estimators**：
   - 尝试 n_estimators = [1, 10, 50, 100, 200]
   - 绘制一张图：横轴是 n_estimators，纵轴是测试集 R²
   - 观察：什么时候增加树数不再带来明显提升？

5. **提交** `random_forest_bagging.md`，包含：
   - 单棵树 vs 随机森林性能对比
   - Bagging 原理解释
   - 与 Week 08 Bootstrap 的连接
   - n_estimators 性能曲线图
   - 最佳 n_estimators 选择

**输出示例**：
```
性能对比:

模型         | 测试集R² | 训练时间
-----------|----------|---------
单棵决策树(深度5) | 0.745    | 0.02秒
随机森林(100棵) | 0.812    | 0.8秒

Bagging 原理解释:
Bagging (Bootstrap Aggregating) 是一种集成学习方法：
1. Bootstrap重采样: 从原始数据中有放回地抽取B个训练子样本
2. 独立训练: 在每个子样本上训练一棵决策树
3. 投票/平均: 预测时，取B棵树预测的平均值(回归)或多数投票(分类)

多棵树投票比单棵树好的原因：
- 单棵树的预测方差高（对数据变化敏感）
- 多棵树的平均预测方差更低（方差 ≈ 单棵树方差 / B）
- 关键是树的"不相关性"——如果每棵树都犯不同错误，平均会抵消

随机森林的两个随机性来源：
1. 数据随机性: 每棵树在不同Bootstrap样本上训练
2. 特征随机性: 每次分裂时只随机选择一部分特征(√p)

与Week 08 Bootstrap的连接:
Week 08学过Bootstrap用于置信区间估计（从样本中重采样，估计统计量分布）。
随机森林用同样的Bootstrap思想，但目的不同——通过重采样创建多个"略有不同"
的模型，它们的错误不相关，平均后降低方差。

n_estimators 实验:

n_estimators | 测试集R² | 提升幅度
------------|----------|---------
1           | 0.745    | 基线
10          | 0.785    | +0.040
50          | 0.805    | +0.020
100         | 0.812    | +0.007
200         | 0.815    | +0.003

结论:
100棵树之后，性能提升不明显(仅0.003)，收益递减。选择n_estimators=100
是性价比平衡点。
```

**评分标准**：
- 随机森林拟合正确（5 分）
- Bagging 原理解释准确（10 分）
- 与 Week 08 Bootstrap 连接正确（8 分）
- n_estimators 实验完整（7 分）
- 性能曲线清晰（5 分）

---

### 任务 4：特征重要性分析与陷阱（30 分）

**目标**：掌握特征重要性的计算方法和正确解释

**背景**：小北的随机森林 R² = 0.812。老潘问："**哪些特征在驱动预测？**"

小北输出了特征重要性：
```
area_sqm: 0.452
bedrooms: 0.098
bathrooms: 0.067
```

阿码说："**面积最重要！那我们扩大面积就能涨价！**"

老潘立刻摇头："**停！你混淆了预测和因果**。"

**步骤**：

1. **计算特征重要性**：
   - 使用 `rf.feature_importances_` 提取重要性
   - 创建一个 DataFrame，包含特征名和重要性
   - 按重要性降序排列

2. **可视化特征重要性**：
   - 使用水平条形图（`plt.barh()`）
   - 只显示 Top 10-15 特征
   - 标注特征名和重要性值

3. **连接 Week 09**：
   - Week 09 你学过**多重共线性**
   - 解释：相关特征（如面积和房间数）会怎样影响特征重要性？
   - 为什么"卧室重要性 = 0.10"不代表卧室不重要？

4. **置换重要性（Permutation Importance）**：
   - 使用 `sklearn.inspection.permutation_importance`
   - 随机打乱某个特征，观察性能下降
   - 对比基于不纯度的重要性和置换重要性

5. **正确解释特征重要性**：
   - 对 Top 3 特征写出正确解释
   - 加上警告："特征重要性 ≠ 因果关系"
   - 解释为什么高基数类别特征（如用户 ID）可能被误认为"重要"

6. **提交** `feature_importance_analysis.md`，包含：
   - 特征重要性表（Top 10）
   - 特征重要性可视化图
   - 与 Week 09 共线性的连接分析
   - 置换重要性对比
   - 正确解释 + 警告

**输出示例**：
```
特征重要性 (Top 10):

特征          | 重要性
------------|--------
area_sqm     | 0.452
age_years    | 0.218
distance_km  | 0.165
bedrooms     | 0.098
bathrooms    | 0.067
property_type | 0.000
...

可视化: [水平条形图]

与Week 09多重共线性的连接:
如果面积(area_sqm)和房间数(bedrooms)高度相关(r=0.8)，模型可能只把重要性
给其中一个(面积=0.45)，另一个看起来"不重要"(卧室=0.10)。但如果删除面积，
卧室的重要性会飙升到0.50——这说明卧室一直重要，只是和面积"分担"了重要性。

这就是Week 09学过的"相关特征会稀释系数"——在随机森林中表现为"相关特征
会稀释重要性"。

置换重要性对比:

特征         | 不纯度重要性 | 置换重要性
-----------|-------------|------------
area_sqm    | 0.452       | 0.2150
age_years   | 0.218       | 0.0892
distance_km | 0.165       | 0.0654
bedrooms    | 0.098       | 0.0234

不纯度重要性: 训练时该特征贡献了多少MSE减少
置换重要性: 打乱该特征后，模型性能下降多少

置换重要性更可靠，因为它回答"如果失去这个特征，模型损失多少性能"，
而不是"训练时用了多少次这个特征"。

正确解释:
- 面积重要性=0.452: 在随机森林的所有分裂中，面积特征贡献了45.2%的MSE减少
- 房龄重要性=0.218: 房龄贡献了21.8%的MSE减少，是第二重要特征
- 距离重要性=0.165: 距离市中心距离贡献了16.5%的MSE减少

⚠️ 重要警告:
1. 特征重要性 ≠ 因果关系: 面积重要可能是"面积大→地段好→价格高"，面积
   只是地段的代理变量，不能说"扩大面积会导致涨价"
2. 相关特征会稀释重要性: 卧室重要性低不代表它不重要，可能只是和面积高度相关
3. 高基数类别特征可能被误认为重要: 用户ID这样的特征看起来"很重要"，
   但只是过拟合，删除后模型性能不会下降
```

**评分标准**：
- 特征重要性计算正确（5 分）
- 可视化清晰（5 分）
- 与 Week 09 共线性连接正确（8 分）
- 置换重要性实现正确（7 分）
- 特征重要性解释准确 + 警告（5 分）

---

## 进阶作业（选做）

### 任务 5：超参数调优——网格搜索 vs 随机搜索（30 分）

**目标**：掌握超参数调优方法，理解网格搜索和随机搜索的区别

**背景**：阿码学会了 `GridSearchCV`，兴奋地说："**我试试所有参数组合！**"

老潘叹气："**如果你有10个超参数，每个试10个值，那就是10^10个组合，算到明年**。"

**步骤**：

1. **定义超参数网格**：
   - 关键超参数：`n_estimators`, `max_depth`, `min_samples_split`, `min_samples_leaf`, `max_features`
   - 为每个超参数设计合理的搜索范围

2. **网格搜索（GridSearchCV）**：
   - 使用 `GridSearchCV` 尝试所有组合
   - 使用 5-fold CV，scoring='r2'
   - 记录最佳参数和 CV 时间

3. **随机搜索（RandomizedSearchCV）**：
   - 使用 `RandomizedSearchCV` 随机采样 50 个组合
   - 使用同样的 CV 和 scoring
   - 记录最佳参数和 CV 时间

4. **对比两种方法**：
   - 性能对比：最佳 R² 差异多少？
   - 时间对比：网格搜索比随机搜索慢多少？
   - 写一段分析（150 字）：什么时候用随机搜索更合适？

5. **提交** `hyperparameter_tuning.md`，包含：
   - 超参数网格定义
   - 网格搜索结果（最佳参数、CV 得分、时间）
   - 随机搜索结果（最佳参数、CV 得分、时间）
   - 两种方法对比分析
   - 最佳模型在测试集上的最终性能

**输出示例**：
```
超参数网格:
{
  'n_estimators': [50, 100, 200],
  'max_depth': [3, 5, 7, 10],
  'min_samples_split': [2, 5, 10],
  'min_samples_leaf': [1, 5, 10],
  'max_features': ['sqrt', 'log2', 0.5, 0.8]
}

总组合数: 3 × 4 × 3 × 2 × 4 = 288个组合
CV拟合次数: 288 × 5 = 1440次

网格搜索结果:
- 最佳参数: {'max_depth': 7, 'max_features': 'sqrt', 'min_samples_leaf': 5,
             'min_samples_split': 10, 'n_estimators': 200}
- 最佳CV R²: 0.824
- CV时间: 125秒

随机搜索结果:
- 最佳参数: {'max_depth': 9, 'max_features': 'sqrt', 'min_samples_leaf': 3,
             'min_samples_split': 8, 'n_estimators': 287}
- 最佳CV R²: 0.826
- CV时间: 22秒

对比分析:
随机搜索用50次采样(250次拟合)找到了比网格搜索(1440次拟合)略好的结果(R²
0.826 vs 0.824)，但时间快了5.7倍(22秒 vs 125秒)。随机搜索更高效的原因：
1. 不是所有超参数都同样重要，随机搜索可以均匀探索
2. 网格搜索在"不重要"的参数上浪费计算资源
3. 连续参数(如n_estimators)用网格搜索可能错过最优值

结论:
超参数较多时，先用随机搜索快速探索，再对关键参数精细调优。网格搜索适合
"参数少、范围小"的场景。
```

**评分标准**：
- 超参数网格定义合理（5 分）
- 网格搜索实现正确（8 分）
- 随机搜索实现正确（8 分）
- 对比分析深入（6 分）
- 最终模型性能评估（3 分）

---

### 任务 6：模型对比与选择（25 分）

**目标**：对比不同模型，学会"基线优先"的建模原则

**背景**：小北训练了线性回归、决策树、随机森林三个模型。老潘问："**哪个模型最好？**"

小北说："随机森林 R² = 0.826，最高！"

老潘摇头："**你还要考虑可解释性、训练时间、业务需求**。"

**步骤**：

1. **训练多个模型**：
   - 线性回归（Week 09）
   - 决策树（max_depth=5，来自任务 2）
   - 随机森林（调优后，来自任务 5）

2. **对比多个维度**：
   - 预测性能：测试集 R²、MSE、MAE
   - 可解释性：系数解释、规则可视化、特征重要性
   - 训练时间：拟合时间 + 预测时间
   - 稳定性：不同随机种子下的性能方差

3. **创建对比表**：
   - 一个清晰的表格，包含所有维度
   - 用颜色或符号标记每个维度的最优模型

4. **模型选择建议**：
   - 写一段分析（200 字），回答：
     - 如果优先考虑可解释性，选哪个模型？
     - 如果优先考虑预测性能，选哪个模型？
     - 如果优先考虑训练速度，选哪个模型？
     - 如果需要在线实时预测，选哪个模型？

5. **提交** `model_comparison.md`，包含：
   - 多模型对比表
   - 每个维度的最优模型分析
   - 不同业务场景下的模型选择建议

**输出示例**：
```
模型对比表:

模型         | 测试集R² | MSE    | 可解释性 | 训练时间 | 预测时间
-----------|----------|--------|---------|----------|---------
线性回归     | 0.623    | 45000  | ★★★★★   | 0.01秒   | <0.001秒
决策树(5)   | 0.745    | 32000  | ★★★★☆   | 0.02秒   | <0.001秒
随机森林(调优)| 0.826    | 21000  | ★★★☆☆   | 1.5秒    | 0.02秒

每个维度的最优模型:
- 预测性能: 随机森林 (R²=0.826, MSE=21000)
- 可解释性: 线性回归 (系数直接解释，截距和斜率有明确含义)
- 训练速度: 线性回归 (0.01秒，比随机森林快150倍)
- 预测速度: 线性回归/决策树 (<0.001秒，适合实时预测)

不同业务场景下的模型选择:

场景1: 需要向管理层解释"哪些因素影响房价"
→ 选择线性回归
→ 原因: 可解释性最强，系数可以直接解释为"在其他变量不变的情况下，
  面积每增加1㎡，房价涨β₁万元"，管理层能理解

场景2: 需要上线自动估价系统，预测越准越好
→ 选择随机森林
→ 原因: 预测性能最优(R²=0.826)，训练时间1.5秒可接受，预测时间0.02秒
  仍在毫秒级，用户体验无影响

场景3: 需要实时在线预测(每秒1000次请求)
→ 选择决策树
→ 原因: 预测速度<0.001秒，性能(R²=0.745)比线性回归好12%，可解释性
  比随机森林强，是速度和性能的平衡

场景4: 数据每月更新一次，需要快速重新训练
→ 选择线性回归或决策树
→ 原因: 训练时间<0.02秒，即使数据量增长也能快速更新，随机森林的1.5秒
  在大数据集上可能更长

结论:
没有"最好"的模型，只有"最适合"的模型。随机森林性能最优，但可解释性
差、训练慢；线性回归可解释性最强，但性能低；决策树在两者之间平衡。
选择模型时要考虑业务需求、数据规模、部署环境。
```

**评分标准**：
- 多模型训练正确（5 分）
- 对比维度全面（8 分）
- 对比表清晰（4 分）
- 模型选择建议合理（5 分）
- 分析深入（3 分）

---

## 挑战作业（可选）

### 任务 7：StatLab 树模型完整流水线（40 分）

**目标**：将你的 StatLab 报告扩展到树模型，产出完整的建模对比章节

**背景**：到上周为止，StatLab 报告已经有了线性回归/逻辑回归。但老潘问："**你能用树模型捕捉非线性关系吗？**"

这正是本周"树模型与集成学习"派上用场的地方。

**要求**：

1. **在 report.md 中添加"树模型与集成学习"章节**，包含：
   - 研究问题：树模型能否比线性模型更好地捕捉非线性？
   - 决策树：可视化树结构、解释分裂规则、过拟合诊断
   - 随机森林：Bagging 原理、性能提升
   - 特征重要性：Top 10 特征、相关性警告
   - 超参数调优：网格/随机搜索结果
   - 模型对比：线性回归 vs 决策树 vs 随机森林
   - 局限性：过拟合风险、特征重要性≠因果

2. **使用示例代码**：
   - 参考 `examples/11_statlab_trees.py`（如果存在）
   - 或使用 `starter_code/solution.py` 作为参考

3. **可视化**：
   - 决策树结构图
   - 特征重要性水平条形图
   - CV 性能曲线（超参数 vs 得分）
   - 模型对比图（如 R² 对比条形图）

4. **提交**：
   - 更新的 `report.md`（添加树模型章节）
   - 树模型代码文件 `tree_models.py`
   - 所有可视化图表文件

**输出示例结构**：
```markdown
## 树模型与集成学习

### 研究问题
线性回归假设特征与目标之间是线性关系，但真实数据可能存在非线性、
交互作用或阈值效应。本章使用决策树和随机森林捕捉这些复杂模式。

### 决策树

决策树通过一系列"如果-那么"规则预测{目标}，可解释性强但容易过拟合。

**树结构可视化**:
[决策树图]

**第一个分裂规则**: 如果 {feature} <= {threshold}，预测 {value}，
否则进入右子节点。

**过拟合诊断**:
无约束决策树训练集R²=0.998，测试集R²=0.610，存在严重过拟合。
通过限制max_depth=5，测试集R²提升到0.745。

### 随机森林

随机森林通过 **Bagging（Bootstrap Aggregating）** 训练多棵树并投票，
显著降低方差。

**性能对比**:
- 单棵决策树: R² = 0.745
- 随机森林(100棵): R² = 0.812

**原理**:
1. Bootstrap重采样：每棵树在不同训练子样本上训练
2. 特征随机性：每次分裂只随机选择√p个特征
3. 投票/平均：回归取平均值，分类取多数投票

### 特征重要性

**Top 10 特征**:
[特征重要性表 + 可视化图]

**解读**:
- 最重要特征: {feature_1}
- 次重要特征: {feature_2}

⚠️ **注意**: 特征重要性不等同于因果关系。相关特征会稀释重要性，
高基数类别特征可能被误认为重要。

### 超参数调优

**随机搜索结果**:
- 最佳参数: {best_params}
- 最佳CV R²: {best_cv_score}
- 测试集R²: {test_score}

### 模型对比

与线性基线（Week 09）的对比:

| 模型 | 测试集R² | 优势 | 劣势 |
|------|---------|------|------|
| 线性回归 | 0.623 | 可解释性强，训练快 | 只能捕捉线性 |
| 决策树 | 0.745 | 可解释规则，捕捉非线性 | 容易过拟合 |
| 随机森林 | 0.812 | 性能最佳，稳健 | 黑盒，训练慢 |

**结论**:
- 如果优先考虑**可解释性**，线性回归是最佳选择
- 如果优先考虑**预测性能**，随机森林明显优于单一模型（R²提升20.3%）
- 决策树在可解释性和性能之间取得平衡

### 局限性与风险

⚠️ **过拟合**: 决策树容易记住训练数据，必须通过max_depth、min_samples_leaf
等超参数控制复杂度。随机森林通过Bagging降低过拟合风险。

⚠️ **特征重要性陷阱**:
- 相关性特征会稀释重要性（面积 vs 房间数）
- 高基数类别特征可能被误认为重要
- 特征重要性≠因果，不能用于干预建议

⚠️ **计算成本**: 随机森林的训练时间是线性模型的10-100倍。
```

**评分标准**：
- 报告结构完整（10 分）
- 分析深度充足（10 分）
- 工程实践正确（Pipeline + CV，10 分）
- 可视化清晰（6 分）
- 局限性讨论（4 分）

---

## AI 协作练习（可选）

### 任务 8：审查 AI 生成的树模型代码（20 分）

**背景**：根据 `shared/ai_progression.md`，Week 11 属于**"协作期"**（Week 09-12）——AI 辅助建模与评估，但关键决策由你主导。你需要学会审查 AI 生成的树模型代码。

**步骤**：

1. **获取 AI 生成的代码**：
   - 使用你喜欢的 AI 工具（如 ChatGPT、Claude 等）
   - 输入以下提示词：
     ```
     我有一个房价预测数据集，包含以下变量：
     - area_sqm: 面积（平方米）
     - bedrooms: 卧室数
     - bathrooms: 浴室数
     - age_years: 房龄（年）
     - distance_km: 距离市中心距离（公里）
     - price: 房价（目标变量）

     请帮我用随机森林预测房价，包括：
     1. 训练随机森林模型
     2. 计算特征重要性
     3. 评估模型性能
     ```

2. **保存 AI 原始输出**，将其保存为 `ai_original_tree_code.txt`

3. **使用审查清单**：

   检查 AI 代码是否包含以下内容：
   - [ ] 是否设置了 `random_state` 确保可复现？
   - [ ] 是否划分了训练集和测试集？（避免在整个数据集上评估）
   - [ ] 是否使用了交叉验证估计泛化性能？
   - [ ] 是否检查了特征重要性？
   - [ ] 是否做了超参数调优（不只是默认值）？
   - [ ] 是否比较了训练集和测试集性能（检查过拟合）？
   - [ ] 是否与基线模型对比（线性回归）？
   - [ ] 是否警告"特征重要性 ≠ 因果关系"？

4. **写一份审查报告** `ai_tree_code_review.md`，包含：
   - AI 原始代码（摘要，150 字）
   - 缺失项列表（按严重性分类：高/中/低）
   - 代码问题分析（如有）
   - 你的修正版代码（补充缺失检查、修正错误）
   - 反思（200 字）：
     - AI 在树模型建模上表现如何？
     - 哪些工程实践 AI 容易遗漏？
     - 超参数调优是 AI 会主动做的吗？
     - 你认为人类必须检查哪些部分？

**评分标准**：
- 审查全面性（10 分）
- 问题分类合理（4 分）
- 修正版代码正确（6 分）

**审查清单示例**：
```
AI 代码审查结果:

缺失项（严重性：高）:
- ❌ 未设置random_state（结果不可复现）
- ❌ 未划分训练/测试集（在整个数据集上评估，性能虚高）
- ❌ 未使用交叉验证（单次评估可能不稳定）

缺失项（严重性：中）:
- ⚠️ 未做超参数调优（使用默认值，可能不是最优）
- ⚠️ 未与基线模型对比（无法判断随机森林是否真的比线性回归好）
- ⚠️ 未检查过拟合（未比较训练集和测试集性能）

缺失项（严重性：低）:
- ℹ️ 未警告"特征重要性≠因果"（可能误导业务决策）
- ℹ️ 未做特征重要性可视化（不利于报告展示）

代码问题:
- ⚠️ AI使用了StandardScaler，但随机森林不需要特征缩放（多余操作）
- ℹ️ AI未使用n_jobs=-1并行训练（训练时间可能更长）
```

---

## StatLab 集成

**要求**：本周所有基础作业的产出应整合到你的 StatLab 报告中

**具体操作**：

1. 在你的 `report.md` 中添加"树模型与集成学习"章节
2. 使用任务 7 的模板结构
3. 包含以下内容：
   - 决策树可视化 + 过拟合诊断
   - 随机森林性能 + Bagging 原理
   - 特征重要性分析 + 相关性警告
   - 超参数调优结果
   - 模型对比（线性 vs 树 vs 集成）
   - 局限性与因果警告

---

## 提交方式

1. 将所有文件放入 `chapters/week_11/assignment/` 目录
2. 文件命名规范：
   - `linear_vs_tree.md`
   - `tree_overfitting.md`
   - `random_forest_bagging.md`
   - `feature_importance_analysis.md`
   - `hyperparameter_tuning.md`（进阶）
   - `model_comparison.md`（进阶）
   - `tree_models.py` + `report.md`（挑战）
   - `ai_original_tree_code.txt`（AI 协作）
   - `ai_tree_code_review.md`（AI 协作）
3. 确保所有 Markdown 文档使用清晰的章节结构
4. 可视化图表可以嵌入文档或单独提交

---

## 作业提示

1. **决策树容易过拟合**：永远比较训练集和测试集性能，如果差异 > 0.2，很可能过拟合

2. **特征重要性 ≠ 因果关系**：面积重要不代表"扩大面积会涨价"，面积可能是地段的代理变量

3. **相关特征会稀释重要性**：如果面积和房间数高度相关，模型只把重要性给其中一个，另一个看起来"不重要"

4. **随机森林的随机性**：设置 `random_state` 确保结果可复现

5. **超参数调优不是"无脑穷举"**：先用随机搜索快速探索，再对关键参数精细调优

6. **永远与基线对比**：先打败线性回归，再谈随机森林的价值

7. **CV 防止数据泄漏**：在交叉验证之前不要做全局预处理

8. **AI 是加速器，不是决策者**：AI 可以拟合随机森林、计算重要性，但防止过拟合、选择基线、解释重要性的责任由你承担

9. **如果遇到困难**：可以参考 `starter_code/solution.py`（如果存在），但不要直接复制粘贴

---

## 常见错误

- ❌ 决策树训练集 R² = 0.99，测试集只有 0.65，却说"模型很好"（严重过拟合）
- ❌ 直接解释特征重要性为因果（"面积重要所以扩大面积会涨价"）
- ❌ 未与线性回归对比，就说"随机森林最好"（没有基线）
- ❌ 使用默认超参数，不做任何调优（模型可能不是最优）
- ❌ 全局 StandardScaler 用于随机森林（树模型不需要特征缩放）
- ❌ 未设置 `random_state`（结果不可复现）
- ❌ 只看 R²，不看特征重要性的陷阱（相关性稀释、高基数特征）
- ❌ 混淆 Bagging 和 Boosting（Bagging 是并行，Boosting 是串行）
- ❌ 网格搜索 10^10 个组合（计算爆炸，应该用随机搜索）
