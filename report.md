# StatLab 分析报告

## 数据清洗与预处理

**数据集**: 用户消费分析
**处理时间**: 2026-02-11T18:35:49

### 处理摘要

- 初始样本量: 500
- 最终样本量: 497
- 删除样本: 3
- 填充缺失值: 91
- 发现异常值: 5

### 详细操作记录

**步骤 1: 删除**
- 目标: total_spend < 0
- 理由: 消费金额不应为负数，判断为数据录入错误
- 方法: 删除包含负数消费的行
- 影响行数: 3
- 备注: 负数记录无法确定原始值，选择删除而非修正

**步骤 2: 标记**
- 目标: total_spend > 50000
- 理由: 高消费用户为真实 VIP，不应删除
- 方法: 添加 outlier_category 列标记为 VIP
- 影响行数: 5
- 备注: VIP 用户将在后续分析中单独考虑

**步骤 3: 填充**
- 目标: age
- 理由: 缺失率较低（~5%），MCAR 机制，中位数稳健
- 方法: 中位数填充 (48)
- 影响行数: 25

**步骤 4: 填充**
- 目标: income
- 理由: MAR 机制（与老用户相关），分组填充保留地域差异
- 方法: 按城市分组，使用中位数填充
- 影响行数: 66
- 备注: 替代方案：删除法（损失 25% 样本）

**步骤 5: 变换**
- 目标: ['age', 'income', 'total_spend']
- 理由: 消除量纲影响，使不同特征可比
- 方法: StandardScaler (z-score)
- 影响行数: 497
- 备注: 变换参数已保存，可用于新数据转换

**步骤 6: 编码**
- 目标: city
- 理由: 城市为名义分类变量，需转换为数值
- 方法: OneHotEncoder
- 影响行数: 497
- 备注: 生成 4 个二元特征

### 数据质量声明

- 所有缺失值已按上述策略处理
- 异常值已分类（suspicious/VIP/normal）并分别处理
- 数值特征已标准化，分类特征已编码
- 清洗后的数据保存于: `data/cleaned/`













## 数据清洗与预处理

**数据集**: 用户消费分析
**处理时间**: 2026-02-11T19:38:29

### 处理摘要

- 初始样本量: 500
- 最终样本量: 497
- 删除样本: 3
- 填充缺失值: 91
- 发现异常值: 5

### 详细操作记录

**步骤 1: 删除**
- 目标: total_spend < 0
- 理由: 消费金额不应为负数，判断为数据录入错误
- 方法: 删除包含负数消费的行
- 影响行数: 3
- 备注: 负数记录无法确定原始值，选择删除而非修正

**步骤 2: 标记**
- 目标: total_spend > 50000
- 理由: 高消费用户为真实 VIP，不应删除
- 方法: 添加 outlier_category 列标记为 VIP
- 影响行数: 5
- 备注: VIP 用户将在后续分析中单独考虑

**步骤 3: 填充**
- 目标: age
- 理由: 缺失率较低（~5%），MCAR 机制，中位数稳健
- 方法: 中位数填充 (48)
- 影响行数: 25

**步骤 4: 填充**
- 目标: income
- 理由: MAR 机制（与老用户相关），分组填充保留地域差异
- 方法: 按城市分组，使用中位数填充
- 影响行数: 66
- 备注: 替代方案：删除法（损失 25% 样本）

**步骤 5: 变换**
- 目标: ['age', 'income', 'total_spend']
- 理由: 消除量纲影响，使不同特征可比
- 方法: StandardScaler (z-score)
- 影响行数: 497
- 备注: 变换参数已保存，可用于新数据转换

**步骤 6: 编码**
- 目标: city
- 理由: 城市为名义分类变量，需转换为数值
- 方法: OneHotEncoder
- 影响行数: 497
- 备注: 生成 4 个二元特征

### 数据质量声明

- 所有缺失值已按上述策略处理
- 异常值已分类（suspicious/VIP/normal）并分别处理
- 数值特征已标准化，分类特征已编码
- 清洗后的数据保存于: `data/cleaned/`

## 数据清洗与预处理

**数据集**: 用户消费分析
**处理时间**: 2026-02-11T19:35:15

### 处理摘要

- 初始样本量: 500
- 最终样本量: 497
- 删除样本: 3
- 填充缺失值: 91
- 发现异常值: 5

### 详细操作记录

**步骤 1: 删除**
- 目标: total_spend < 0
- 理由: 消费金额不应为负数，判断为数据录入错误
- 方法: 删除包含负数消费的行
- 影响行数: 3
- 备注: 负数记录无法确定原始值，选择删除而非修正

**步骤 2: 标记**
- 目标: total_spend > 50000
- 理由: 高消费用户为真实 VIP，不应删除
- 方法: 添加 outlier_category 列标记为 VIP
- 影响行数: 5
- 备注: VIP 用户将在后续分析中单独考虑

**步骤 3: 填充**
- 目标: age
- 理由: 缺失率较低（~5%），MCAR 机制，中位数稳健
- 方法: 中位数填充 (48)
- 影响行数: 25

**步骤 4: 填充**
- 目标: income
- 理由: MAR 机制（与老用户相关），分组填充保留地域差异
- 方法: 按城市分组，使用中位数填充
- 影响行数: 66
- 备注: 替代方案：删除法（损失 25% 样本）

**步骤 5: 变换**
- 目标: ['age', 'income', 'total_spend']
- 理由: 消除量纲影响，使不同特征可比
- 方法: StandardScaler (z-score)
- 影响行数: 497
- 备注: 变换参数已保存，可用于新数据转换

**步骤 6: 编码**
- 目标: city
- 理由: 城市为名义分类变量，需转换为数值
- 方法: OneHotEncoder
- 影响行数: 497
- 备注: 生成 4 个二元特征

### 数据质量声明

- 所有缺失值已按上述策略处理
- 异常值已分类（suspicious/VIP/normal）并分别处理
- 数值特征已标准化，分类特征已编码
- 清洗后的数据保存于: `data/cleaned/`

## 数据清洗与预处理

**数据集**: 用户消费分析
**处理时间**: 2026-02-11T19:34:05

### 处理摘要

- 初始样本量: 500
- 最终样本量: 497
- 删除样本: 3
- 填充缺失值: 91
- 发现异常值: 5

### 详细操作记录

**步骤 1: 删除**
- 目标: total_spend < 0
- 理由: 消费金额不应为负数，判断为数据录入错误
- 方法: 删除包含负数消费的行
- 影响行数: 3
- 备注: 负数记录无法确定原始值，选择删除而非修正

**步骤 2: 标记**
- 目标: total_spend > 50000
- 理由: 高消费用户为真实 VIP，不应删除
- 方法: 添加 outlier_category 列标记为 VIP
- 影响行数: 5
- 备注: VIP 用户将在后续分析中单独考虑

**步骤 3: 填充**
- 目标: age
- 理由: 缺失率较低（~5%），MCAR 机制，中位数稳健
- 方法: 中位数填充 (48)
- 影响行数: 25

**步骤 4: 填充**
- 目标: income
- 理由: MAR 机制（与老用户相关），分组填充保留地域差异
- 方法: 按城市分组，使用中位数填充
- 影响行数: 66
- 备注: 替代方案：删除法（损失 25% 样本）

**步骤 5: 变换**
- 目标: ['age', 'income', 'total_spend']
- 理由: 消除量纲影响，使不同特征可比
- 方法: StandardScaler (z-score)
- 影响行数: 497
- 备注: 变换参数已保存，可用于新数据转换

**步骤 6: 编码**
- 目标: city
- 理由: 城市为名义分类变量，需转换为数值
- 方法: OneHotEncoder
- 影响行数: 497
- 备注: 生成 4 个二元特征

### 数据质量声明

- 所有缺失值已按上述策略处理
- 异常值已分类（suspicious/VIP/normal）并分别处理
- 数值特征已标准化，分类特征已编码
- 清洗后的数据保存于: `data/cleaned/`

## 数据清洗与预处理

**数据集**: 用户消费分析
**处理时间**: 2026-02-11T19:24:44

### 处理摘要

- 初始样本量: 500
- 最终样本量: 497
- 删除样本: 3
- 填充缺失值: 91
- 发现异常值: 5

### 详细操作记录

**步骤 1: 删除**
- 目标: total_spend < 0
- 理由: 消费金额不应为负数，判断为数据录入错误
- 方法: 删除包含负数消费的行
- 影响行数: 3
- 备注: 负数记录无法确定原始值，选择删除而非修正

**步骤 2: 标记**
- 目标: total_spend > 50000
- 理由: 高消费用户为真实 VIP，不应删除
- 方法: 添加 outlier_category 列标记为 VIP
- 影响行数: 5
- 备注: VIP 用户将在后续分析中单独考虑

**步骤 3: 填充**
- 目标: age
- 理由: 缺失率较低（~5%），MCAR 机制，中位数稳健
- 方法: 中位数填充 (48)
- 影响行数: 25

**步骤 4: 填充**
- 目标: income
- 理由: MAR 机制（与老用户相关），分组填充保留地域差异
- 方法: 按城市分组，使用中位数填充
- 影响行数: 66
- 备注: 替代方案：删除法（损失 25% 样本）

**步骤 5: 变换**
- 目标: ['age', 'income', 'total_spend']
- 理由: 消除量纲影响，使不同特征可比
- 方法: StandardScaler (z-score)
- 影响行数: 497
- 备注: 变换参数已保存，可用于新数据转换

**步骤 6: 编码**
- 目标: city
- 理由: 城市为名义分类变量，需转换为数值
- 方法: OneHotEncoder
- 影响行数: 497
- 备注: 生成 4 个二元特征

### 数据质量声明

- 所有缺失值已按上述策略处理
- 异常值已分类（suspicious/VIP/normal）并分别处理
- 数值特征已标准化，分类特征已编码
- 清洗后的数据保存于: `data/cleaned/`

## 数据清洗与预处理

**数据集**: 用户消费分析
**处理时间**: 2026-02-11T19:17:24

### 处理摘要

- 初始样本量: 500
- 最终样本量: 497
- 删除样本: 3
- 填充缺失值: 91
- 发现异常值: 5

### 详细操作记录

**步骤 1: 删除**
- 目标: total_spend < 0
- 理由: 消费金额不应为负数，判断为数据录入错误
- 方法: 删除包含负数消费的行
- 影响行数: 3
- 备注: 负数记录无法确定原始值，选择删除而非修正

**步骤 2: 标记**
- 目标: total_spend > 50000
- 理由: 高消费用户为真实 VIP，不应删除
- 方法: 添加 outlier_category 列标记为 VIP
- 影响行数: 5
- 备注: VIP 用户将在后续分析中单独考虑

**步骤 3: 填充**
- 目标: age
- 理由: 缺失率较低（~5%），MCAR 机制，中位数稳健
- 方法: 中位数填充 (48)
- 影响行数: 25

**步骤 4: 填充**
- 目标: income
- 理由: MAR 机制（与老用户相关），分组填充保留地域差异
- 方法: 按城市分组，使用中位数填充
- 影响行数: 66
- 备注: 替代方案：删除法（损失 25% 样本）

**步骤 5: 变换**
- 目标: ['age', 'income', 'total_spend']
- 理由: 消除量纲影响，使不同特征可比
- 方法: StandardScaler (z-score)
- 影响行数: 497
- 备注: 变换参数已保存，可用于新数据转换

**步骤 6: 编码**
- 目标: city
- 理由: 城市为名义分类变量，需转换为数值
- 方法: OneHotEncoder
- 影响行数: 497
- 备注: 生成 4 个二元特征

### 数据质量声明

- 所有缺失值已按上述策略处理
- 异常值已分类（suspicious/VIP/normal）并分别处理
- 数值特征已标准化，分类特征已编码
- 清洗后的数据保存于: `data/cleaned/`

## 数据清洗与预处理

**数据集**: 用户消费分析
**处理时间**: 2026-02-11T19:08:55

### 处理摘要

- 初始样本量: 500
- 最终样本量: 497
- 删除样本: 3
- 填充缺失值: 91
- 发现异常值: 5

### 详细操作记录

**步骤 1: 删除**
- 目标: total_spend < 0
- 理由: 消费金额不应为负数，判断为数据录入错误
- 方法: 删除包含负数消费的行
- 影响行数: 3
- 备注: 负数记录无法确定原始值，选择删除而非修正

**步骤 2: 标记**
- 目标: total_spend > 50000
- 理由: 高消费用户为真实 VIP，不应删除
- 方法: 添加 outlier_category 列标记为 VIP
- 影响行数: 5
- 备注: VIP 用户将在后续分析中单独考虑

**步骤 3: 填充**
- 目标: age
- 理由: 缺失率较低（~5%），MCAR 机制，中位数稳健
- 方法: 中位数填充 (48)
- 影响行数: 25

**步骤 4: 填充**
- 目标: income
- 理由: MAR 机制（与老用户相关），分组填充保留地域差异
- 方法: 按城市分组，使用中位数填充
- 影响行数: 66
- 备注: 替代方案：删除法（损失 25% 样本）

**步骤 5: 变换**
- 目标: ['age', 'income', 'total_spend']
- 理由: 消除量纲影响，使不同特征可比
- 方法: StandardScaler (z-score)
- 影响行数: 497
- 备注: 变换参数已保存，可用于新数据转换

**步骤 6: 编码**
- 目标: city
- 理由: 城市为名义分类变量，需转换为数值
- 方法: OneHotEncoder
- 影响行数: 497
- 备注: 生成 4 个二元特征

### 数据质量声明

- 所有缺失值已按上述策略处理
- 异常值已分类（suspicious/VIP/normal）并分别处理
- 数值特征已标准化，分类特征已编码
- 清洗后的数据保存于: `data/cleaned/`

## 数据清洗与预处理

**数据集**: 用户消费分析
**处理时间**: 2026-02-11T18:52:37

### 处理摘要

- 初始样本量: 500
- 最终样本量: 497
- 删除样本: 3
- 填充缺失值: 91
- 发现异常值: 5

### 详细操作记录

**步骤 1: 删除**
- 目标: total_spend < 0
- 理由: 消费金额不应为负数，判断为数据录入错误
- 方法: 删除包含负数消费的行
- 影响行数: 3
- 备注: 负数记录无法确定原始值，选择删除而非修正

**步骤 2: 标记**
- 目标: total_spend > 50000
- 理由: 高消费用户为真实 VIP，不应删除
- 方法: 添加 outlier_category 列标记为 VIP
- 影响行数: 5
- 备注: VIP 用户将在后续分析中单独考虑

**步骤 3: 填充**
- 目标: age
- 理由: 缺失率较低（~5%），MCAR 机制，中位数稳健
- 方法: 中位数填充 (48)
- 影响行数: 25

**步骤 4: 填充**
- 目标: income
- 理由: MAR 机制（与老用户相关），分组填充保留地域差异
- 方法: 按城市分组，使用中位数填充
- 影响行数: 66
- 备注: 替代方案：删除法（损失 25% 样本）

**步骤 5: 变换**
- 目标: ['age', 'income', 'total_spend']
- 理由: 消除量纲影响，使不同特征可比
- 方法: StandardScaler (z-score)
- 影响行数: 497
- 备注: 变换参数已保存，可用于新数据转换

**步骤 6: 编码**
- 目标: city
- 理由: 城市为名义分类变量，需转换为数值
- 方法: OneHotEncoder
- 影响行数: 497
- 备注: 生成 4 个二元特征

### 数据质量声明

- 所有缺失值已按上述策略处理
- 异常值已分类（suspicious/VIP/normal）并分别处理
- 数值特征已标准化，分类特征已编码
- 清洗后的数据保存于: `data/cleaned/`

## 数据清洗与预处理

**数据集**: 用户消费分析
**处理时间**: 2026-02-11T18:43:28

### 处理摘要

- 初始样本量: 500
- 最终样本量: 497
- 删除样本: 3
- 填充缺失值: 91
- 发现异常值: 5

### 详细操作记录

**步骤 1: 删除**
- 目标: total_spend < 0
- 理由: 消费金额不应为负数，判断为数据录入错误
- 方法: 删除包含负数消费的行
- 影响行数: 3
- 备注: 负数记录无法确定原始值，选择删除而非修正

**步骤 2: 标记**
- 目标: total_spend > 50000
- 理由: 高消费用户为真实 VIP，不应删除
- 方法: 添加 outlier_category 列标记为 VIP
- 影响行数: 5
- 备注: VIP 用户将在后续分析中单独考虑

**步骤 3: 填充**
- 目标: age
- 理由: 缺失率较低（~5%），MCAR 机制，中位数稳健
- 方法: 中位数填充 (48)
- 影响行数: 25

**步骤 4: 填充**
- 目标: income
- 理由: MAR 机制（与老用户相关），分组填充保留地域差异
- 方法: 按城市分组，使用中位数填充
- 影响行数: 66
- 备注: 替代方案：删除法（损失 25% 样本）

**步骤 5: 变换**
- 目标: ['age', 'income', 'total_spend']
- 理由: 消除量纲影响，使不同特征可比
- 方法: StandardScaler (z-score)
- 影响行数: 497
- 备注: 变换参数已保存，可用于新数据转换

**步骤 6: 编码**
- 目标: city
- 理由: 城市为名义分类变量，需转换为数值
- 方法: OneHotEncoder
- 影响行数: 497
- 备注: 生成 4 个二元特征

### 数据质量声明

- 所有缺失值已按上述策略处理
- 异常值已分类（suspicious/VIP/normal）并分别处理
- 数值特征已标准化，分类特征已编码
- 清洗后的数据保存于: `data/cleaned/`

## 数据清洗与预处理

**数据集**: 用户消费分析
**处理时间**: 2026-02-11T18:43:03

### 处理摘要

- 初始样本量: 500
- 最终样本量: 497
- 删除样本: 3
- 填充缺失值: 91
- 发现异常值: 5

### 详细操作记录

**步骤 1: 删除**
- 目标: total_spend < 0
- 理由: 消费金额不应为负数，判断为数据录入错误
- 方法: 删除包含负数消费的行
- 影响行数: 3
- 备注: 负数记录无法确定原始值，选择删除而非修正

**步骤 2: 标记**
- 目标: total_spend > 50000
- 理由: 高消费用户为真实 VIP，不应删除
- 方法: 添加 outlier_category 列标记为 VIP
- 影响行数: 5
- 备注: VIP 用户将在后续分析中单独考虑

**步骤 3: 填充**
- 目标: age
- 理由: 缺失率较低（~5%），MCAR 机制，中位数稳健
- 方法: 中位数填充 (48)
- 影响行数: 25

**步骤 4: 填充**
- 目标: income
- 理由: MAR 机制（与老用户相关），分组填充保留地域差异
- 方法: 按城市分组，使用中位数填充
- 影响行数: 66
- 备注: 替代方案：删除法（损失 25% 样本）

**步骤 5: 变换**
- 目标: ['age', 'income', 'total_spend']
- 理由: 消除量纲影响，使不同特征可比
- 方法: StandardScaler (z-score)
- 影响行数: 497
- 备注: 变换参数已保存，可用于新数据转换

**步骤 6: 编码**
- 目标: city
- 理由: 城市为名义分类变量，需转换为数值
- 方法: OneHotEncoder
- 影响行数: 497
- 备注: 生成 4 个二元特征

### 数据质量声明

- 所有缺失值已按上述策略处理
- 异常值已分类（suspicious/VIP/normal）并分别处理
- 数值特征已标准化，分类特征已编码
- 清洗后的数据保存于: `data/cleaned/`

## 数据清洗与预处理

**数据集**: 用户消费分析
**处理时间**: 2026-02-11T18:42:48

### 处理摘要

- 初始样本量: 500
- 最终样本量: 497
- 删除样本: 3
- 填充缺失值: 91
- 发现异常值: 5

### 详细操作记录

**步骤 1: 删除**
- 目标: total_spend < 0
- 理由: 消费金额不应为负数，判断为数据录入错误
- 方法: 删除包含负数消费的行
- 影响行数: 3
- 备注: 负数记录无法确定原始值，选择删除而非修正

**步骤 2: 标记**
- 目标: total_spend > 50000
- 理由: 高消费用户为真实 VIP，不应删除
- 方法: 添加 outlier_category 列标记为 VIP
- 影响行数: 5
- 备注: VIP 用户将在后续分析中单独考虑

**步骤 3: 填充**
- 目标: age
- 理由: 缺失率较低（~5%），MCAR 机制，中位数稳健
- 方法: 中位数填充 (48)
- 影响行数: 25

**步骤 4: 填充**
- 目标: income
- 理由: MAR 机制（与老用户相关），分组填充保留地域差异
- 方法: 按城市分组，使用中位数填充
- 影响行数: 66
- 备注: 替代方案：删除法（损失 25% 样本）

**步骤 5: 变换**
- 目标: ['age', 'income', 'total_spend']
- 理由: 消除量纲影响，使不同特征可比
- 方法: StandardScaler (z-score)
- 影响行数: 497
- 备注: 变换参数已保存，可用于新数据转换

**步骤 6: 编码**
- 目标: city
- 理由: 城市为名义分类变量，需转换为数值
- 方法: OneHotEncoder
- 影响行数: 497
- 备注: 生成 4 个二元特征

### 数据质量声明

- 所有缺失值已按上述策略处理
- 异常值已分类（suspicious/VIP/normal）并分别处理
- 数值特征已标准化，分类特征已编码
- 清洗后的数据保存于: `data/cleaned/`

## 数据清洗与预处理

**数据集**: 用户消费分析
**处理时间**: 2026-02-11T18:40:53

### 处理摘要

- 初始样本量: 500
- 最终样本量: 497
- 删除样本: 3
- 填充缺失值: 91
- 发现异常值: 5

### 详细操作记录

**步骤 1: 删除**
- 目标: total_spend < 0
- 理由: 消费金额不应为负数，判断为数据录入错误
- 方法: 删除包含负数消费的行
- 影响行数: 3
- 备注: 负数记录无法确定原始值，选择删除而非修正

**步骤 2: 标记**
- 目标: total_spend > 50000
- 理由: 高消费用户为真实 VIP，不应删除
- 方法: 添加 outlier_category 列标记为 VIP
- 影响行数: 5
- 备注: VIP 用户将在后续分析中单独考虑

**步骤 3: 填充**
- 目标: age
- 理由: 缺失率较低（~5%），MCAR 机制，中位数稳健
- 方法: 中位数填充 (48)
- 影响行数: 25

**步骤 4: 填充**
- 目标: income
- 理由: MAR 机制（与老用户相关），分组填充保留地域差异
- 方法: 按城市分组，使用中位数填充
- 影响行数: 66
- 备注: 替代方案：删除法（损失 25% 样本）

**步骤 5: 变换**
- 目标: ['age', 'income', 'total_spend']
- 理由: 消除量纲影响，使不同特征可比
- 方法: StandardScaler (z-score)
- 影响行数: 497
- 备注: 变换参数已保存，可用于新数据转换

**步骤 6: 编码**
- 目标: city
- 理由: 城市为名义分类变量，需转换为数值
- 方法: OneHotEncoder
- 影响行数: 497
- 备注: 生成 4 个二元特征

### 数据质量声明

- 所有缺失值已按上述策略处理
- 异常值已分类（suspicious/VIP/normal）并分别处理
- 数值特征已标准化，分类特征已编码
- 清洗后的数据保存于: `data/cleaned/`

## 数据清洗与预处理

**数据集**: 用户消费分析
**处理时间**: 2026-02-11T18:39:41

### 处理摘要

- 初始样本量: 500
- 最终样本量: 497
- 删除样本: 3
- 填充缺失值: 91
- 发现异常值: 5

### 详细操作记录

**步骤 1: 删除**
- 目标: total_spend < 0
- 理由: 消费金额不应为负数，判断为数据录入错误
- 方法: 删除包含负数消费的行
- 影响行数: 3
- 备注: 负数记录无法确定原始值，选择删除而非修正

**步骤 2: 标记**
- 目标: total_spend > 50000
- 理由: 高消费用户为真实 VIP，不应删除
- 方法: 添加 outlier_category 列标记为 VIP
- 影响行数: 5
- 备注: VIP 用户将在后续分析中单独考虑

**步骤 3: 填充**
- 目标: age
- 理由: 缺失率较低（~5%），MCAR 机制，中位数稳健
- 方法: 中位数填充 (48)
- 影响行数: 25

**步骤 4: 填充**
- 目标: income
- 理由: MAR 机制（与老用户相关），分组填充保留地域差异
- 方法: 按城市分组，使用中位数填充
- 影响行数: 66
- 备注: 替代方案：删除法（损失 25% 样本）

**步骤 5: 变换**
- 目标: ['age', 'income', 'total_spend']
- 理由: 消除量纲影响，使不同特征可比
- 方法: StandardScaler (z-score)
- 影响行数: 497
- 备注: 变换参数已保存，可用于新数据转换

**步骤 6: 编码**
- 目标: city
- 理由: 城市为名义分类变量，需转换为数值
- 方法: OneHotEncoder
- 影响行数: 497
- 备注: 生成 4 个二元特征

### 数据质量声明

- 所有缺失值已按上述策略处理
- 异常值已分类（suspicious/VIP/normal）并分别处理
- 数值特征已标准化，分类特征已编码
- 清洗后的数据保存于: `data/cleaned/`


# 探索性数据分析

> 本章记录从数据中发现的关系、差异与假设，为后续统计推断提供基础。

生成时间：2026-02-11 20:38

## 探索目标

本次 EDA 旨在回答以下问题：

1. 哪些用户特征与消费行为最相关？
2. 不同用户群体是否存在系统性消费差异？
3. 这些差异是否受其他变量（如收入）混杂？
4. 哪些发现值得进一步统计检验？

## 数据概览

- **样本量**：300 名用户
- **分析变量**：年龄、月收入、月消费、性别、城市级别、用户等级、注册天数
- **数据时间范围**：2024年1月-12月（详见数据卡）
- **清洗说明**：缺失值已按 Week 03 决策日志处理

## 变量关系发现

### 相关性矩阵 (Pearson r)

| 变量对 | Pearson r | 强度 | 方向 | 解读 |
|--------|-----------|------|------|------|
| age - monthly_income | 0.015 | 弱 | 正 | 收入随年龄增长 |
| age - monthly_spend | -0.017 | 弱 | 负 | 弱相关，可能受收入混杂 |
| monthly_income - monthly_spend | 0.811 | 强 | 正 | 收入是消费的重要预测因子 |

### 关键发现

1. **收入-消费关系**：中度正相关（r=0.811），是消费的最强预测因子
2. **年龄-消费关系**：弱相关（r=-0.017），可能受收入混杂
3. **年龄-收入关系**：中度正相关，提示收入随年龄增长

## 分组比较发现

### 用户等级差异

| 用户等级 | 样本量 | 平均年龄 | 平均收入 | 平均消费 |
|----------|--------|----------|----------|----------|
| 普通 | 104 | 34 岁 | 4110 元 | 558 元 |
| 银卡 | 166 | 35 岁 | 5875 元 | 1673 元 |
| 金卡 | 30 | 34 岁 | 13465 元 | 4142 元 |
| 钻石 | 0 | N/A 岁 | N/A 元 | N/A 元 |

**洞察**：钻石用户的平均消费是普通用户的 5-6 倍，
但钻石用户的平均年龄也偏大（约 10 岁），提示年龄-等级-消费三者存在关联网络。

### 城市级别差异

| 城市级别 | 平均消费 | 相对差异 |
|----------|----------|----------|
| 一线 | 1977 元 | +68% |
| 二线 | 1448 元 | +23% |
| 三线 | 1180 元 | +0% |

**洞察**：一线城市用户的平均消费高于二三线城市，
但这一差异在控制收入后缩小，提示城市级别的影响可能主要由收入分布差异解释。

### 性别差异

| 性别 | 平均消费 | 差异 |
|------|----------|------|
| 男 | 1596 元 | - |
| 女 | 1470 元 | -7.9% |

**注意**：整体性别差异在控制收入后显著减小，提示收入可能是混杂变量。

## 潜在混杂变量

通过分层分析，识别以下潜在混杂：

- **收入**：可能混杂年龄-消费、性别-消费关系
- **年龄**：可能混杂用户等级-消费关系
- **城市级别**：可能混杂性别-消费关系（一线城市女性用户比例较高）

## 可检验假设清单

基于上述发现，提出以下假设供后续统计检验：

### 假设 H1 [高优先级]

**描述**：用户收入与月消费金额存在正相关关系

**H0**：收入与消费的 Pearson 相关系数 = 0
**H1**：收入与消费的 Pearson 相关系数 > 0

**数据支持**：EDA 发现 r ≈ 0.52, p < 0.001
**建议检验**：Pearson 相关性检验
**潜在混杂**：年龄、城市级别、职业类型

### 假设 H2 [中优先级]

**描述**：不同城市级别用户的平均消费存在差异

**H0**：一线 = 二线 = 三线城市的平均消费
**H1**：至少有一组城市的平均消费不同

**数据支持**：一线城市均值比三线高约 40-50%
**建议检验**：单因素方差分析 (ANOVA)
**潜在混杂**：收入分布、用户等级构成

### 假设 H3 [高优先级]

**描述**：钻石用户年龄显著大于普通用户

**H0**：钻石用户与普通用户的平均年龄相等
**H1**：钻石用户的平均年龄显著大于普通用户

**数据支持**：钻石用户平均 42 岁 vs 普通用户 31 岁
**建议检验**：独立样本 t 检验
**潜在混杂**：收入、职业阶段、注册时长

## 局限与下一步

**数据局限**：

- 样本为平台现有用户，可能存在选择偏差
- 收入数据为用户自报，可能存在测量误差
- 横截面数据无法确定因果方向

**下一步工作**：

- Week 06-08 将对假设 H1-H3 进行统计检验
- 考虑收集纵向数据以支持因果推断
- 探索更多潜在混杂变量（如职业、教育水平）

---

*本章为探索性分析，所有结论需经后续统计检验验证。*

## 探索性数据分析

> 本章记录从数据中发现的关系、差异与假设，为后续统计推断提供基础。
> 生成时间：2026-02-11T20:48:00

### 分析摘要

- **数据集**：用户消费分析
- **发现数量**：3 个
- **假设数量**：2 个
- **生成图表**：2 个

### 关键发现

**F1** [高优先级]
- age与income的相关性分析
- 相关系数：r = 0.008

**F2** [中优先级]
- age与total_spend的相关性分析
- 相关系数：r = -0.048

**F3** [中优先级]
- 上海城市用户消费比深圳高 3%
- 组间差异：-3%

### 可检验假设清单

**假设 H1** [高优先级]
- 描述：user_id与age存在相关关系
- H0：user_id与age的 Pearson 相关系数 = 0
- H1：user_id与age的 Pearson 相关系数 ≠ 0
- 数据支持：EDA 发现 r = -0.025
- 建议检验：Pearson 相关性检验
- 潜在混杂：其他未控制的变量

**假设 H2** [中优先级]
- 描述：不同用户群体的消费行为存在差异
- H0：各用户群体的平均消费相等
- H1：至少有一组用户的平均消费不同
- 数据支持：分组统计显示群体间存在差异
- 建议检验：单因素方差分析 (ANOVA)
- 潜在混杂：收入、年龄、城市分布

### 分析局限

- 横截面数据，无法确定因果方向
- 部分变量为用户自报，可能存在测量误差
- 未控制的潜在混杂：职业、教育水平、家庭状况

### 下一步工作

- Week 06-08 将对上述假设进行统计检验
- 考虑收集纵向数据以支持因果推断
- 探索机器学习模型预测消费行为
